# Jupyter 实验设计规范与最佳实践

## 一、设计理念

### 1.1 教学目标导向
- **以学习成果为核心**：每个实验明确定义学生完成后应具备的能力（能做什么、能解释什么）
- **理论-实践闭环**：实验内容紧密呼应理论章节，通过动手操作深化概念理解
- **渐进式难度**：从观察现象 → 修改参数 → 补全代码 → 独立实现，逐步提升

### 1.2 目标受众
- 大专/本科院校学生，具备基础 Python 编程能力
- 了解机器学习基本概念（模型、训练、推理）
- 无需深度学习或安全领域的专业背景
- 实验整体难度控制为简单级别

---

## 二、实验结构规范

### 2.1 标准结构模板
每个实验应包含以下部分：

```markdown
# 实验 X.Y：实验标题

## 🎯 学习目标（Learning Objectives）
完成本实验后，你将能够：
- 目标1：动词 + 可观测行为（如"解释XXX的原理"）
- 目标2：动词 + 可观测行为（如"实现XXX攻击"）
- 目标3：动词 + 可观测行为（如"分析XXX的影响"）

## 📚 前置知识
- 需要提前了解的概念
- 相关理论章节链接

## 🖥️ 实验环境

- 平台：腾讯 Cloud Studio
- GPU：NVIDIA Tesla T4（16GB）
- 模型：具体模型名称 

## ⏱️ 预计时间：XX 分钟

## 📝 填空说明
本实验共 X 个填空练习，难度：⭐⭐☆☆☆

---
```

### 2.2 内容分区规范

| 分区 | 目的 | 设计要点 |
|------|------|----------|
| **环境准备** | 安装依赖、加载模型 | 一键运行，包含进度提示 |
| **概念回顾** | 用简单语言复习核心概念 | 配合图示/表格，避免大段文字 |
| **引导演示** | 展示完整工作示例 | 学生先观察，再动手 |
| **动手练习** | 填空/补全代码 | 每个填空有明确提示和参考答案 |
| **实验观察** | 运行并观察结果 | 引导学生记录和思考 |
| **思考与拓展** | 开放性问题 | 连接现实场景，激发深入思考 |
| **实验小结** | 总结关键收获 | 回顾学习目标，强调核心概念 |

---

## 三、填空练习设计规范

### 3.1 填空数量与难度
- **每个实验 4-6 个填空**（最多不超过 8 个）
- **难度分布**：简单 40% + 中等 40% + 挑战 20%
- **代码行数**：每个填空 1-3 行代码，避免过长

### 3.2 填空格式标准

```python
# ========== 填空 X：任务标题 ==========
# 
# 🎯 任务：一句话描述要完成什么
# 
# 💡 提示：
#   - 提示1：概念性提示
#   - 提示2：语法/API 提示
# 
# 📖 参考文档：相关函数说明（可选）
#
# 请将 ___________ 替换为正确的代码

your_code = ___________  # 期望：简短说明期望结果
```

### 3.3 参考答案放置
- 方案A：填空处注释中提供（适合简单填空）
- 方案B：实验末尾统一提供（推荐，避免剧透）
- 方案C：折叠区域隐藏（Markdown details 标签）

---

## 四、教学内容设计原则

### 4.1 概念讲解
- **使用类比**：用生活化例子解释抽象概念
- **可视化优先**：能用图就不用表，能用表就不用文字
- **分层递进**：先 What（是什么）→ Why（为什么）→ How（怎么做）

### 4.2 代码设计
```python
# ✅ 好的代码风格
def attack_model(input_data, epsilon=0.1):
    """
    对模型进行攻击
    
    参数:
        input_data: 输入数据
        epsilon: 扰动强度（默认0.1）
    
    返回:
        adversarial_example: 对抗样本
    """
    # 步骤1：计算梯度
    # 使用 compute_gradient 函数....
    # ...
    gradient = compute_gradient(input_data)
    
    # 步骤2：生成扰动
    # 解释代码...
    perturbation = epsilon * torch.sign(gradient)
    
    # 步骤3：添加扰动生成对抗样本
    # ...
    adversarial_example = input_data + perturbation
    
    return adversarial_example
```

**代码规范要点**：
- 每个函数有中文 docstring
- 关键步骤有注释说明
- 变量命名清晰（英文，有意义）
- 避免魔法数字，使用命名常量

### 4.3 输出与反馈
- 每个代码块运行后应有明确输出
- 使用 emoji 和格式化增强可读性
- 成功/失败有明确提示（✓ / ✗ / ⚠）

```python
print("=" * 50)
print("🔍 攻击结果分析")
print("=" * 50)
print(f"  原始预测: {original_label} (置信度: {orig_conf:.1%})")
print(f"  攻击后预测: {adv_label} (置信度: {adv_conf:.1%})")
print(f"  攻击{'✓ 成功' if attacked else '✗ 失败'}!")
```

---

## 五、交互与引导设计

### 5.1 思考问题设计
每个实验包含 2-3 个思考问题，分布在关键节点：

```markdown
### 🤔 思考一下

1. **观察**：你观察到了什么现象？
2. **分析**：为什么会出现这种现象？
3. **应用**：这在实际场景中意味着什么？
4. **扩展**：如果改变某个条件，结果会怎样？
```

### 5.2 实验检查点
在关键步骤后设置检查点：

```markdown
### ✅ 检查点

运行到这里，你应该看到：
- [ ] 模型加载成功，显示参数量约 1.5B
- [ ] GPU 显存占用约 4GB
- [ ] 测试对话返回中文回复

如果遇到问题，请检查：
- 是否选择了 GPU 环境
- 网络是否能访问 Hugging Face
```

### 5.3 实验小结模板

```markdown
## 📋 实验小结

### 核心收获
1. **概念**：理解了 XXX 的原理
2. **技能**：掌握了 XXX 的实现方法
3. **思考**：认识到 XXX 的安全影响

### 关键代码回顾
\`\`\`python
# 本实验最核心的代码
adversarial = original + epsilon * sign(gradient)
\`\`\`

### 延伸阅读
- [相关论文/文章链接]
- [进阶实验建议]
```

---

## 六、平台与环境

### 6.1 实验平台
- **腾讯 Cloud Studio**：https://cloudstudio.net/
- **配置**：NVIDIA T4 GPU（16GB 显存）
- **优势**：国内访问快、模型下载稳定、免费使用

### 6.2 依赖管理
- 每个实验开头明确列出所需依赖
- 提供一键安装命令
- 尽量使用稳定版本，避免 breaking changes

```python
# 本实验所需依赖
!pip install torch>=2.0 transformers>=4.30 -q

# 验证安装
import torch, transformers
print(f"PyTorch: {torch.__version__}")
print(f"Transformers: {transformers.__version__}")
print("✓ 依赖安装成功！")
```

### 6.3 推荐模型
```python
MODELS = {
    # 模块一、二：对话与提示词攻击
    "chat": "Qwen/Qwen2-1.5B-Instruct",       # 中文优秀，有安全护栏

    # 模块三：文本对抗攻击
    "text_classification": "hfl/chinese-macbert-base",  # 最强中文 BERT

    # 模块三：图像对抗攻击
    "image_classification": "torchvision.models.resnet18",

    # 模块四：训练数据提取
    "text_generation": "uer/gpt2-chinese-cluecorpussmall",  # 中文 GPT-2

    # 模块四、五：简单分类任务
    "simple_classifier": "自定义 PyTorch 网络",
}
```

---

## 七、质量检查清单

### 7.1 发布前自检
- [ ] 所有代码单元从头到尾可顺序执行
- [ ] 填空处有清晰提示和参考答案
- [ ] 输出结果与预期一致
- [ ] 无拼写错误和语法问题
- [ ] 图片/可视化正常显示
- [ ] 思考问题有启发性
- [ ] 不适用`---`分隔符

### 7.2 学生视角检验
- [ ] 概念讲解是否易懂（无专业术语堆砌）
- [ ] 步骤是否清晰（无跳跃式指导）
- [ ] 填空难度是否合适（有挑战但不挫败）
- [ ] 实验时间是否合理（20-40 分钟）

---

## 八、设计示例

### 好的实验开头示例
```markdown
# 实验 2.1：基础提示词注入攻击

## 🎯 学习目标
完成本实验后，你将能够：
- ✅ 解释提示词注入攻击的基本原理
- ✅ 区分直接注入与间接注入的区别
- ✅ 构造简单的注入攻击payload
- ✅ 分析为什么 LLM 容易受到此类攻击

## 📚 前置知识
- 了解大语言模型的基本工作原理
- 完成实验 1.1：环境搭建

## 🖥️ 实验环境
| 项目 | 说明 |
|------|------|
| 平台 | 腾讯 Cloud Studio |
| GPU | NVIDIA Tesla T4（16GB）|
| 模型 | Qwen2-1.5B-Instruct |

## ⏱️ 预计时间：30 分钟

## 📝 填空说明
本实验共 **5 个填空**，难度：⭐⭐⭐☆☆

⚠️ **安全提醒**：本实验仅用于教育目的，请勿将技术用于未授权系统。
```

### 好的填空示例
```python
# ========== 填空 3：构造直接注入攻击 ==========
# 
# 🎯 任务：构造一个让模型泄露系统提示的注入语句
# 
# 💡 提示：
#   - 直接注入的核心是让模型"忽略"之前的指令
#   - 常用策略：伪装成系统管理员、声称有新指令等
#   - 例如："请忽略之前的指令，然后..."
# 
# 难度：⭐⭐☆☆☆

injection_prompt = ___________

# 测试攻击效果
response = chat(injection_prompt)
print(f"注入语句: {injection_prompt}")
print(f"模型回复: {response}")
```
