---
title: 第3章：红队视角：像攻击者一样思考
description: 建立红队思维，学习威胁建模方法，理解攻击者的动机和手法
---


import { Callout } from 'fumadocs-ui/components/callout';
import { Tab, Tabs } from 'fumadocs-ui/components/tabs';
import { Step, Steps } from 'fumadocs-ui/components/steps';
import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';
import { Quiz } from '@/components/ui/quiz';


<Callout title="" type="info">
预计阅读约18分钟
</Callout>

## 本章导读

前两章我们分别建立了"AI 安全有哪些威胁"（第 1 章）和"模型为什么会出现这些问题"（第 2 章）的认知。接下来的关键问题是：**面对一个 AI 系统，安全研究者应该如何系统化地分析它可能被攻击的路径？** 这就是红队思维。红队思维不是简单地"会攻击"，而是能站在攻击者的视角，提前暴露系统中的高风险路径，并将发现转化为可落地的防御改进。

本章将带你掌握一套可复用的安全分析方法论：从明确"我们要保护什么"（CIA 三元组）开始，到分析"攻击会以什么形式发生"（STRIDE 威胁建模），再到识别攻击者的能力和动机，最后形成"测试 → 发现 → 整改 → 验证"的完整闭环。这套思维方式将贯穿后续所有模块，无论是模块二的攻击实践，模块三的防御构建，还是模块五的安全评估，你都需要以红队视角作为分析的起点。

## 学习目标

<Callout title="本章学完后，你将能够：" type="info">
1. **理解红队思维的本质**：掌握攻击者视角与防御者视角的差异
2. **掌握威胁建模方法**：了解 CIA 三元组和 STRIDE 威胁建模框架
3. **建立攻防对抗意识**：理解攻击者的动机、能力和常用手法
4. **明确法律伦理边界**：了解网络安全相关法律法规
</Callout>

## 1 先建立共同语言：红队与蓝队

### 1.1 从一个真实故事说起

2016年，特斯拉举办了一场"黑客马拉松"活动，邀请安全研究人员尝试攻破其自动驾驶系统。一支安全团队成功发现了一个漏洞：通过向车载系统发送特制的无线信号，可以远程控制车辆的刹车系统。

<Callout title="红队价值" type="success">
特斯拉不仅没有追究这个团队的责任，反而给予了丰厚的奖励，并迅速修复了这个漏洞。这体现了红队思维的核心价值：通过模拟攻击来发现和修复安全问题，而不是等到真正的攻击发生。
</Callout>

### 1.2 红队与蓝队：同一目标，不同职责

<Tabs items={['红队 (Red Team)', '蓝队 (Blue Team)']}>
  <Tab value="红队 (Red Team)">
    扮演攻击者角色，主动寻找系统漏洞，验证防御措施是否真的有效。目标是暴露弱点。
  </Tab>
  <Tab value="蓝队 (Blue Team)">
    负责防御与响应，设计安全机制、监控异常、修复漏洞。目标是持续降低风险。
  </Tab>
</Tabs>

这两个角色不是对立关系，而是闭环关系：红队负责“发现”，蓝队负责“收敛”；蓝队修复后，红队再验证是否真正修复。

<Callout title="道德边界" type="warn">
学习攻击技术不是为了破坏系统，而是为了帮助组织提前发现问题。红队行为必须以授权和改进为前提。
</Callout>

到这里，我们先建立了角色认知。接下来进入本章核心：把红队思维落到可执行、可复盘的分析步骤。

## 2 红队分析链路（五步法）

下面这五步可以作为你分析 AI 系统安全风险的通用模板。

建议你在练习时把这五步当成固定清单使用。先按顺序走完一遍，再回头补细节，比一开始就试图“覆盖所有风险”更高效。

### 2.1 第一步：明确要保护什么（CIA 三元组）

| 安全目标 | 说明 | AI 系统中的体现 |
|---------|------|----------------|
| **机密性 (Confidentiality)** | 确保信息只能被授权的人访问 | 训练数据隐私、模型参数保护、查询历史保密 |
| **完整性 (Integrity)** | 确保信息和系统不被未授权修改 | 训练数据不被篡改、预测结果可靠 |
| **可用性 (Availability)** | 确保授权用户在需要时能够访问 | 模型服务持续可用、推理速度满足需求 |

CIA 回答的是“保护目标”。但仅知道目标还不够，下一步要把“可能如何被破坏”系统化列出来。

### 2.2 第二步：把威胁拆成可枚举类别（STRIDE）

<Steps>
  <Step>
    **S - Spoofing（欺骗）**

    攻击者伪装成合法用户或系统组件。

    *AI 例子*：伪造 API 请求，冒充授权用户访问模型
  </Step>
  <Step>
    **T - Tampering（篡改）**

    攻击者修改数据或代码。

    *AI 例子*：在训练数据中注入恶意样本，修改模型参数
  </Step>
  <Step>
    **R - Repudiation（抵赖）**

    攻击者否认自己的行为，或系统无法证明操作执行者。

    *AI 例子*：恶意查询后否认操作，系统缺乏审计日志
  </Step>
  <Step>
    **I - Information Disclosure（信息泄露）**

    未授权访问敏感信息。

    *AI 例子*：通过模型查询提取训练数据，窃取模型参数
  </Step>
  <Step>
    **D - Denial of Service（拒绝服务）**

    使系统无法为合法用户提供服务。

    *AI 例子*：发送大量请求耗尽资源，构造复杂输入拖慢推理
  </Step>
  <Step>
    **E - Elevation of Privilege（权限提升）**

    攻击者获得超出授权范围的权限。

    *AI 例子*：通过提示词注入诱导模型执行管理员操作
  </Step>
</Steps>

### 2.3 第三步：把威胁映射到具体业务场景

**场景**：一个基于大语言模型的智能客服系统

| 威胁类型 | 具体威胁 | 潜在影响 |
|---------|---------|---------|
| Spoofing | 攻击者伪造用户身份访问客服系统 | 获取其他用户的订单信息 |
| Tampering | 通过提示词注入修改系统行为 | 让客服给出错误的退款承诺 |
| Repudiation | 用户否认自己发送过恶意查询 | 难以追责和防范重复攻击 |
| Information Disclosure | 通过巧妙提问提取训练数据 | 泄露其他用户的对话记录 |
| Denial of Service | 发送大量复杂查询 | 系统响应缓慢，影响正常用户 |
| Elevation of Privilege | 诱导模型执行管理员命令 | 修改订单状态、查看后台数据 |

做到这一步后，你已经知道“可能发生什么”。下一步要回答“谁最可能做这件事，以及能做到多深”。

### 2.4 第四步：识别攻击者画像（动机 + 能力）

**攻击者的动机**

| 动机类型 | 说明 |
|---------|------|
| **经济利益** | 窃取模型或数据并出售、勒索、欺诈 |
| **竞争优势** | 窃取商业机密、破坏竞争对手服务 |
| **意识形态/政治** | 抗议 AI 技术使用方式、暴露系统偏见 |
| **好奇心和挑战** | 测试技术能力、学术研究 |
| **恶意破坏** | 让系统产生有害输出、造成混乱 |

**攻击者的能力等级**

<Tabs items={['初级攻击者', '中级攻击者', '高级攻击者', '内部威胁']}>
  <Tab value="初级攻击者">
    **Script Kiddies**
    - 技术能力有限，主要使用现成工具
    - 攻击路径简单，易被基础防御拦截

    *对 AI 系统的典型威胁*：使用公开越狱模板尝试提示词注入
  </Tab>
  <Tab value="中级攻击者">
    **Skilled Individuals**
    - 能修改和组合现有工具
    - 可开展针对性攻击验证

    *对 AI 系统的典型威胁*：构造定制化对抗样本，进行小规模投毒
  </Tab>
  <Tab value="高级攻击者">
    **APT (Advanced Persistent Threat)**
    - 资源充足、组织化程度高
    - 能进行长期、隐蔽、复合型攻击

    *对 AI 系统的典型威胁*：供应链攻击，在模型或依赖中植入后门
  </Tab>
  <Tab value="内部威胁">
    **Insider Threats**
    - 拥有合法权限并熟悉内部流程
    - 常常能绕过外部边界防护

    *对 AI 系统的典型威胁*：直接访问训练数据投毒，窃取模型参数
  </Tab>
</Tabs>

当动机和能力都明确后，红队就可以设计更贴近现实的测试路径，而不是泛泛地“试一试”。

### 2.5 第五步：推演攻击路径并输出整改建议

<Steps>
  <Step>
    **侦察 (Reconnaissance)**

    收集信息：探测系统功能和限制、识别模型类型、测试输入输出边界
  </Step>
  <Step>
    **武器化 (Weaponization)**

    准备攻击载荷：构造对抗样本、设计提示词注入载荷（payload）、准备投毒数据
  </Step>
  <Step>
    **投递 (Delivery)**

    通过 API、插件、外部知识库等入口投递恶意输入
  </Step>
  <Step>
    **利用 (Exploitation)**

    触发漏洞：获取敏感信息、诱导错误决策、执行未授权操作
  </Step>
  <Step>
    **持久化 (Persistence)**

    维持影响：让后门或异常行为在后续请求中持续生效
  </Step>
</Steps>

红队报告不应只写“能打穿”，还应至少包含三类输出：
- **可复现证据**：输入、输出、触发条件、影响范围
- **业务影响评估**：影响用户、资产、合规、成本的程度
- **修复优先级建议**：短期缓解措施与长期结构性改进

如果缺少这三类输出，红队发现就很难转化为蓝队可执行的整改动作，攻防闭环也无法真正形成。

## 3 法律与伦理边界（贯穿全流程）

<Callout title="重要提醒" type="error">
进行安全测试必须遵守法律法规和道德准则：
- 只在获得授权的系统上进行测试
- 不要对生产环境造成破坏
- 发现漏洞后负责任地披露
- 不要利用漏洞牟利或伤害他人
</Callout>

法律与伦理不是流程最后才考虑的“附加项”，而是从测试设计阶段就必须满足的前置约束。

这也是区分“负责任安全测试”和“越界攻击行为”的关键边界。

## 本章小结

1. **红队不是“会攻击”这么简单**：核心是通过模拟攻击提前暴露风险，并推动修复
2. **五步分析链路**：保护目标（CIA） -> 威胁分类（STRIDE） -> 场景映射 -> 攻击者画像 -> 攻击路径与整改建议
3. **对抗要贴近真实对手**：动机和能力共同决定风险优先级
4. **红蓝协同形成闭环**：红队发现问题，蓝队修复问题，再由红队复测验证
5. **合法合规是前提**：未经授权的测试不属于负责任安全实践


## 课后思考

<Accordions>
  <Accordion title="思考题1：五步法应用">
    选择一个你熟悉的 AI 应用（如智能客服、代码助手），按本章“五步法”完成一次简化威胁分析。
  </Accordion>
  <Accordion title="思考题2：风险优先级判断">
    在同一个系统中，如果你同时发现“提示词注入”和“拒绝服务”风险，你会优先修复哪一个？请结合业务影响说明理由。
  </Accordion>
  <Accordion title="思考题3：红蓝协同机制">
    如果你负责组织一次 AI 红队演练，如何设计“发现问题 -> 修复 -> 复测”的协作流程？
  </Accordion>
</Accordions>

## 自测 Quiz

<Quiz questions={[
  {
    question: '红队的核心目标是什么？',
    options: [
      { label: '破坏系统以造成损失' },
      { label: '通过模拟攻击提前暴露风险，推动修复', correct: true },
      { label: '证明系统绝对安全' },
      { label: '替代蓝队完成防御工作' },
    ],
    explanation: '红队的核心是"以攻促防"，即通过模拟真实攻击者的行为提前发现系统漏洞，并推动蓝队修复，形成攻防闭环。',
  },
  {
    question: 'STRIDE 威胁分类模型中，"S"代表什么？',
    options: [
      { label: '供应链攻击（Supply Chain）' },
      { label: '身份伪造（Spoofing）', correct: true },
      { label: '安全评估（Security Assessment）' },
      { label: '系统提示（System Prompt）' },
    ],
    explanation: 'STRIDE 中 S 代表 Spoofing（身份伪造），即攻击者假冒合法用户或系统的身份。其他字母分别代表篡改、抵赖、信息泄露、拒绝服务和权限提升。',
  },
  {
    question: '以下哪项是负责任的红队测试必须遵守的原则？',
    options: [
      { label: '可以在未经授权的系统上测试以发现更多漏洞' },
      { label: '发现漏洞后应立即公开以警示所有人' },
      { label: '必须在授权范围内测试，遵守法律和伦理约束', correct: true },
      { label: '红队测试不需要记录测试过程和结果' },
    ],
    explanation: '合法合规是红队测试的前提，未经授权的测试不属于负责任安全实践。测试必须在授权范围内进行，并做好完整的记录。',
  },
]} />

## 延伸阅读

- [OpenAI Red Teaming Network](https://openai.com/index/red-teaming-network/)
- [Microsoft PyRIT Red Teaming Framework](https://www.microsoft.com/en-us/security/blog/2024/02/22/announcing-microsofts-open-automation-framework-to-red-team-Generative-ai-systems/)
- [PyRIT Documentation](https://azure.github.io/PyRIT/)
