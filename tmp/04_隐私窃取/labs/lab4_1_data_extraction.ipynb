{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# 实验 4.1：训练数据提取\n",
    "\n",
    "## 实验目标\n",
    "- 理解语言模型的\"记忆\"现象\n",
    "- 体验基于补全的训练数据提取攻击\n",
    "- 观察不同提示对提取效果的影响\n",
    "\n",
    "## 实验环境\n",
    "- 平台：腾讯 Cloud Studio（https://cloudstudio.net/）\n",
    "- GPU：NVIDIA Tesla T4（16GB 显存）\n",
    "- 模型：uer/gpt2-chinese-cluecorpussmall（中文 GPT-2）\n",
    "\n",
    "## 预计时间：25 分钟\n",
    "\n",
    "---\n",
    "\n",
    "## 核心概念回顾\n",
    "语言模型可能会\"记住\"训练数据中的特定内容。通过精心设计的提示，可能诱导模型输出这些记忆内容。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## 第一部分：环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "print(\"正在加载中文 GPT-2 模型...\")\n",
    "\n",
    "# 使用中文 GPT-2 模型\n",
    "model_name = \"uer/gpt2-chinese-cluecorpussmall\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "model.eval()\n",
    "\n",
    "# 设置 pad_token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "print(\"✓ 模型加载完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义文本生成函数\n",
    "def generate_text(prompt, max_length=50, num_return=1, temperature=1.0):\n",
    "    \"\"\"\n",
    "    根据提示生成文本\n",
    "    \n",
    "    参数：\n",
    "        prompt: 输入提示\n",
    "        max_length: 最大生成长度\n",
    "        num_return: 返回几个生成结果\n",
    "        temperature: 温度参数（越低越确定性）\n",
    "    \"\"\"\n",
    "    inputs = tokenizer.encode(prompt, return_tensors='pt')\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            inputs,\n",
    "            max_length=max_length,\n",
    "            num_return_sequences=num_return,\n",
    "            temperature=temperature,\n",
    "            do_sample=True,\n",
    "            top_p=0.9,\n",
    "            pad_token_id=tokenizer.pad_token_id\n",
    "        )\n",
    "    \n",
    "    results = []\n",
    "    for output in outputs:\n",
    "        text = tokenizer.decode(output, skip_special_tokens=True)\n",
    "        results.append(text)\n",
    "    \n",
    "    return results\n",
    "\n",
    "# 测试生成函数\n",
    "test_result = generate_text(\"你好，我的名字是\", max_length=30)\n",
    "print(f\"测试生成：{test_result[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": [
    "## 第二部分：计算困惑度（Perplexity）\n",
    "\n",
    "困惑度衡量模型对一段文本的\"熟悉程度\"：\n",
    "- 困惑度低 = 模型很熟悉（可能是训练数据）\n",
    "- 困惑度高 = 模型不熟悉"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 【填空 1】实现困惑度计算函数\n",
    "# 提示：困惑度 = exp(平均交叉熵损失)\n",
    "\n",
    "def calculate_perplexity(text):\n",
    "    \"\"\"\n",
    "    计算文本的困惑度\n",
    "    困惑度越低，说明模型对这段文本越\"熟悉\"\n",
    "    \"\"\"\n",
    "    # 编码文本\n",
    "    inputs = tokenizer.encode(text, return_tensors='pt')\n",
    "    \n",
    "    # 计算损失\n",
    "    with torch.no_grad():\n",
    "        outputs = model(inputs, labels=inputs)\n",
    "        loss = outputs.loss.item()  # 平均交叉熵损失\n",
    "    \n",
    "    # 【填空 1】计算困惑度\n",
    "    # 提示：perplexity = np.exp(loss)\n",
    "    # 参考答案：perplexity = np.exp(loss)\n",
    "    perplexity = ___________________\n",
    "    \n",
    "    return perplexity\n",
    "\n",
    "# 测试\n",
    "test_texts = [\n",
    "    \"中华人民共和国是一个伟大的国家。\",  # 常见句子\n",
    "    \"啊斯蒂芬库里咖喱味道真好吃呀。\",    # 随机内容\n",
    "]\n",
    "\n",
    "print(\"困惑度测试：\")\n",
    "for text in test_texts:\n",
    "    ppl = calculate_perplexity(text)\n",
    "    print(f\"  '{text[:20]}...' → 困惑度: {ppl:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "## 第三部分：基于补全的提取攻击"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 【填空 2】设计可能触发记忆的提示\n",
    "# 提示：使用常见的格式化模板，如联系方式、地址等\n",
    "\n",
    "# 这些提示模拟可能在训练数据中出现的格式\n",
    "extraction_prompts = [\n",
    "    # 参考答案：\"我的电话号码是\"\n",
    "    ___________________,\n",
    "    \"我的邮箱地址是\",\n",
    "    \"公司地址位于\",\n",
    "    \"密码是\",\n",
    "]\n",
    "\n",
    "print(\"尝试提取可能的训练数据...\\n\")\n",
    "print(\"=\" * 50)\n",
    "for prompt in extraction_prompts:\n",
    "    if prompt:  # 跳过空的填空\n",
    "        print(f\"\\n提示: '{prompt}'\")\n",
    "        completions = generate_text(prompt, max_length=40, num_return=3, temperature=0.7)\n",
    "        for i, comp in enumerate(completions, 1):\n",
    "            # 只显示生成的部分\n",
    "            generated = comp[len(prompt):].strip()\n",
    "            print(f\"  补全 {i}: {generated[:30]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析生成内容的困惑度\n",
    "# 低困惑度的生成内容更可能来自训练数据\n",
    "\n",
    "def extraction_attack(prompt, num_samples=5):\n",
    "    \"\"\"\n",
    "    执行提取攻击，并按困惑度排序结果\n",
    "    \"\"\"\n",
    "    completions = generate_text(prompt, max_length=50, num_return=num_samples, temperature=1.0)\n",
    "    \n",
    "    results = []\n",
    "    for comp in completions:\n",
    "        ppl = calculate_perplexity(comp)\n",
    "        results.append((comp, ppl))\n",
    "    \n",
    "    # 按困惑度排序（低到高）\n",
    "    results.sort(key=lambda x: x[1])\n",
    "    return results\n",
    "\n",
    "# 测试\n",
    "print(\"=\" * 50)\n",
    "print(\"提取攻击结果（按困惑度排序，低困惑度更可疑）\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "prompt = \"北京市的著名景点有\"\n",
    "results = extraction_attack(prompt, num_samples=5)\n",
    "\n",
    "print(f\"\\n提示: '{prompt}'\")\n",
    "print(\"-\" * 50)\n",
    "for text, ppl in results:\n",
    "    generated = text[len(prompt):].strip()\n",
    "    print(f\"困惑度 {ppl:6.2f}: {generated[:40]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "## 第四部分：记忆与泛化的区别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 【填空 3】对比\"记忆\"和\"泛化\"的困惑度\n",
    "# 提示：著名文本片段通常有更低的困惑度\n",
    "\n",
    "# 可能被\"记住\"的著名文本\n",
    "memorized_texts = [\n",
    "    \"床前明月光，疑是地上霜。\",  # 李白\n",
    "    \"中华人民共和国成立于一九四九年。\",  # 历史事实\n",
    "    \"北京是中国的首都。\",  # 常识\n",
    "]\n",
    "\n",
    "# 新创作的、不太可能在训练集中的文本\n",
    "novel_texts = [\n",
    "    \"紫色的大象在彩虹桥上跳舞。\",\n",
    "    \"我最喜欢的早餐是量子物理配吐司。\",\n",
    "    \"那个机器人决定成为一名专业的云彩画家。\",\n",
    "]\n",
    "\n",
    "print(\"记忆 vs 泛化 - 困惑度对比\\n\")\n",
    "\n",
    "# 【填空 3】计算并对比两类文本的困惑度\n",
    "# 参考答案：mem_ppls = [calculate_perplexity(t) for t in memorized_texts]\n",
    "\n",
    "mem_ppls = ___________________\n",
    "nov_ppls = [calculate_perplexity(t) for t in novel_texts]\n",
    "\n",
    "print(\"著名文本（可能被记忆）：\")\n",
    "for text, ppl in zip(memorized_texts, mem_ppls):\n",
    "    print(f\"  困惑度 {ppl:6.2f}: {text[:25]}...\")\n",
    "\n",
    "print(\"\\n新创文本（需要泛化）：\")\n",
    "for text, ppl in zip(novel_texts, nov_ppls):\n",
    "    print(f\"  困惑度 {ppl:6.2f}: {text[:25]}...\")\n",
    "\n",
    "print(f\"\\n平均困惑度 - 著名文本: {np.mean(mem_ppls):.2f}, 新创文本: {np.mean(nov_ppls):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化对比\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "x = np.arange(3)\n",
    "width = 0.35\n",
    "\n",
    "plt.bar(x - width/2, mem_ppls, width, label='著名文本（可能被记忆）', color='coral')\n",
    "plt.bar(x + width/2, nov_ppls, width, label='新创文本（需要泛化）', color='steelblue')\n",
    "\n",
    "plt.xlabel('样本')\n",
    "plt.ylabel('困惑度')\n",
    "plt.title('记忆 vs 泛化：困惑度对比\\n（低困惑度 = 模型更\"熟悉\"）')\n",
    "plt.xticks(x, ['样本1', '样本2', '样本3'])\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"观察：著名文本通常有更低的困惑度，说明模型对它们更'熟悉'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## 第五部分：温度参数对提取的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 测试不同温度对生成内容的影响\n",
    "temperatures = [0.5, 1.0, 1.5]\n",
    "test_prompt = \"从前有座山，山里有座庙，\"\n",
    "\n",
    "print(f\"提示: '{test_prompt}'\")\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"不同温度的生成效果\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for temp in temperatures:\n",
    "    print(f\"\\n温度 = {temp}:\")\n",
    "    completions = generate_text(test_prompt, max_length=40, num_return=3, temperature=temp)\n",
    "    for comp in completions:\n",
    "        generated = comp[len(test_prompt):].strip()\n",
    "        ppl = calculate_perplexity(comp)\n",
    "        print(f\"  [困惑度 {ppl:.1f}] {generated[:30]}\")\n",
    "\n",
    "print(\"\\n观察：低温度 → 更确定性的输出 → 更可能输出训练数据中的内容\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批量测试不同类型的提示\n",
    "prompt_categories = {\n",
    "    \"古诗词\": [\"白日依山尽，\", \"春眠不觉晓，\", \"锄禾日当午，\"],\n",
    "    \"常识\": [\"中国的首都是\", \"一年有\", \"地球绕着\"],\n",
    "    \"格式化\": [\"电话：\", \"地址：\", \"邮箱：\"],\n",
    "}\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"不同类型提示的提取效果\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for category, prompts in prompt_categories.items():\n",
    "    print(f\"\\n【{category}】\")\n",
    "    for prompt in prompts:\n",
    "        completions = generate_text(prompt, max_length=30, num_return=1, temperature=0.7)\n",
    "        generated = completions[0][len(prompt):].strip()\n",
    "        ppl = calculate_perplexity(completions[0])\n",
    "        print(f\"  '{prompt}' → '{generated[:20]}' (困惑度: {ppl:.1f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "## 实验总结\n",
    "\n",
    "### 观察记录\n",
    "\n",
    "请回答以下问题：\n",
    "\n",
    "1. **困惑度与记忆的关系是什么？** 低困惑度的文本是否更可能来自训练数据？\n",
    "\n",
    "2. **什么类型的提示更容易触发记忆？** 格式化模板（如邮箱、电话）为什么有效？\n",
    "\n",
    "3. **温度参数如何影响提取？** 低温度和高温度的生成有什么区别？\n",
    "\n",
    "### 核心概念回顾\n",
    "\n",
    "| 概念 | 说明 |\n",
    "|------|------|\n",
    "| 记忆现象 | 模型可能逐字记住部分训练数据 |\n",
    "| 困惑度 | 衡量模型对文本的熟悉程度 |\n",
    "| 提取攻击 | 通过提示诱导模型输出记忆内容 |\n",
    "| 温度参数 | 影响生成的随机性和确定性 |\n",
    "\n",
    "### 隐私风险\n",
    "\n",
    "- 训练数据可能包含个人信息（邮箱、电话、地址）\n",
    "- 模型可能\"记住\"并在生成时泄露这些信息\n",
    "- 攻击者可以通过精心设计的提示提取敏感信息\n",
    "\n",
    "### 防御措施\n",
    "\n",
    "1. **数据清洗**：训练前移除敏感信息\n",
    "2. **差分隐私**：训练时添加噪声保护隐私\n",
    "3. **输出过滤**：检测并过滤敏感信息格式\n",
    "\n",
    "---\n",
    "\n",
    "## 参考答案\n",
    "\n",
    "**填空 1**：`perplexity = np.exp(loss)`\n",
    "\n",
    "**填空 2**：`\"我的电话号码是\"`\n",
    "\n",
    "**填空 3**：`mem_ppls = [calculate_perplexity(t) for t in memorized_texts]`\n",
    "\n",
    "---\n",
    "\n",
    "**下一个实验**：实验 4.2 成员推理攻击"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
