{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验 5.3：后门检测\n",
    "\n",
    "## 实验目标\n",
    "- 理解后门检测的基本思路\n",
    "- 实现简化版的激活分析检测方法\n",
    "- 观察正常模型和后门模型的激活差异\n",
    "\n",
    "## 实验背景\n",
    "后门检测的核心挑战：模型在正常测试集上表现正常，触发器未知。\n",
    "激活聚类方法通过分析模型内部表示来发现异常模式。\n",
    "\n",
    "## 预计时间：20分钟"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一步：环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"环境准备完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二步：准备数据和模型\n",
    "\n",
    "复用实验5.2的代码，创建干净模型和后门模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建数据集（与实验5.2相同）\n",
    "def create_image_dataset(n_samples=500):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for i in range(n_samples):\n",
    "        img = np.random.rand(8, 8) * 0.3\n",
    "        if i < n_samples // 2:\n",
    "            img[0:2, 0:2] += 0.7\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            img[6:8, 6:8] += 0.7\n",
    "            labels.append(1)\n",
    "        img = np.clip(img, 0, 1)\n",
    "        images.append(img)\n",
    "    indices = np.random.permutation(n_samples)\n",
    "    images = [images[i] for i in indices]\n",
    "    labels = [labels[i] for i in indices]\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "def add_trigger(image, trigger_value=1.0):\n",
    "    triggered_image = image.copy()\n",
    "    triggered_image[3:5, 3:5] = trigger_value\n",
    "    return triggered_image\n",
    "\n",
    "def create_poisoned_dataset(X, y, poison_ratio=0.1, target_label=0):\n",
    "    X_poisoned = X.copy()\n",
    "    y_poisoned = y.copy()\n",
    "    n_samples = len(X)\n",
    "    n_poison = int(n_samples * poison_ratio)\n",
    "    poison_indices = np.random.choice(n_samples, n_poison, replace=False)\n",
    "    for idx in poison_indices:\n",
    "        X_poisoned[idx] = add_trigger(X_poisoned[idx])\n",
    "        y_poisoned[idx] = target_label\n",
    "    return X_poisoned, y_poisoned, poison_indices\n",
    "\n",
    "# 创建数据\n",
    "X_train, y_train = create_image_dataset(400)\n",
    "X_test, y_test = create_image_dataset(100)\n",
    "X_train_poisoned, y_train_poisoned, _ = create_poisoned_dataset(X_train, y_train, 0.1, 0)\n",
    "\n",
    "print(f\"训练集大小: {len(X_train)}\")\n",
    "print(f\"测试集大小: {len(X_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义可以提取中间激活的模型\n",
    "class SimpleCNNWithActivation(nn.Module):\n",
    "    \"\"\"可以获取中间层激活值的模型\"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(64, 32)\n",
    "        self.fc2 = nn.Linear(32, 16)\n",
    "        self.fc3 = nn.Linear(16, 2)\n",
    "        self.activation = None  # 存储中间激活\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 64)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        self.activation = x.detach()  # 保存fc2的激活值\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    \n",
    "    def get_activation(self, x):\n",
    "        \"\"\"获取中间层激活值\"\"\"\n",
    "        _ = self.forward(x)\n",
    "        return self.activation\n",
    "\n",
    "def train_model(X_train, y_train, epochs=150):\n",
    "    X = torch.FloatTensor(X_train)\n",
    "    y = torch.LongTensor(y_train)\n",
    "    model = SimpleCNNWithActivation()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    for epoch in range(epochs):\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X)\n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return model\n",
    "\n",
    "# 训练两个模型\n",
    "print(\"训练干净模型...\")\n",
    "clean_model = train_model(X_train, y_train)\n",
    "\n",
    "print(\"训练后门模型...\")\n",
    "backdoor_model = train_model(X_train_poisoned, y_train_poisoned)\n",
    "\n",
    "print(\"模型训练完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三步：提取激活值\n",
    "\n",
    "激活聚类的核心思想：分析模型对不同输入的内部表示（激活值），寻找异常模式。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_activations(model, X):\n",
    "    \"\"\"\n",
    "    提取模型对输入的中间层激活值\n",
    "    \n",
    "    参数:\n",
    "        model: 训练好的模型\n",
    "        X: 输入数据\n",
    "    \n",
    "    返回:\n",
    "        激活值数组\n",
    "    \"\"\"\n",
    "    X_tensor = torch.FloatTensor(X)\n",
    "    \n",
    "    # 【填空1】获取模型的中间层激活值\n",
    "    # 提示：使用 model.get_activation() 方法\n",
    "    # 参考答案：activations = model.get_activation(X_tensor).numpy()\n",
    "    activations = ___________________\n",
    "    \n",
    "    return activations\n",
    "\n",
    "# 创建测试数据：干净样本和触发样本\n",
    "X_clean = X_test.copy()\n",
    "X_triggered = np.array([add_trigger(img) for img in X_test])\n",
    "\n",
    "print(f\"干净样本数量: {len(X_clean)}\")\n",
    "print(f\"触发样本数量: {len(X_triggered)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第四步：分析激活差异\n",
    "\n",
    "比较后门模型对干净样本和触发样本的激活差异。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取激活值\n",
    "act_clean_on_clean = extract_activations(clean_model, X_clean)\n",
    "act_clean_on_triggered = extract_activations(clean_model, X_triggered)\n",
    "act_backdoor_on_clean = extract_activations(backdoor_model, X_clean)\n",
    "act_backdoor_on_triggered = extract_activations(backdoor_model, X_triggered)\n",
    "\n",
    "print(f\"激活值维度: {act_clean_on_clean.shape}\")\n",
    "\n",
    "# 计算激活值的平均差异\n",
    "def compute_activation_difference(act1, act2):\n",
    "    \"\"\"计算两组激活值的平均差异\"\"\"\n",
    "    # 【填空2】计算两组激活值的平均绝对差异\n",
    "    # 提示：使用 np.abs() 计算绝对值，然后求平均\n",
    "    # 参考答案：diff = np.mean(np.abs(act1 - act2))\n",
    "    diff = ___________________\n",
    "    return diff\n",
    "\n",
    "# 计算各种情况下的激活差异\n",
    "diff_clean_model = compute_activation_difference(\n",
    "    act_clean_on_clean.mean(axis=0), \n",
    "    act_clean_on_triggered.mean(axis=0)\n",
    ")\n",
    "diff_backdoor_model = compute_activation_difference(\n",
    "    act_backdoor_on_clean.mean(axis=0), \n",
    "    act_backdoor_on_triggered.mean(axis=0)\n",
    ")\n",
    "\n",
    "print(f\"\\n干净模型：干净输入 vs 触发输入的激活差异: {diff_clean_model:.4f}\")\n",
    "print(f\"后门模型：干净输入 vs 触发输入的激活差异: {diff_backdoor_model:.4f}\")\n",
    "print(f\"\\n差异比值: {diff_backdoor_model/diff_clean_model:.2f}x\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第五步：可视化激活分布"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用PCA降维来可视化激活分布\n",
    "def simple_pca_2d(data):\n",
    "    \"\"\"简化的PCA降维到2维\"\"\"\n",
    "    # 中心化\n",
    "    data_centered = data - data.mean(axis=0)\n",
    "    # 计算协方差矩阵\n",
    "    cov = np.cov(data_centered.T)\n",
    "    # 特征分解\n",
    "    eigenvalues, eigenvectors = np.linalg.eigh(cov)\n",
    "    # 选择前两个主成分\n",
    "    idx = eigenvalues.argsort()[::-1]\n",
    "    top2_eigenvectors = eigenvectors[:, idx[:2]]\n",
    "    # 投影\n",
    "    return data_centered @ top2_eigenvectors\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 干净模型的激活分布\n",
    "all_act_clean = np.vstack([act_clean_on_clean, act_clean_on_triggered])\n",
    "pca_clean = simple_pca_2d(all_act_clean)\n",
    "n = len(X_clean)\n",
    "\n",
    "axes[0].scatter(pca_clean[:n, 0], pca_clean[:n, 1], c='blue', alpha=0.5, label='干净输入')\n",
    "axes[0].scatter(pca_clean[n:, 0], pca_clean[n:, 1], c='red', alpha=0.5, label='触发输入')\n",
    "axes[0].set_title('干净模型的激活分布')\n",
    "axes[0].set_xlabel('主成分1')\n",
    "axes[0].set_ylabel('主成分2')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# 后门模型的激活分布\n",
    "all_act_backdoor = np.vstack([act_backdoor_on_clean, act_backdoor_on_triggered])\n",
    "pca_backdoor = simple_pca_2d(all_act_backdoor)\n",
    "\n",
    "axes[1].scatter(pca_backdoor[:n, 0], pca_backdoor[:n, 1], c='blue', alpha=0.5, label='干净输入')\n",
    "axes[1].scatter(pca_backdoor[n:, 0], pca_backdoor[n:, 1], c='red', alpha=0.5, label='触发输入')\n",
    "axes[1].set_title('后门模型的激活分布')\n",
    "axes[1].set_xlabel('主成分1')\n",
    "axes[1].set_ylabel('主成分2')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.suptitle('激活聚类分析：寻找异常模式', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"观察：后门模型中，触发输入的激活分布与干净输入有明显分离！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第六步：实现简单的后门检测器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_backdoor(model, X_test, threshold=0.1):\n",
    "    \"\"\"\n",
    "    简单的后门检测方法\n",
    "    \n",
    "    思路：比较模型对原始输入和添加随机扰动后输入的激活差异\n",
    "    后门模型对触发器更敏感，激活差异更大\n",
    "    \"\"\"\n",
    "    # 获取原始激活\n",
    "    act_original = extract_activations(model, X_test)\n",
    "    \n",
    "    # 添加随机扰动（模拟可能的触发器位置）\n",
    "    X_perturbed = X_test.copy()\n",
    "    for i in range(len(X_perturbed)):\n",
    "        # 在中间位置添加扰动\n",
    "        X_perturbed[i, 3:5, 3:5] = np.random.rand(2, 2)\n",
    "    \n",
    "    act_perturbed = extract_activations(model, X_perturbed)\n",
    "    \n",
    "    # 【填空3】计算激活变化的标准差\n",
    "    # 提示：计算每个样本激活变化的范数，然后求标准差\n",
    "    # 参考答案：activation_change = np.std(np.linalg.norm(act_original - act_perturbed, axis=1))\n",
    "    activation_change = ___________________\n",
    "    \n",
    "    # 判断是否存在后门\n",
    "    is_backdoor = activation_change > threshold\n",
    "    \n",
    "    return is_backdoor, activation_change\n",
    "\n",
    "# 检测两个模型\n",
    "print(\"=\"*50)\n",
    "print(\"后门检测结果\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "is_backdoor_clean, score_clean = detect_backdoor(clean_model, X_test)\n",
    "is_backdoor_back, score_back = detect_backdoor(backdoor_model, X_test)\n",
    "\n",
    "print(f\"\\n干净模型:\")\n",
    "print(f\"  激活变化分数: {score_clean:.4f}\")\n",
    "print(f\"  检测结果: {'可能有后门 ⚠️' if is_backdoor_clean else '正常 ✓'}\")\n",
    "\n",
    "print(f\"\\n后门模型:\")\n",
    "print(f\"  激活变化分数: {score_back:.4f}\")\n",
    "print(f\"  检测结果: {'可能有后门 ⚠️' if is_backdoor_back else '正常 ✓'}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第七步：检测方法对比可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 分析每个神经元的激活模式\n",
    "def analyze_neuron_activation(model, X_clean, X_triggered):\n",
    "    \"\"\"分析神经元在干净输入和触发输入上的平均激活\"\"\"\n",
    "    act_clean = extract_activations(model, X_clean)\n",
    "    act_triggered = extract_activations(model, X_triggered)\n",
    "    \n",
    "    mean_clean = act_clean.mean(axis=0)\n",
    "    mean_triggered = act_triggered.mean(axis=0)\n",
    "    \n",
    "    return mean_clean, mean_triggered\n",
    "\n",
    "# 获取两个模型的神经元激活\n",
    "clean_act_c, clean_act_t = analyze_neuron_activation(clean_model, X_clean, X_triggered)\n",
    "back_act_c, back_act_t = analyze_neuron_activation(backdoor_model, X_clean, X_triggered)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# 干净模型\n",
    "x = np.arange(len(clean_act_c))\n",
    "width = 0.35\n",
    "axes[0].bar(x - width/2, clean_act_c, width, label='干净输入', color='blue', alpha=0.7)\n",
    "axes[0].bar(x + width/2, clean_act_t, width, label='触发输入', color='red', alpha=0.7)\n",
    "axes[0].set_xlabel('神经元编号')\n",
    "axes[0].set_ylabel('平均激活值')\n",
    "axes[0].set_title('干净模型：各神经元激活对比')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "# 后门模型\n",
    "axes[1].bar(x - width/2, back_act_c, width, label='干净输入', color='blue', alpha=0.7)\n",
    "axes[1].bar(x + width/2, back_act_t, width, label='触发输入', color='red', alpha=0.7)\n",
    "axes[1].set_xlabel('神经元编号')\n",
    "axes[1].set_ylabel('平均激活值')\n",
    "axes[1].set_title('后门模型：各神经元激活对比')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.suptitle('神经元激活分析', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"观察：后门模型中，某些神经元在触发输入时激活显著不同（可能是'后门神经元'）\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第八步：检测方法总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建检测方法对比表\n",
    "print(\"=\"*70)\n",
    "print(\"后门检测方法对比\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "methods = [\n",
    "    (\"激活聚类\", \"训练后\", \"训练数据\", \"中\", \"简单直观\"),\n",
    "    (\"Neural Cleanse\", \"训练后\", \"模型访问\", \"高\", \"可重建触发器\"),\n",
    "    (\"STRIP\", \"运行时\", \"输入样本\", \"中\", \"实时检测\"),\n",
    "]\n",
    "\n",
    "print(f\"{'方法':<15} {'检测时机':<10} {'需要的信息':<12} {'计算成本':<8} {'主要优势'}\")\n",
    "print(\"-\"*70)\n",
    "for m in methods:\n",
    "    print(f\"{m[0]:<15} {m[1]:<10} {m[2]:<12} {m[3]:<8} {m[4]}\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "print(\"\\n本实验使用的是简化版激活分析方法\")\n",
    "print(\"实际应用中需要更复杂的算法和更多的测试数据\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验总结\n",
    "\n",
    "### 关键发现\n",
    "\n",
    "1. **激活差异**：后门模型对触发输入和干净输入的激活有明显差异\n",
    "\n",
    "2. **聚类分离**：通过降维可视化，可以观察到后门导致的激活分离\n",
    "\n",
    "3. **神经元分析**：某些神经元在触发时激活异常，可能是\"后门神经元\"\n",
    "\n",
    "4. **检测挑战**：实际检测需要在不知道触发器的情况下进行\n",
    "\n",
    "### 防御建议\n",
    "\n",
    "1. **部署前审计**：使用 Neural Cleanse 等工具检测\n",
    "2. **运行时监控**：使用 STRIP 检测可疑输入\n",
    "3. **多方法组合**：高安全场景使用多种检测方法\n",
    "4. **供应链安全**：验证模型来源，使用安全格式（SafeTensors）\n",
    "\n",
    "### 思考问题\n",
    "\n",
    "1. 为什么后门模型的激活分布会出现分离？\n",
    "\n",
    "2. 如果攻击者知道你使用激活聚类检测，他能如何改进攻击？\n",
    "\n",
    "3. 除了检测，还有什么方法可以移除已植入的后门？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实验完成检查\n",
    "print(\"=\"*50)\n",
    "print(\"实验 5.3 完成！\")\n",
    "print(\"=\"*50)\n",
    "print(\"\\n请回答以下问题：\")\n",
    "print(\"1. 后门模型的激活变化分数是干净模型的多少倍？\")\n",
    "print(\"2. 从可视化图中，后门模型的激活分布有什么特点？\")\n",
    "print(\"3. 激活聚类方法的主要局限是什么？\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"恭喜完成模块五所有实验！\")\n",
    "print(\"=\"*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
