---
title: 第3章：模型逆向攻击
description: 探索如何从模型输出中重建训练数据特征
---


import { Callout } from 'fumadocs-ui/components/callout';
import { Tab, Tabs } from 'fumadocs-ui/components/tabs';
import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';


<Callout title="" type="info">
预计阅读约10分钟
</Callout>

## 本章导读

模型逆向攻击（Model Inversion Attack）是一种从模型输出中重建训练数据特征的攻击技术。

## 学习目标

<Callout title="本章学完后，你将能够：" type="info">
1. 理解模型逆向攻击的原理
2. 了解不同类型的逆向攻击
3. 认识攻击的隐私威胁
4. 掌握基本的防御思路
</Callout>

## 攻击原理

### 核心思想

模型的输出包含了关于训练数据的信息。通过优化过程，攻击者可以重建与训练数据相似的输入。

<Tabs items={['属性推断', '特征重建', '数据重建']}>
  <Tab value="属性推断">
    从模型输出推断训练数据的敏感属性
    
    **示例**：从人脸识别模型推断某人的种族、年龄等信息
  </Tab>
  <Tab value="特征重建">
    重建训练数据的统计特征
    
    **示例**：推断某类别训练样本的平均特征向量
  </Tab>
  <Tab value="数据重建">
    直接重建训练数据的具体内容
    
    **示例**：从模型中重建训练用的人脸图像
  </Tab>
</Tabs>

## 攻击方法

### 基于梯度的重建

通过优化以下目标函数重建输入：

```
min_x Loss(f(x), target) + λ * Regularization(x)
```

其中：
- `f(x)` 是模型输出
- `target` 是目标类别
- `Regularization` 确保重建结果的合理性

### 基于生成模型的重建

使用预训练的生成模型（如 GAN）来限制搜索空间，生成更真实的重建结果。

## 隐私威胁

<Callout title="严重隐私风险" type="error">
模型逆向攻击可能：
- 重建训练用的人脸图像
- 推断医疗诊断模型的患者信息
- 暴露机密训练数据的特征
</Callout>

## 本章小结

1. 模型逆向攻击从模型输出重建训练数据特征
2. 攻击方法包括梯度优化和生成模型辅助
3. 对隐私敏感应用构成严重威胁


## 课后思考

<Accordions>
  <Accordion title="思考题1：人脸识别系统的风险">
    为什么人脸识别模型特别容易受到模型逆向攻击？应该采取哪些防护措施？
  </Accordion>
  <Accordion title="思考题2：属性推断 vs 数据重建">
    属性推断和数据重建这两种攻击方式有什么本质区别？哪种威胁更大？
  </Accordion>
  <Accordion title="思考题3：生成模型的作用">
    为什么基于生成模型（如 GAN）的重建方法通常比纯梯度优化效果更好？
  </Accordion>
</Accordions>

## 延伸阅读

- [Model Inversion Attacks (CCS 2015 PDF)](https://www.cs.cmu.edu/~mfredrik/papers/fjr2015ccs.pdf)
- [CMU News: Model Inversion Test-of-Time Award](https://www.cs.cmu.edu/news/2025/fredrikson-test-of-time-award)
