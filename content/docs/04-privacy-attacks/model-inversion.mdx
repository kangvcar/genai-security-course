---
title: 第3章：模型逆向攻击
description: 探索如何从模型输出中重建训练数据特征
---

import { Callout } from 'fumadocs-ui/components/callout';
import { Tab, Tabs } from 'fumadocs-ui/components/tabs';

模型逆向攻击（Model Inversion Attack）是一种从模型输出中重建训练数据特征的攻击技术。

## 章节目标

<Callout title="学完本章后，你将能够：" type="info">
1. 理解模型逆向攻击的原理
2. 了解不同类型的逆向攻击
3. 认识攻击的隐私威胁
4. 掌握基本的防御思路
</Callout>

## 攻击原理

### 核心思想

模型的输出包含了关于训练数据的信息。通过优化过程，攻击者可以重建与训练数据相似的输入。

<Tabs items={['属性推断', '特征重建', '数据重建']}>
  <Tab value="属性推断">
    从模型输出推断训练数据的敏感属性
    
    **示例**：从人脸识别模型推断某人的种族、年龄等信息
  </Tab>
  <Tab value="特征重建">
    重建训练数据的统计特征
    
    **示例**：推断某类别训练样本的平均特征向量
  </Tab>
  <Tab value="数据重建">
    直接重建训练数据的具体内容
    
    **示例**：从模型中重建训练用的人脸图像
  </Tab>
</Tabs>

## 攻击方法

### 基于梯度的重建

通过优化以下目标函数重建输入：

```
min_x Loss(f(x), target) + λ * Regularization(x)
```

其中：
- `f(x)` 是模型输出
- `target` 是目标类别
- `Regularization` 确保重建结果的合理性

### 基于生成模型的重建

使用预训练的生成模型（如 GAN）来限制搜索空间，生成更真实的重建结果。

## 隐私威胁

<Callout title="严重隐私风险" type="error">
模型逆向攻击可能：
- 重建训练用的人脸图像
- 推断医疗诊断模型的患者信息
- 暴露机密训练数据的特征
</Callout>

## 本章小结

1. 模型逆向攻击从模型输出重建训练数据特征
2. 攻击方法包括梯度优化和生成模型辅助
3. 对隐私敏感应用构成严重威胁
