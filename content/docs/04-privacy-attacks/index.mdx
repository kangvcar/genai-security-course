---
title: 隐私攻击总览
description: 学习 AI 系统的隐私泄露风险和防护技术
icon: Eye
---

import { Cards, Card } from 'fumadocs-ui/components/card';
import { Callout } from 'fumadocs-ui/components/callout';

本模块将深入探讨 AI 系统面临的隐私安全威胁。通过本模块的学习，你将了解 AI 模型如何"记住"敏感信息，以及攻击者如何利用这些特性窃取隐私数据。

## 学习目标

<Callout title="完成本模块后，你将能够：" type="success">
- 理解 AI 模型的"记忆泄露"问题
- 掌握成员推理攻击的原理和实施方法
- 了解模型逆向攻击的技术细节
- 学习差分隐私等隐私保护技术
</Callout>

## 章节概览

<Cards>
  <Card title="第1章：AI 的记忆泄露问题" href="/docs/04-privacy-attacks/memory-leakage">
    理解 AI 模型如何"记住"训练数据中的敏感信息
  </Card>
  <Card title="第2章：成员推理攻击" href="/docs/04-privacy-attacks/membership-inference">
    学习如何判断特定数据是否被用于模型训练
  </Card>
  <Card title="第3章：模型逆向攻击" href="/docs/04-privacy-attacks/model-inversion">
    探索如何从模型输出中重建训练数据特征
  </Card>
  <Card title="第4章：差分隐私基础" href="/docs/04-privacy-attacks/differential-privacy">
    掌握差分隐私等隐私保护技术的基本原理
  </Card>
</Cards>

## 配套实验

<Cards>
  <Card title="实验 4.1：数据提取" href="/docs/04-privacy-attacks/labs/data-extraction">
    实践从模型中提取训练数据的技术
  </Card>
  <Card title="实验 4.2：成员推理" href="/docs/04-privacy-attacks/labs/membership-inference">
    实现成员推理攻击并分析结果
  </Card>
  <Card title="实验 4.3：差分隐私" href="/docs/04-privacy-attacks/labs/differential-privacy">
    应用差分隐私技术保护模型隐私
  </Card>
</Cards>
