{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": "# å®éªŒ 4.1ï¼šè®­ç»ƒæ•°æ®æå–æ”»å‡»\n\n## ğŸ¯ å­¦ä¹ ç›®æ ‡\n\nå®Œæˆæœ¬å®éªŒåï¼Œä½ å°†èƒ½å¤Ÿï¼š\n- âœ… è§£é‡Šè¯­è¨€æ¨¡å‹çš„\"è®°å¿†\"ç°è±¡ä¸è¿‡æ‹Ÿåˆçš„å…³ç³»\n- âœ… ç†è§£å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰ä½œä¸ºéšç§æ³„éœ²æŒ‡æ ‡çš„å«ä¹‰\n- âœ… å®ç°åŸºäºè¡¥å…¨çš„è®­ç»ƒæ•°æ®æå–æ”»å‡»\n- âœ… åˆ†æä¸åŒæç¤ºç­–ç•¥å¯¹æå–æ•ˆæœçš„å½±å“\n\n## ğŸ“š å‰ç½®çŸ¥è¯†\n\n- å¤§è¯­è¨€æ¨¡å‹çš„åŸºæœ¬å·¥ä½œåŸç†ï¼ˆè¾“å…¥ã€è¾“å‡ºã€æ¦‚ç‡åˆ†å¸ƒï¼‰\n- äº¤å‰ç†µæŸå¤±å’Œå›°æƒ‘åº¦çš„æ¦‚å¿µ\n- Python æ•°æ®å¤„ç†å’Œå¯è§†åŒ–åŸºç¡€\n\n## ğŸ–¥ï¸ å®éªŒç¯å¢ƒ\n\n| é¡¹ç›® | è¯´æ˜ |\n|------|------|\n| å¹³å° | è…¾è®¯ Cloud Studio |\n| GPU | NVIDIA Tesla T4ï¼ˆ16GBï¼‰|\n| æ¨¡å‹ | uer/gpt2-chinese-cluecorpussmallï¼ˆä¸­æ–‡ GPT-2ï¼‰|\n| ä¾èµ– | torch>=2.0, transformers>=4.30 |\n\n## â±ï¸ é¢„è®¡æ—¶é—´ï¼š30 åˆ†é’Ÿ\n\n## ğŸ“ å¡«ç©ºè¯´æ˜\n\næœ¬å®éªŒå…± **4 ä¸ªå¡«ç©º**ï¼Œéš¾åº¦ï¼šâ­â­â­â˜†â˜†\n\nâš ï¸ **å®‰å…¨æé†’**ï¼šæœ¬å®éªŒä»…ç”¨äºæ•™è‚²ç›®çš„ï¼Œæ¼”ç¤ºå¦‚ä½•é˜²æŠ¤æ¨¡å‹éšç§æ³„éœ²ã€‚è¯·å‹¿å°†æŠ€æœ¯ç”¨äºæœªæˆæƒç³»ç»Ÿã€‚"
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": "## ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒå‡†å¤‡ä¸æ¦‚å¿µå›é¡¾\n\n### æ ¸å¿ƒæ¦‚å¿µï¼šä»€ä¹ˆæ˜¯\"è®­ç»ƒæ•°æ®æå–\"ï¼Ÿ\n\n**ç±»æ¯”ç†è§£**ï¼š\n- ä½ èƒŒè¯µä¸€é¦–è¯—ï¼Œå½“åˆ«äººç»™ä½ \"åºŠå‰æ˜æœˆå…‰\"æ—¶ï¼Œä½ å¯èƒ½ä¼šè‡ªåŠ¨æ¥\"ç–‘æ˜¯åœ°ä¸Šéœœ\"\n- è¯­è¨€æ¨¡å‹ä¹Ÿæ˜¯å¦‚æ­¤â€”â€”è®­ç»ƒæ•°æ®ä¸­å‡ºç°è¿‡çš„å†…å®¹å¯èƒ½è¢«\"è®°ä½\"\n- æ”»å‡»è€…å¯ä»¥é€šè¿‡ç²¾å¿ƒè®¾è®¡çš„æç¤º\"è¯±å¯¼\"æ¨¡å‹è¾“å‡ºè¿™äº›è®°å¿†å†…å®¹\n\n**éšç§é£é™©**ï¼š\n- è®­ç»ƒæ•°æ®å¯èƒ½åŒ…å«ä¸ªäººä¿¡æ¯ï¼ˆé‚®ç®±ã€ç”µè¯ã€åœ°å€ã€å¯†ç ï¼‰\n- æ¨¡å‹å¯èƒ½æ— æ„ä¸­æ³„éœ²è¿™äº›æ•æ„Ÿä¿¡æ¯\n- ç ”ç©¶è¡¨æ˜å¤§å‹è¯­è¨€æ¨¡å‹å¯ä»¥é€å­—è®°ä½è®­ç»ƒé›†çš„éƒ¨åˆ†å†…å®¹\n\n### å…³é”®æŒ‡æ ‡ï¼šå›°æƒ‘åº¦ï¼ˆPerplexityï¼‰\n\nå›°æƒ‘åº¦è¡¡é‡æ¨¡å‹å¯¹æ–‡æœ¬çš„\"ç†Ÿæ‚‰\"ç¨‹åº¦ï¼š\n- **ä½å›°æƒ‘åº¦**ï¼šæ¨¡å‹å¾ˆç†Ÿæ‚‰ï¼ˆå¯èƒ½è§è¿‡/è®°ä½äº†ï¼‰\n- **é«˜å›°æƒ‘åº¦**ï¼šæ¨¡å‹ä¸ç†Ÿæ‚‰ï¼ˆéœ€è¦æ³›åŒ–èƒ½åŠ›ï¼‰\n\nè®¡ç®—å…¬å¼ï¼š`Perplexity = exp(äº¤å‰ç†µæŸå¤±)`"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": "### ç¬¬ä¸€æ­¥ï¼šå®‰è£…ä¾èµ–\n\n# æœ¬å®éªŒæ‰€éœ€ä¾èµ–\n!pip install torch>=2.0 transformers>=4.30 -q\n\n# éªŒè¯å®‰è£…\nimport torch\nimport transformers\nprint(f\"PyTorch: {torch.__version__}\")\nprint(f\"Transformers: {transformers.__version__}\")\nprint(\"âœ“ ä¾èµ–å®‰è£…æˆåŠŸï¼\")\n\n# å¯¼å…¥å…¶ä»–å¿…è¦åº“\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\n# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º\nplt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']\nplt.rcParams['axes.unicode_minus'] = False\n\nprint(\"\\nè®¾ç½®å®Œæˆï¼Œå‡†å¤‡åŠ è½½æ¨¡å‹...\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": "### ç¬¬äºŒæ­¥ï¼šåŠ è½½æ¨¡å‹\n\nprint(\"æ­£åœ¨åŠ è½½ä¸­æ–‡ GPT-2 æ¨¡å‹ï¼ˆçº¦ 350MBï¼‰...\")\nprint(\"â³ é¦–æ¬¡åŠ è½½å¯èƒ½éœ€è¦ 1-2 åˆ†é’Ÿ...\\n\")\n\n# ä½¿ç”¨ä¸­æ–‡ GPT-2 æ¨¡å‹\nmodel_name = \"uer/gpt2-chinese-cluecorpussmall\"\ntry:\n    tokenizer = AutoTokenizer.from_pretrained(model_name)\n    model = AutoModelForCausalLM.from_pretrained(model_name)\n    model.eval()\n    \n    # è®¾ç½® pad_token\n    if tokenizer.pad_token is None:\n        tokenizer.pad_token = tokenizer.eos_token\n    \n    print(\"=\" * 50)\n    print(\"âœ“ æ¨¡å‹åŠ è½½å®Œæˆï¼\")\n    print(\"=\" * 50)\n    print(f\"æ¨¡å‹å¤§å°ï¼š{model_name}\")\n    print(f\"è¯è¡¨å¤§å°ï¼š{len(tokenizer)} tokens\")\n    print(f\"æ¨¡å‹å‚æ•°é‡ï¼šçº¦ 1.3B\")\n    \nexcept Exception as e:\n    print(f\"âŒ æ¨¡å‹åŠ è½½å¤±è´¥ï¼š{e}\")\n    print(\"è¯·æ£€æŸ¥ç½‘ç»œè¿æ¥æˆ–ç¨åé‡è¯•\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-4",
   "metadata": {},
   "source": "### âœ… æ£€æŸ¥ç‚¹\n\nè¿è¡Œåˆ°è¿™é‡Œï¼Œä½ åº”è¯¥çœ‹åˆ°ï¼š\n- [x] ä¾èµ–å®‰è£…æˆåŠŸï¼Œæ˜¾ç¤º PyTorch å’Œ Transformers ç‰ˆæœ¬\n- [x] æ¨¡å‹åŠ è½½å®Œæˆï¼Œæ— é”™è¯¯æç¤º\n- [x] æ˜¾ç¤ºæ¨¡å‹åŸºæœ¬ä¿¡æ¯ï¼ˆå‚æ•°é‡çº¦ 1.3Bï¼‰\n\nå¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š\n- æ˜¯å¦é€‰æ‹©äº† GPU ç¯å¢ƒ\n- ç½‘ç»œæ˜¯å¦èƒ½è®¿é—® Hugging Face"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": "### ç¬¬ä¸‰æ­¥ï¼šå®šä¹‰æ–‡æœ¬ç”Ÿæˆå‡½æ•°\n\ndef generate_text(prompt, max_length=50, num_return=1, temperature=1.0):\n    \"\"\"\n    æ ¹æ®æç¤ºç”Ÿæˆæ–‡æœ¬\n    \n    å‚æ•°:\n        prompt: è¾“å…¥æç¤ºæ–‡æœ¬\n        max_length: æœ€å¤§ç”Ÿæˆé•¿åº¦ï¼ˆåŒ…æ‹¬è¾“å…¥ï¼‰\n        num_return: è¿”å›å‡ ä¸ªç”Ÿæˆç»“æœ\n        temperature: æ¸©åº¦å‚æ•°ï¼ˆè¶Šä½è¶Šç¡®å®šæ€§ï¼Œæ¨è 0.7-1.5ï¼‰\n    \n    è¿”å›:\n        ç”Ÿæˆæ–‡æœ¬åˆ—è¡¨\n    \"\"\"\n    # ç¼–ç è¾“å…¥\n    inputs = tokenizer.encode(prompt, return_tensors='pt')\n    \n    # ç”Ÿæˆæ–‡æœ¬\n    with torch.no_grad():\n        outputs = model.generate(\n            inputs,\n            max_length=max_length,\n            num_return_sequences=num_return,\n            temperature=temperature,\n            do_sample=True,             # å¯ç”¨é‡‡æ ·\n            top_p=0.9,                   # nucleusé‡‡æ ·\n            pad_token_id=tokenizer.pad_token_id\n        )\n    \n    # è§£ç è¾“å‡º\n    results = []\n    for output in outputs:\n        text = tokenizer.decode(output, skip_special_tokens=True)\n        results.append(text)\n    \n    return results\n\n\n# æµ‹è¯•ç”Ÿæˆå‡½æ•°\nprint(\"æµ‹è¯•æ–‡æœ¬ç”ŸæˆåŠŸèƒ½...\")\ntest_prompt = \"ä½ å¥½ï¼Œæˆ‘çš„åå­—æ˜¯\"\ntest_result = generate_text(test_prompt, max_length=30)\nprint(f\"\\nè¾“å…¥æç¤ºï¼š{test_prompt}\")\nprint(f\"æ¨¡å‹ç”Ÿæˆï¼š{test_result[0]}\")\nprint(\"\\nâœ“ æ–‡æœ¬ç”ŸæˆåŠŸèƒ½æ­£å¸¸ï¼\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": "## ç¬¬äºŒéƒ¨åˆ†ï¼šè®¡ç®—å›°æƒ‘åº¦ï¼ˆPerplexityï¼‰\n\n### ä»€ä¹ˆæ˜¯å›°æƒ‘åº¦ï¼Ÿ\n\nå›°æƒ‘åº¦æ˜¯è¡¡é‡æ¨¡å‹å¯¹æ–‡æœ¬\"ç†Ÿæ‚‰ç¨‹åº¦\"çš„æŒ‡æ ‡ï¼š\n\n| å›°æƒ‘åº¦èŒƒå›´ | å«ä¹‰ | å¯èƒ½åŸå›  |\n|-----------|------|---------|\n| < 10 | éå¸¸ç†Ÿæ‚‰ | è®­ç»ƒæ•°æ®ä¸­çš„é«˜é¢‘å†…å®¹ |\n| 10-50 | è¾ƒç†Ÿæ‚‰ | å¸¸è§æ¨¡å¼æˆ–ç±»ä¼¼å†…å®¹ |\n| 50-200 | ä¸€èˆ¬ | æ­£å¸¸æ³›åŒ–èƒ½åŠ› |\n| > 200 | ä¸ç†Ÿæ‚‰ | ç¨€æœ‰å†…å®¹æˆ–éšæœºæ–‡æœ¬ |\n\n**ç›´è§‰ç†è§£**ï¼šå¦‚æœæ¨¡å‹å¯¹æŸæ®µæ–‡æœ¬å›°æƒ‘åº¦å¾ˆä½ï¼Œè¯´æ˜å®ƒåœ¨è®­ç»ƒæ—¶å¯èƒ½\"è§è¿‡\"è¿™æ®µæ–‡æœ¬ï¼"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": "# ========== å¡«ç©º 1ï¼šå®ç°å›°æƒ‘åº¦è®¡ç®— ==========\n# \n# ğŸ¯ ä»»åŠ¡ï¼šå®Œæˆå›°æƒ‘åº¦è®¡ç®—å‡½æ•°\n# \n# ğŸ’¡ æç¤ºï¼š\n#   - å›°æƒ‘åº¦ = exp(å¹³å‡äº¤å‰ç†µæŸå¤±)\n#   - ä½¿ç”¨ np.exp() è®¡ç®—æŒ‡æ•°\n#   - å˜é‡ loss å·²ç»æ˜¯å¹³å‡æŸå¤±\n# \n# ğŸ“– å‚è€ƒï¼š\n#   Perplexity è¶Šä½ â†’ æ¨¡å‹å¯¹æ–‡æœ¬è¶Šç†Ÿæ‚‰\n# \n# è¯·å°† ___________ æ›¿æ¢ä¸ºæ­£ç¡®çš„ä»£ç \n\ndef calculate_perplexity(text):\n    \"\"\"\n    è®¡ç®—æ–‡æœ¬çš„å›°æƒ‘åº¦\n    \n    å‚æ•°:\n        text: è¦è®¡ç®—çš„æ–‡æœ¬å­—ç¬¦ä¸²\n    \n    è¿”å›:\n        å›°æƒ‘åº¦å€¼ï¼ˆfloatï¼‰\n    \"\"\"\n    # ç¼–ç æ–‡æœ¬\n    inputs = tokenizer.encode(text, return_tensors='pt')\n    \n    # è®¡ç®—æŸå¤±ï¼ˆlabels=inputs è¡¨ç¤ºè¯­è¨€å»ºæ¨¡ä»»åŠ¡ï¼‰\n    with torch.no_grad():\n        outputs = model(inputs, labels=inputs)\n        loss = outputs.loss.item()  # å¹³å‡äº¤å‰ç†µæŸå¤±\n    \n    # ========== å¡«ç©ºä½ç½® ==========\n    # è®¡ç®—å›°æƒ‘åº¦ï¼šperplexity = exp(loss)\n    perplexity = ___________  # æœŸæœ›ï¼šä½¿ç”¨ np.exp(loss)\n    \n    return perplexity\n\n\n# æµ‹è¯•å›°æƒ‘åº¦è®¡ç®—\ntest_texts = [\n    \"ä¸­åäººæ°‘å…±å’Œå›½æ˜¯ä¸€ä¸ªä¼Ÿå¤§çš„å›½å®¶ã€‚\",  # å¸¸è§å¥å­ï¼ˆå¯èƒ½ä½å›°æƒ‘åº¦ï¼‰\n    \"å•Šæ–¯è’‚èŠ¬åº“é‡Œå’–å–±å‘³é“çœŸå¥½åƒå‘€ã€‚\",    # éšæœºå†…å®¹ï¼ˆå¯èƒ½é«˜å›°æƒ‘åº¦ï¼‰\n]\n\nprint(\"å›°æƒ‘åº¦æµ‹è¯•ï¼š\")\nprint(\"=\" * 50)\nfor text in test_texts:\n    ppl = calculate_perplexity(text)\n    print(f\"æ–‡æœ¬ï¼š{text}\")\n    print(f\"å›°æƒ‘åº¦ï¼š{ppl:.2f}\\n\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": "### ğŸ¤” æ€è€ƒä¸€ä¸‹\n\n1. **è§‚å¯Ÿ**ï¼šå“ªä¸ªå¥å­çš„å›°æƒ‘åº¦æ›´ä½ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n2. **åˆ†æ**ï¼šå›°æƒ‘åº¦ä½æ„å‘³ç€ä»€ä¹ˆï¼Ÿè¿™ä¸æ¨¡å‹çš„è®­ç»ƒæœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿ"
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": "## ç¬¬ä¸‰éƒ¨åˆ†ï¼šåŸºäºè¡¥å…¨çš„æå–æ”»å‡»\n\n### æ”»å‡»åŸç†\n\n1. **è®¾è®¡è¯±å¯¼æ€§æç¤º**ï¼šä½¿ç”¨å¯èƒ½åœ¨è®­ç»ƒæ•°æ®ä¸­å‡ºç°çš„æ ¼å¼ï¼ˆå¦‚è”ç³»æ–¹å¼ã€åœ°å€ç­‰ï¼‰\n2. **ç”Ÿæˆå¤šä¸ªè¡¥å…¨**ï¼šè®©æ¨¡å‹äº§ç”Ÿå¤šä¸ªå¯èƒ½çš„ç»­æ–‡\n3. **è®¡ç®—å›°æƒ‘åº¦**ï¼šå›°æƒ‘åº¦ä½çš„è¡¥å…¨æ›´å¯èƒ½æ¥è‡ªè®­ç»ƒæ•°æ®\n4. **è¯„ä¼°éšç§æ³„éœ²**ï¼šæ±‡æ€»å¾—åˆ°å¯ç–‘çš„æ•æ„Ÿä¿¡æ¯\n\n### æ¼”ç¤ºï¼šè®¾è®¡æç¤º\n\n# ========== å¡«ç©º 2ï¼šè®¾è®¡æå–æç¤º ==========\n# \n# ğŸ¯ ä»»åŠ¡ï¼šé€‰æ‹©ä¸€ä¸ªå¯èƒ½è§¦å‘æ¨¡å‹è®°å¿†çš„æç¤º\n# \n# ğŸ’¡ æç¤ºï¼š\n#   - æ¨¡å‹å¯èƒ½ä¼š\"è®°ä½\"è®­ç»ƒæ•°æ®ä¸­å¸¸è§çš„æ¨¡æ¿\n#   - æ ¼å¼åŒ–å†…å®¹ï¼ˆå¦‚\"é‚®ç®±åœ°å€\"ã€\"ç”µè¯å·ç \"ï¼‰æ›´å®¹æ˜“è¢«è®°ä½\n#   - è‘—åæ–‡å­¦ä½œå“ï¼ˆå¦‚å¤è¯—è¯ï¼‰é€šå¸¸æœ‰ä½å›°æƒ‘åº¦\n# \n# éš¾åº¦ï¼šâ­â­â˜†â˜†â˜†\n# \n# è¯·é€‰æ‹©ä¸‹åˆ—é€‰é¡¹ä¸­çš„ä¸€ä¸ªæ›¿æ¢ ___________\n\n# ç¤ºä¾‹ï¼šä»¥ä¸‹æç¤ºå¯èƒ½è§¦å‘æ¨¡å‹è®°å¿†\nextraction_prompts = [\n    ___________,           # å¡«ç©º 2ï¼šé€‰æ‹©ä¸€ä¸ªæ–‡å­¦ä½œå“çš„å¼€å¤´\n    \"æˆ‘çš„ç”µè¯å·ç æ˜¯\",\n    \"é‚®ç®±åœ°å€æ˜¯\",\n    \"æˆ‘æœ€å–œæ¬¢çš„å¤è¯—æ˜¯\",\n]\n\nprint(\"è®¾è®¡çš„æå–æç¤ºï¼š\")\nprint(\"=\" * 50)\nfor i, prompt in enumerate(extraction_prompts):\n    if prompt:  # è·³è¿‡ç©ºçš„å¡«ç©º\n        print(f\"{i+1}. '{prompt}'\")\n    else:\n        print(f\"{i+1}. [å¾…å¡«ç©º]\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": "### æ‰§è¡Œæå–æ”»å‡»\n\nprint(\"å°è¯•æå–å¯èƒ½çš„è®­ç»ƒæ•°æ®...\")\nprint(\"=\" * 50)\n\nfor prompt in extraction_prompts:\n    if prompt:  # è·³è¿‡ç©ºçš„å¡«ç©º\n        print(f\"\\næç¤º: '{prompt}'\")\n        print(\"-\" * 50)\n        \n        # ç”Ÿæˆ 3 ä¸ªè¡¥å…¨ç»“æœ\n        completions = generate_text(prompt, max_length=40, num_return=3, temperature=0.7)\n        \n        for i, comp in enumerate(completions, 1):\n            # åªæ˜¾ç¤ºç”Ÿæˆçš„éƒ¨åˆ†\n            generated = comp[len(prompt):].strip()\n            \n            # è®¡ç®—å›°æƒ‘åº¦\n            ppl = calculate_perplexity(comp)\n            \n            print(f\"  è¡¥å…¨ {i} [å›°æƒ‘åº¦={ppl:5.1f}]: {generated[:40]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": "## ç¬¬å››éƒ¨åˆ†ï¼šè®°å¿† vs æ³›åŒ–åˆ†æ\n\n### å®éªŒè®¾è®¡\n\næˆ‘ä»¬å°†æ¯”è¾ƒä¸¤ç±»æ–‡æœ¬çš„å›°æƒ‘åº¦ï¼š\n1. **å¯èƒ½è¢«\"è®°ä½\"çš„æ–‡æœ¬**ï¼šè‘—åæ–‡å­¦ä½œå“ã€å¸¸è¯†æ€§äº‹å®\n2. **éœ€è¦\"æ³›åŒ–\"çš„æ–‡æœ¬**ï¼šæ–°åˆ›ä½œçš„ã€ä¸å¤ªå¯èƒ½å‡ºç°åœ¨è®­ç»ƒé›†ä¸­çš„å†…å®¹\n\n# ========== å¡«ç©º 3ï¼šå¯¹æ¯”ä¸¤ç±»æ–‡æœ¬ ==========\n# \n# ğŸ¯ ä»»åŠ¡ï¼šè®¡ç®—\"è®°å¿†\"æ–‡æœ¬çš„å›°æƒ‘åº¦åˆ—è¡¨\n# \n# ğŸ’¡ æç¤ºï¼š\n#   - ä½¿ç”¨åˆ—è¡¨æ¨å¯¼å¼ [function(item) for item in list]\n#   - å¯¹ memorized_texts ä¸­çš„æ¯ä¸ªæ–‡æœ¬è°ƒç”¨ calculate_perplexity\n#   - å‚è€ƒï¼š[calculate_perplexity(t) for t in memorized_texts]\n# \n# éš¾åº¦ï¼šâ­â­â˜†â˜†â˜†\n\n# å¯èƒ½è¢«\"è®°ä½\"çš„è‘—åæ–‡æœ¬\nmemorized_texts = [\n    \"åºŠå‰æ˜æœˆå…‰ï¼Œç–‘æ˜¯åœ°ä¸Šéœœã€‚\",  # æç™½ - é™å¤œæ€\n    \"ä¸­åäººæ°‘å…±å’Œå›½æˆç«‹äºä¸€ä¹å››ä¹å¹´ã€‚\",  # å†å²å¸¸è¯†\n    \"åŒ—äº¬æ˜¯ä¸­å›½çš„é¦–éƒ½ã€‚\",  # åœ°ç†å¸¸è¯†\n]\n\n# æ–°åˆ›ä½œçš„ã€ä¸å¤ªå¯èƒ½åœ¨è®­ç»ƒé›†ä¸­çš„æ–‡æœ¬\nnovel_texts = [\n    \"ç´«è‰²çš„å¤§è±¡åœ¨å½©è™¹æ¡¥ä¸Šè·³èˆã€‚\",\n    \"æˆ‘æœ€å–œæ¬¢çš„æ—©é¤æ˜¯é‡å­ç‰©ç†é…åå¸ã€‚\",\n    \"é‚£ä¸ªæœºå™¨äººå†³å®šæˆä¸ºä¸€åä¸“ä¸šçš„äº‘å½©ç”»å®¶ã€‚\",\n]\n\nprint(\"è®°å¿† vs æ³›åŒ– - å›°æƒ‘åº¦å¯¹æ¯”\")\nprint(\"=\" * 50)\n\n# ========== å¡«ç©ºä½ç½® ==========\n# è®¡ç®—\"è®°å¿†\"æ–‡æœ¬çš„å›°æƒ‘åº¦\nmem_ppls = ___________  # æœŸæœ›ï¼š[calculate_perplexity(t) for t in memorized_texts]\n\n# è®¡ç®—\"æ³›åŒ–\"æ–‡æœ¬çš„å›°æƒ‘åº¦\nnov_ppls = [calculate_perplexity(t) for t in novel_texts]\n\nprint(\"\\nè‘—åæ–‡æœ¬ï¼ˆå¯èƒ½è¢«è®°å¿†ï¼‰ï¼š\")\nfor text, ppl in zip(memorized_texts, mem_ppls):\n    print(f\"  å›°æƒ‘åº¦ {ppl:6.2f}: {text[:25]}...\")\n\nprint(\"\\næ–°åˆ›æ–‡æœ¬ï¼ˆéœ€è¦æ³›åŒ–ï¼‰ï¼š\")\nfor text, ppl in zip(novel_texts, nov_ppls):\n    print(f\"  å›°æƒ‘åº¦ {ppl:6.2f}: {text[:25]}...\")\n\nprint(f\"\\nå¹³å‡å›°æƒ‘åº¦å¯¹æ¯”ï¼š\")\nprint(f\"  è‘—åæ–‡æœ¬: {np.mean(mem_ppls):.2f}\")\nprint(f\"  æ–°åˆ›æ–‡æœ¬: {np.mean(nov_ppls):.2f}\")\nprint(f\"  å·®å¼‚: {np.mean(nov_ppls) - np.mean(mem_ppls):.2f}\")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": "# å¯è§†åŒ–å¯¹æ¯”\nplt.figure(figsize=(10, 5))\n\nx = np.arange(3)\nwidth = 0.35\n\nplt.bar(x - width/2, mem_ppls, width, label='è‘—åæ–‡æœ¬ï¼ˆå¯èƒ½è¢«è®°å¿†ï¼‰', color='#FF6B6B', alpha=0.8)\nplt.bar(x + width/2, nov_ppls, width, label='æ–°åˆ›æ–‡æœ¬ï¼ˆéœ€è¦æ³›åŒ–ï¼‰', color='#4ECDC4', alpha=0.8)\n\nplt.xlabel('æ ·æœ¬å·', fontsize=11, fontweight='bold')\nplt.ylabel('å›°æƒ‘åº¦', fontsize=11, fontweight='bold')\nplt.title('è®°å¿† vs æ³›åŒ–ï¼šå›°æƒ‘åº¦å¯¹æ¯”\\nï¼ˆä½å›°æƒ‘åº¦ = æ¨¡å‹æ›´\"ç†Ÿæ‚‰\"ï¼‰', fontsize=13, fontweight='bold')\nplt.xticks(x, ['æ ·æœ¬1', 'æ ·æœ¬2', 'æ ·æœ¬3'])\nplt.legend(fontsize=10)\nplt.grid(axis='y', alpha=0.3)\nplt.tight_layout()\nplt.show()\n\nprint(\"\\nğŸ” å…³é”®è§‚å¯Ÿï¼š\")\nprint(f\"  è‘—åæ–‡æœ¬å›°æƒ‘åº¦é€šå¸¸è¾ƒä½ï¼ˆ< 20ï¼‰ï¼Œè¯´æ˜æ¨¡å‹å¾ˆ\"ç†Ÿæ‚‰\"\")\nprint(f\"  æ–°åˆ›æ–‡æœ¬å›°æƒ‘åº¦é€šå¸¸è¾ƒé«˜ï¼ˆ> 50ï¼‰ï¼Œè¯´æ˜æ¨¡å‹éœ€è¦\"æ³›åŒ–\"\")\nprint(f\"\\nğŸ’¡ å«ä¹‰ï¼š\")\nprint(f\"  è¿™ç§å›°æƒ‘åº¦å·®å¼‚å¯èƒ½è¢«ç”¨äºè¯†åˆ«è®­ç»ƒæ•°æ®ä¸­çš„å†…å®¹ï¼\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": "## ç¬¬äº”éƒ¨åˆ†ï¼šæ¸©åº¦å‚æ•°å¯¹æå–çš„å½±å“\n\n### æ¸©åº¦å‚æ•°çš„ä½œç”¨\n\næ¸©åº¦ï¼ˆTemperatureï¼‰æ§åˆ¶ç”Ÿæˆçš„éšæœºæ€§ï¼š\n- **ä½æ¸©åº¦ï¼ˆ0.3-0.7ï¼‰**ï¼šæ›´ç¡®å®šæ€§ï¼Œå€¾å‘äºè¾“å‡ºé«˜æ¦‚ç‡å†…å®¹ï¼ˆå¯èƒ½æ˜¯è®°å¿†ï¼‰\n- **é«˜æ¸©åº¦ï¼ˆ1.0-1.5ï¼‰**ï¼šæ›´éšæœºï¼Œè¾“å‡ºæ›´å¤šæ ·åŒ–\n\n**éšç§å«ä¹‰**ï¼šä½æ¸©åº¦å¯èƒ½æ›´å®¹æ˜“æå–è®­ç»ƒæ•°æ®ï¼\n\n# ========== å¡«ç©º 4ï¼šæµ‹è¯•ä¸åŒæ¸©åº¦ ==========\n# \n# ğŸ¯ ä»»åŠ¡ï¼šè§‚å¯Ÿä¸åŒæ¸©åº¦å¯¹ç”Ÿæˆå†…å®¹çš„å½±å“\n# \n# ğŸ’¡ æç¤ºï¼š\n#   - temperature å‚æ•°åœ¨ generate_text å‡½æ•°ä¸­\n#   - å®Œæˆå¡«ç©º 2 åï¼Œextraction_prompts[0] å°±æ˜¯ä½ é€‰çš„æç¤º\n# \n# éš¾åº¦ï¼šâ­â˜†â˜†â˜†â˜†\n\n# é€‰æ‹©ä¸€ä¸ªæç¤ºè¿›è¡Œæµ‹è¯•\ntest_prompt = \"åºŠå‰æ˜æœˆå…‰ï¼Œ\"  # æˆ–ä½¿ç”¨ extraction_prompts[0]\n\n# æµ‹è¯•ä¸åŒæ¸©åº¦\ntemperatures = [0.5, 1.0, 1.5]\n\nprint(f\"æç¤º: '{test_prompt}'\")\nprint(\"=\" * 50)\nprint(\"ä¸åŒæ¸©åº¦çš„ç”Ÿæˆæ•ˆæœå¯¹æ¯”\")\nprint(\"=\" * 50)\n\nfor temp in temperatures:\n    print(f\"\\nğŸŒ¡ï¸ æ¸©åº¦ = {temp}:\")\n    print(\"-\" * 50)\n    \n    # ç”Ÿæˆ 3 ä¸ªè¡¥å…¨\n    completions = generate_text(test_prompt, max_length=40, num_return=3, temperature=temp)\n    \n    for i, comp in enumerate(completions, 1):\n        generated = comp[len(test_prompt):].strip()\n        ppl = calculate_perplexity(comp)\n        print(f\"  {i}. [å›°æƒ‘åº¦={ppl:5.1f}] {generated[:35]}\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": "print(\"\\nğŸ’¡ è§‚å¯Ÿï¼š\")\nprint(\"  ä½æ¸©åº¦ â†’ ç”Ÿæˆæ›´ä¸€è‡´ â†’ æ›´å¤šä½å›°æƒ‘åº¦å†…å®¹ â†’ æ›´å®¹æ˜“æå–è®­ç»ƒæ•°æ®\")\nprint(\"  é«˜æ¸©åº¦ â†’ ç”Ÿæˆæ›´å¤šæ · â†’ å›°æƒ‘åº¦æ³¢åŠ¨å¤§ â†’ æå–éš¾åº¦å¢åŠ \")"
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": "## ğŸ“‹ å®éªŒå°ç»“\n\n### æ ¸å¿ƒæ”¶è·\n\n1. **æ¦‚å¿µç†è§£**ï¼š\n   - è¯­è¨€æ¨¡å‹å¯èƒ½ä¼š\"è®°ä½\"è®­ç»ƒæ•°æ®ä¸­çš„å†…å®¹\n   - å›°æƒ‘åº¦ä½ = æ¨¡å‹ç†Ÿæ‚‰ = å¯èƒ½æ˜¯è®­ç»ƒæ•°æ®\n\n2. **æŠ€èƒ½æŒæ¡**ï¼š\n   - èƒ½è®¡ç®—å›°æƒ‘åº¦è¯„ä¼°æ–‡æœ¬\"ç†Ÿæ‚‰ç¨‹åº¦\"\n   - èƒ½è®¾è®¡æç¤ºè¯±å¯¼æ¨¡å‹ç”Ÿæˆç‰¹å®šå†…å®¹\n   - èƒ½è¯†åˆ«å“ªäº›å†…å®¹æœ€å®¹æ˜“è¢«æå–\n\n3. **å®‰å…¨è®¤è¯†**ï¼š\n   - æ¨¡å‹éšç§æ³„éœ²æ˜¯çœŸå®çš„å®‰å…¨å¨èƒ\n   - æ”»å‡»è€…å¯é€šè¿‡åˆç†è®¾è®¡çš„æç¤ºæå–æ•æ„Ÿä¿¡æ¯\n   - é˜²å¾¡éœ€è¦ä»æ•°æ®æ¸…æ´—ã€è®­ç»ƒæ–¹æ³•å’Œè¾“å‡ºè¿‡æ»¤ç­‰å¤šæ–¹é¢å…¥æ‰‹\n\n### å…³é”®ä»£ç å›é¡¾\n\n```python\n# å›°æƒ‘åº¦è®¡ç®—ï¼ˆéšç§æ³„éœ²æŒ‡æ ‡ï¼‰\nperplexity = np.exp(loss)\n\n# åˆ—è¡¨æ¨å¯¼å¼ï¼ˆæ‰¹é‡è®¡ç®—ï¼‰\nppls = [calculate_perplexity(t) for t in texts]\n\n# æ¸©åº¦å‚æ•°å½±å“ç”Ÿæˆç¡®å®šæ€§ï¼ˆä½æ¸©â†’æ›´å®¹æ˜“æ³„éœ²è®°å¿†ï¼‰\ngenerate_text(prompt, temperature=0.7)\n```\n\n### ğŸ¤” æ€è€ƒä¸è®¨è®º\n\n1. **è§‚å¯Ÿ**ï¼šåœ¨å®éªŒä¸­ï¼Œå“ªç±»æç¤ºæœ€å®¹æ˜“è§¦å‘æ¨¡å‹çš„è®°å¿†ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n\n2. **åˆ†æ**ï¼šå›°æƒ‘åº¦ä¸è¿‡æ‹Ÿåˆæœ‰ä»€ä¹ˆå…³ç³»ï¼Ÿä¸€ä¸ªè¿‡æ‹Ÿåˆçš„æ¨¡å‹æ˜¯å¦æ›´å®¹æ˜“è¢«æå–æ”»å‡»ï¼Ÿ\n\n3. **åº”ç”¨**ï¼šå¦‚æœä½ æ˜¯æ¨¡å‹éƒ¨ç½²è€…ï¼Œå¦‚ä½•é˜²æ­¢ç±»ä¼¼æ”»å‡»ï¼Ÿ\n   - æ•°æ®é¢„å¤„ç†ï¼šç§»é™¤æ•æ„Ÿä¿¡æ¯\n   - è®­ç»ƒæ–¹æ³•ï¼šä½¿ç”¨å·®åˆ†éšç§ç­‰æŠ€æœ¯\n   - è¾“å‡ºè¿‡æ»¤ï¼šæ£€æµ‹å¹¶è¿‡æ»¤æ•æ„Ÿä¿¡æ¯æ ¼å¼\n\n4. **æ‰©å±•**ï¼šé™¤äº†å›°æƒ‘åº¦ï¼Œè¿˜æœ‰å…¶ä»–æŒ‡æ ‡å¯ä»¥ç”¨äºæ£€æµ‹éšç§æ³„éœ²å—ï¼Ÿ\n\n### å»¶ä¼¸é˜…è¯»\n\n- [è®ºæ–‡] Carlini et al. \"Extracting Training Data from Large Language Models\" (USENIX Security 2021)\n- [è¿›é˜¶å®éªŒ] å®éªŒ 4.2ï¼šæˆå‘˜æ¨ç†æ”»å‡» - åˆ¤æ–­æ ·æœ¬æ˜¯å¦åœ¨è®­ç»ƒé›†ä¸­\n- [é˜²å¾¡æ–¹æ³•] å®éªŒ 4.3ï¼šå·®åˆ†éšç§è®­ç»ƒ - ä½¿ç”¨å™ªå£°ä¿æŠ¤éšç§\n\n---\n\n## å‚è€ƒç­”æ¡ˆ\n\n<details>\n<summary>ç‚¹å‡»æŸ¥çœ‹å‚è€ƒç­”æ¡ˆ</summary>\n\n**å¡«ç©º 1**ï¼šå›°æƒ‘åº¦è®¡ç®—\n```python\nperplexity = np.exp(loss)\n```\n\n**å¡«ç©º 2**ï¼šé€‰æ‹©æå–æç¤ºï¼ˆç¤ºä¾‹ç­”æ¡ˆï¼Œå¯å¤šç§é€‰æ‹©ï¼‰\n```python\n\"åºŠå‰æ˜æœˆå…‰ï¼Œ\"  # æç™½çš„è¯—å¥\n# æˆ–\n\"ä»å‰æœ‰åº§å±±ï¼Œ\"  # æ°‘é—´æ•…äº‹å¼€å¤´\n```\n\n**å¡«ç©º 3**ï¼šè®¡ç®—å›°æƒ‘åº¦åˆ—è¡¨\n```python\nmem_ppls = [calculate_perplexity(t) for t in memorized_texts]\n```\n\n**å¡«ç©º 4**ï¼šæ¸©åº¦å‚æ•°ç†è§£ï¼ˆæ— éœ€å¡«ç©ºï¼Œè§‚å¯Ÿè¾“å‡ºå³å¯ï¼‰\n- ä½æ¸©åº¦ç”Ÿæˆæ›´ä¸€è‡´ï¼Œå›°æƒ‘åº¦é€šå¸¸æ›´ä½\n- é«˜æ¸©åº¦ç”Ÿæˆæ›´å¤šæ ·ï¼Œå›°æƒ‘åº¦æ³¢åŠ¨æ›´å¤§\n\n</details>"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}