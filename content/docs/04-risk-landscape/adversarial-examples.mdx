---
title: 第1章：对抗样本
description: 了解对抗样本的概念，通过文本对抗实例理解"微小修改、颠覆判断"的攻击原理
---

import { Callout } from 'fumadocs-ui/components/callout';
import { Tabs, Tab } from 'fumadocs-ui/components/tabs';
import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

<Callout title="" type="info">
预计阅读约12分钟
</Callout>

## 本章导读

在前面的模块中，我们学到的攻击——提示词注入、越狱——都是通过**改变指令**来影响模型行为。但还有一类完全不同的攻击方式：**不改变指令，只对输入数据做微小修改，就能让模型产生完全错误的判断**。

这就是对抗样本（Adversarial Examples）攻击。

本章将以概念理解为主，不涉及底层算法，帮助你建立对这类风险的基本认知。

## 学习目标

<Callout title="本章学完后，你将能够：" type="info">
1. **解释对抗样本的基本概念**：知道什么是对抗样本，为什么 AI 模型容易受到影响
2. **区分对抗样本的主要类型**：图像对抗与文本对抗的区别
3. **理解文本对抗攻击的常见方法**：字符替换、同义词替换、句法变换
4. **认识对抗样本的现实影响**：了解实际案例和潜在威胁
</Callout>

## 1 什么是对抗样本

### 1.1 一个直观的例子

假设有一个 AI 模型负责检测垃圾邮件。以下两封邮件内容几乎相同：

```text title="原始邮件（被正确识别为垃圾邮件）"
恭喜您获得免费 iPhone！立即点击领取：http://spam.example.com
```

```text title="修改后的邮件（逃过检测）"
恭喜您获得免費 iPhоne！立即点击领取：http://spam.example.com
```

你能看出区别吗？修改后的版本做了两个微小改动：

1. "免费" → "免費"（简体换繁体）
2. "iPhone" 中的 "o" → "о"（拉丁字母 o 换成西里尔字母 о）

这两个改动对人类来说几乎不可见，但对于逐字符处理的 AI 模型来说，可能完全改变了输入特征，导致检测失败。

**这就是对抗样本的核心思想：对输入做人类难以察觉的修改，使 AI 模型产生错误判断。**

### 1.2 为什么 AI 模型容易受影响

对抗样本之所以有效，根源在于 AI 模型和人类"看世界"的方式不同：

| 对比维度 | 人类 | AI 模型 |
|----------|------|---------|
| 识别方式 | 关注整体含义和上下文 | 关注具体的特征值和统计模式 |
| 容错能力 | 对微小变化不敏感（"免费" ≈ "免費"） | 对输入特征高度敏感 |
| 对抗鲁棒性 | 天然具备（人脑演化优势） | 需要专门训练才能获得 |

简单来说：人类理解"含义"，AI 模型匹配"模式"。当攻击者修改了模式但保留了含义，人类不受影响，但模型可能被欺骗。

### 1.3 对抗样本的正式定义

> 对抗样本是指：对原始输入施加微小的、人类难以察觉的扰动，使目标模型产生错误输出的特制输入。

三个关键要素：
1. **微小扰动**：修改要足够小，人类不容易发现
2. **有意为之**：不是随机噪声，而是精心设计的修改
3. **导致误判**：模型的输出从正确变为错误

## 2 图像对抗 vs 文本对抗

对抗样本最早在计算机视觉领域被发现，后来扩展到了自然语言处理领域。

### 2.1 图像对抗样本（了解即可）

2013 年，研究者发现在图像上添加人眼不可见的微小噪声，就能让图像分类模型产生严重错误。例如：

```text title="经典图像对抗案例"
原始图像：一只熊猫 → 模型判断：熊猫（置信度 57%）
                    ↓ 添加微小噪声
对抗图像：看起来仍然是熊猫 → 模型判断：长臂猿（置信度 99%）
```

这个案例震动了整个 AI 安全领域，因为它表明：即使是高精度的模型，也可能被精心设计的微小扰动完全欺骗。

<Callout title="本课程不深入图像对抗" type="warn">
图像对抗样本的生成涉及梯度计算（如 FGSM、PGD 等算法），超出了本课程的入门定位。我们重点关注与 LLM 更相关的**文本对抗样本**。
</Callout>

### 2.2 文本对抗样本

文本领域的对抗攻击原理相同——对文本做微小修改来欺骗模型——但实现方式不同，因为文本是离散的（一个字要么改了要么没改），而图像是连续的（像素值可以微调）。

文本对抗的常见方法包括：

**方法一：字符级扰动**

| 技术 | 示例 | 原理 |
|------|------|------|
| 形近字替换 | "免费" → "免費" | 利用形状相似的字符 |
| 同形异码字符 | "apple" → "аpple"（首字母换成西里尔字母 а） | Unicode 中存在外观相同但编码不同的字符 |
| 插入零宽字符 | "恶意" → "恶\u200b意" | 插入不可见字符 |
| 字符交换 | "dangerous" → "dangeruos" | 人类能自动纠错，模型可能不行 |

**方法二：词级扰动**

| 技术 | 示例 | 原理 |
|------|------|------|
| 同义词替换 | "这部电影太好看了" → "这部电影太精彩了" | 含义不变但特征改变 |
| 反义插入 | "产品质量不好" → "产品质量不是不好" | 双重否定让模型困惑 |

**方法三：句法级扰动**

| 技术 | 示例 | 原理 |
|------|------|------|
| 语序调整 | "我很喜欢这个产品" → "这个产品，我很喜欢" | 含义不变但句法结构改变 |
| 添加无关从句 | "产品很好" → "虽然下雨了，但产品很好" | 添加与判断无关的干扰信息 |

## 3 文本对抗的真实威胁

### 3.1 攻击场景举例

文本对抗样本在以下场景中可能造成实际威胁：

**场景一：绕过内容审核**

社交平台使用 AI 模型检测违规内容。攻击者通过字符替换（如用谐音字、特殊 Unicode 字符）来发布违规内容，逃过自动检测。

```text title="内容审核绕过"
原始违规内容：赌博网站 → 被AI检测到
修改后：赌 博 网 站（插入全角空格）→ 可能逃过检测
修改后：dǔ bó 网站（拼音替换）→ 可能逃过检测
```

**场景二：欺骗情感分析**

电商平台使用 AI 分析商品评价的情感倾向。攻击者可以通过文本扰动让负面评价被误判为正面。

**场景三：绕过恶意软件检测**

安全系统使用 AI 分析代码或文档中的恶意内容。攻击者通过变量名替换、注释插入等方式让恶意代码逃过检测。

### 3.2 与提示词注入的区别

学到这里，你可能会想：这和模块二的提示词注入有什么区别？

| 对比维度 | 提示词注入 | 对抗样本 |
|----------|-----------|---------|
| 攻击目标 | 改变模型的行为指令 | 改变模型的判断结果 |
| 攻击方式 | 插入新的指令 | 修改已有的数据 |
| 攻击对象 | 生成式 AI（聊天机器人等） | 判别式 AI（分类器等） |
| 修改幅度 | 通常添加较多文本 | 尽量做最小修改 |
| 人类感知 | 攻击内容通常可被人类识别 | 修改通常难以被人类察觉 |

简单来说：提示词注入是"说服"模型做别的事，对抗样本是"欺骗"模型看错了东西。

## 4 对抗样本的防御思路

虽然深入的防御技术超出本课程范围，但了解基本的防御思路有助于建立完整的安全认知：

**思路一：输入预处理**

在将输入送入模型之前，先进行清洗——去除零宽字符、统一 Unicode 编码、拼写纠错等。回忆模块三第2章的输入层防护，其中的"特殊字符清洗"就是这个思路的应用。

**思路二：对抗训练**

在训练过程中，故意用对抗样本来训练模型，让模型学会识别和抵抗扰动。这类似于让模型"打疫苗"。

**思路三：集成防御**

使用多个不同的模型同时判断，只有当多数模型达成一致时才接受结果。单个模型容易被欺骗，但同时欺骗多个模型就难得多。

## 本章小结

本章介绍了对抗样本这一重要的 AI 安全风险。

**核心概念**：对抗样本是对输入做微小的、人类难以察觉的修改，使 AI 模型产生错误判断。根源在于 AI 模型关注"模式"而非"含义"。

**文本对抗方法**：字符级扰动（形近字、同形异码、零宽字符）、词级扰动（同义词替换）、句法级扰动（语序调整、添加干扰信息）。

**与提示词注入的区别**：提示词注入改变指令，对抗样本修改数据；前者"说服"模型，后者"欺骗"模型。

在实验 4.1 中，你将亲手体验文本对抗攻击——通过各种文字修改技术来影响 Qwen 模型的判断。

## 课后思考

<Accordions>
  <Accordion title="思考题1：生活中的对抗样本">
    验证码（CAPTCHA）的设计理念与对抗样本有什么关系？提示：验证码故意对文字做扭曲、加噪声，是为了让 AI 难以识别但人类能识别。
  </Accordion>
  <Accordion title="思考题2：防御的困境">
    如果一个社交平台同时使用关键词过滤和 AI 语义分析来检测违规内容，攻击者可能如何结合本章学到的文本对抗技术和模块二学到的绕过技术来规避检测？
  </Accordion>
</Accordions>

## 延伸阅读

- [TextFooler：文本对抗样本生成工具](https://github.com/jind11/TextFooler)
- [OpenAttack：开源文本对抗攻击工具包](https://github.com/thunlp/OpenAttack)
