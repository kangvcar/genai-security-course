{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 实验 3.2：PGD 迭代攻击\n",
    "\n",
    "## 实验目标\n",
    "- 理解 PGD（投影梯度下降）的迭代攻击原理\n",
    "- 对比 FGSM 和 PGD 的攻击效果\n",
    "- 观察迭代次数对攻击成功率的影响\n",
    "\n",
    "## 实验环境\n",
    "- Python 3.8+\n",
    "- PyTorch\n",
    "- torchvision\n",
    "\n",
    "## 预计时间：25 分钟\n",
    "\n",
    "---\n",
    "\n",
    "## 核心概念回顾\n",
    "PGD 是 FGSM 的迭代增强版：\n",
    "- FGSM：一步到位，快但不够精确\n",
    "- PGD：多次小步调整，更强但更慢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一部分：环境准备"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 加载预训练模型\n",
    "print(\"正在加载模型...\")\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()\n",
    "print(\"模型加载完成！\")\n",
    "\n",
    "# 标准化参数\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建测试图片（与实验3.1相同）\n",
    "def create_test_image():\n",
    "    np.random.seed(42)\n",
    "    img = np.random.rand(224, 224, 3) * 0.3 + 0.35\n",
    "    center_x, center_y = 112, 112\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            dist = np.sqrt((i - center_x)**2 + (j - center_y)**2)\n",
    "            if dist < 60:\n",
    "                img[i, j] = [0.1, 0.1, 0.1]\n",
    "            elif dist < 80:\n",
    "                img[i, j] = [0.9, 0.9, 0.9]\n",
    "    return torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)\n",
    "\n",
    "def predict(model, img_tensor):\n",
    "    input_tensor = normalize(img_tensor).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    pred_class = output.argmax(dim=1).item()\n",
    "    confidence = probs[0, pred_class].item()\n",
    "    return pred_class, confidence\n",
    "\n",
    "# 创建并预测原始图片\n",
    "original_image = create_test_image()\n",
    "original_class, original_conf = predict(model, original_image)\n",
    "print(f\"原始预测：类别 {original_class}，置信度：{original_conf:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二部分：实现 PGD 攻击"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 【填空 1】实现 PGD 攻击的核心函数\n",
    "# 提示：PGD = 多次 FGSM + 投影（确保扰动不超过 epsilon）\n",
    "\n",
    "def pgd_attack(model, image, label, epsilon, alpha, num_steps):\n",
    "    \"\"\"\n",
    "    PGD 攻击\n",
    "    \n",
    "    参数：\n",
    "        model: 目标模型\n",
    "        image: 原始图片张量 [C, H, W]\n",
    "        label: 原始标签\n",
    "        epsilon: 最大扰动范围\n",
    "        alpha: 每步的步长\n",
    "        num_steps: 迭代次数\n",
    "    \n",
    "    返回：\n",
    "        对抗样本张量\n",
    "    \"\"\"\n",
    "    # 初始化：从原图开始（也可以加随机噪声）\n",
    "    adv_image = image.clone().unsqueeze(0)\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        adv_image.requires_grad = True\n",
    "        \n",
    "        # 前向传播\n",
    "        normalized = normalize(adv_image.squeeze(0)).unsqueeze(0)\n",
    "        output = model(normalized)\n",
    "        \n",
    "        # 计算损失\n",
    "        loss = nn.CrossEntropyLoss()(output, torch.tensor([label]))\n",
    "        \n",
    "        # 反向传播\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        # 获取梯度\n",
    "        gradient = adv_image.grad.data\n",
    "        \n",
    "        # 【填空 1】沿梯度方向走一小步（步长为 alpha）\n",
    "        # 提示：adv_image = adv_image + alpha * gradient.sign()\n",
    "        # 参考答案：adv_image = adv_image.detach() + alpha * gradient.sign()\n",
    "        adv_image = ___________________\n",
    "        \n",
    "        # 投影：确保扰动在 [-epsilon, epsilon] 范围内\n",
    "        perturbation = adv_image - image.unsqueeze(0)\n",
    "        perturbation = torch.clamp(perturbation, -epsilon, epsilon)\n",
    "        adv_image = image.unsqueeze(0) + perturbation\n",
    "        \n",
    "        # 确保像素值在 [0, 1] 范围内\n",
    "        adv_image = torch.clamp(adv_image, 0, 1)\n",
    "    \n",
    "    return adv_image.squeeze(0).detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现 FGSM 用于对比\n",
    "def fgsm_attack(model, image, label, epsilon):\n",
    "    image_copy = image.clone().unsqueeze(0)\n",
    "    image_copy.requires_grad = True\n",
    "    \n",
    "    normalized = normalize(image_copy.squeeze(0)).unsqueeze(0)\n",
    "    output = model(normalized)\n",
    "    loss = nn.CrossEntropyLoss()(output, torch.tensor([label]))\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    gradient = image_copy.grad.data\n",
    "    perturbation = epsilon * gradient.sign()\n",
    "    adversarial_image = torch.clamp(image_copy + perturbation, 0, 1)\n",
    "    \n",
    "    return adversarial_image.squeeze(0).detach()\n",
    "\n",
    "print(\"攻击函数定义完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三部分：对比 FGSM 和 PGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 【填空 2】执行 PGD 攻击并对比 FGSM\n",
    "# 提示：使用相同的 epsilon，观察两种方法的效果差异\n",
    "\n",
    "epsilon = 0.03   # 最大扰动\n",
    "alpha = 0.01     # 每步步长\n",
    "num_steps = 10   # 迭代次数\n",
    "\n",
    "# FGSM 攻击\n",
    "fgsm_adv = fgsm_attack(model, original_image, original_class, epsilon)\n",
    "fgsm_pred, fgsm_conf = predict(model, fgsm_adv)\n",
    "\n",
    "# 【填空 2】执行 PGD 攻击\n",
    "# 参考答案：pgd_adv = pgd_attack(model, original_image, original_class, epsilon, alpha, num_steps)\n",
    "pgd_adv = ___________________\n",
    "pgd_pred, pgd_conf = predict(model, pgd_adv)\n",
    "\n",
    "print(\"攻击效果对比：\")\n",
    "print(f\"原始：类别 {original_class}，置信度 {original_conf:.2%}\")\n",
    "print(f\"FGSM：类别 {fgsm_pred}，置信度 {fgsm_conf:.2%}，{'成功' if fgsm_pred != original_class else '失败'}\")\n",
    "print(f\"PGD： 类别 {pgd_pred}，置信度 {pgd_conf:.2%}，{'成功' if pgd_pred != original_class else '失败'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化对比\n",
    "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
    "\n",
    "# 原始图片\n",
    "axes[0].imshow(original_image.permute(1, 2, 0).numpy())\n",
    "axes[0].set_title(f\"原始图片\\n类别{original_class} ({original_conf:.1%})\")\n",
    "axes[0].axis('off')\n",
    "\n",
    "# FGSM 对抗样本\n",
    "axes[1].imshow(fgsm_adv.permute(1, 2, 0).numpy())\n",
    "color = 'red' if fgsm_pred != original_class else 'black'\n",
    "axes[1].set_title(f\"FGSM (1步)\\n类别{fgsm_pred} ({fgsm_conf:.1%})\", color=color)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# PGD 对抗样本\n",
    "axes[2].imshow(pgd_adv.permute(1, 2, 0).numpy())\n",
    "color = 'red' if pgd_pred != original_class else 'black'\n",
    "axes[2].set_title(f\"PGD ({num_steps}步)\\n类别{pgd_pred} ({pgd_conf:.1%})\", color=color)\n",
    "axes[2].axis('off')\n",
    "\n",
    "# 扰动对比\n",
    "fgsm_perturb = (fgsm_adv - original_image).abs().mean(dim=0)\n",
    "pgd_perturb = (pgd_adv - original_image).abs().mean(dim=0)\n",
    "axes[3].bar(['FGSM', 'PGD'], [fgsm_perturb.mean().item(), pgd_perturb.mean().item()])\n",
    "axes[3].set_title('平均扰动大小')\n",
    "axes[3].set_ylabel('扰动值')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第四部分：迭代次数的影响"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 【填空 3】测试不同迭代次数的攻击效果\n",
    "# 提示：增加迭代次数通常会提高攻击成功率\n",
    "\n",
    "step_values = [1, 3, 5, 10, 20, 40]\n",
    "epsilon = 0.03\n",
    "alpha = 0.01\n",
    "\n",
    "print(\"迭代次数对攻击效果的影响：\\n\")\n",
    "print(f\"{'迭代次数':<10} {'预测类别':<12} {'置信度':<12} {'原类别置信度':<15} {'攻击结果'}\")\n",
    "print(\"-\" * 65)\n",
    "\n",
    "results = []\n",
    "for steps in step_values:\n",
    "    # 【填空 3】对每个迭代次数执行 PGD 攻击\n",
    "    # 参考答案：adv = pgd_attack(model, original_image, original_class, epsilon, alpha, steps)\n",
    "    adv = ___________________\n",
    "    pred, conf = predict(model, adv)\n",
    "    \n",
    "    # 计算原类别的置信度下降\n",
    "    with torch.no_grad():\n",
    "        output = model(normalize(adv).unsqueeze(0))\n",
    "        probs = torch.softmax(output, dim=1)\n",
    "        orig_class_conf = probs[0, original_class].item()\n",
    "    \n",
    "    success = \"✓\" if pred != original_class else \"✗\"\n",
    "    results.append((steps, pred, conf, orig_class_conf))\n",
    "    print(f\"{steps:<10} {pred:<12} {conf:<12.2%} {orig_class_conf:<15.2%} {success}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化迭代次数的影响\n",
    "steps_list = [r[0] for r in results]\n",
    "orig_conf_list = [r[3] for r in results]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(steps_list, orig_conf_list, 'bo-', linewidth=2, markersize=8)\n",
    "plt.xlabel('迭代次数')\n",
    "plt.ylabel('原类别置信度')\n",
    "plt.title('迭代次数 vs 原类别置信度')\n",
    "plt.axhline(y=0.5, color='r', linestyle='--', label='50% 阈值')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# 显示不同迭代次数的图片\n",
    "plt.subplot(1, 2, 2)\n",
    "selected_steps = [1, 10, 40]\n",
    "for i, steps in enumerate(selected_steps):\n",
    "    adv = pgd_attack(model, original_image, original_class, epsilon, alpha, steps)\n",
    "    plt.subplot(2, 3, 4 + i)\n",
    "    plt.imshow(adv.permute(1, 2, 0).numpy())\n",
    "    pred, conf = predict(model, adv)\n",
    "    plt.title(f\"{steps}步\\n类别{pred}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第五部分：PGD 攻击过程可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化 PGD 的迭代过程\n",
    "def pgd_attack_with_history(model, image, label, epsilon, alpha, num_steps):\n",
    "    \"\"\"记录每一步的中间结果\"\"\"\n",
    "    history = []\n",
    "    adv_image = image.clone().unsqueeze(0)\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        adv_image.requires_grad = True\n",
    "        normalized = normalize(adv_image.squeeze(0)).unsqueeze(0)\n",
    "        output = model(normalized)\n",
    "        loss = nn.CrossEntropyLoss()(output, torch.tensor([label]))\n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        gradient = adv_image.grad.data\n",
    "        adv_image = adv_image.detach() + alpha * gradient.sign()\n",
    "        \n",
    "        perturbation = adv_image - image.unsqueeze(0)\n",
    "        perturbation = torch.clamp(perturbation, -epsilon, epsilon)\n",
    "        adv_image = torch.clamp(image.unsqueeze(0) + perturbation, 0, 1)\n",
    "        \n",
    "        # 记录当前状态\n",
    "        pred, conf = predict(model, adv_image.squeeze(0))\n",
    "        with torch.no_grad():\n",
    "            out = model(normalize(adv_image.squeeze(0)).unsqueeze(0))\n",
    "            probs = torch.softmax(out, dim=1)\n",
    "            orig_conf = probs[0, label].item()\n",
    "        history.append((step + 1, pred, conf, orig_conf))\n",
    "    \n",
    "    return adv_image.squeeze(0).detach(), history\n",
    "\n",
    "# 执行并可视化\n",
    "_, history = pgd_attack_with_history(model, original_image, original_class, 0.03, 0.01, 20)\n",
    "\n",
    "steps = [h[0] for h in history]\n",
    "orig_confs = [h[3] for h in history]\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "plt.plot(steps, orig_confs, 'b-o', label='原类别置信度')\n",
    "plt.axhline(y=original_conf, color='g', linestyle='--', label=f'初始置信度 ({original_conf:.1%})')\n",
    "plt.xlabel('迭代步数')\n",
    "plt.ylabel('置信度')\n",
    "plt.title('PGD 攻击过程：原类别置信度变化')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n经过 20 步迭代：\")\n",
    "print(f\"原类别置信度：{original_conf:.2%} → {orig_confs[-1]:.2%}\")\n",
    "print(f\"置信度下降：{(original_conf - orig_confs[-1]):.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 实验总结\n",
    "\n",
    "### 观察记录\n",
    "\n",
    "请回答以下问题：\n",
    "\n",
    "1. **PGD 比 FGSM 更强吗？** 在相同 ε 下，哪种方法的攻击效果更好？\n",
    "\n",
    "2. **迭代次数越多越好吗？** 观察置信度变化曲线，收益是否会递减？\n",
    "\n",
    "3. **PGD 的代价是什么？** 考虑计算时间和攻击效果的权衡。\n",
    "\n",
    "### 核心概念回顾\n",
    "\n",
    "- **PGD vs FGSM**：多步迭代 vs 一步到位\n",
    "- **投影操作**：确保扰动不超过限制\n",
    "- **参数选择**：ε（总范围）、α（步长）、N（步数）\n",
    "\n",
    "---\n",
    "\n",
    "**下一个实验**：实验 3.3 黑盒迁移攻击"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
