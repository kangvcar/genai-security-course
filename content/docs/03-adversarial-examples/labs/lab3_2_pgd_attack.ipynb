{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 实验 3.2：PGD 迭代对抗攻击\n\n## 🎯 学习目标\n\n完成本实验后，你将能够：\n- ✅ 解释 PGD（投影梯度下降）的迭代攻击原理\n- ✅ 对比 FGSM 单步攻击与 PGD 多步攻击的效果差异\n- ✅ 实现带投影约束的迭代优化算法\n- ✅ 分析迭代次数对攻击成功率和收敛速度的影响\n\n## 📚 前置知识\n\n- 完成实验 3.1：FGSM 白盒攻击\n- 理解梯度下降优化算法\n- 了解投影操作和约束优化\n\n## 🖥️ 实验环境\n\n| 项目 | 说明 |\n|------|------|\n| 平台 | 腾讯 Cloud Studio |\n| GPU | NVIDIA Tesla T4（16GB）|\n| 模型 | ResNet-18（ImageNet 预训练）|\n| 框架 | PyTorch 2.0+ |\n\n## 📝 填空说明\n\n本实验共 **4 个填空练习**，难度：⭐⭐⭐☆☆\n\n## 核心概念回顾\n\n**PGD（Projected Gradient Descent）** 是 FGSM 的迭代增强版本，由 Madry 等人提出，被认为是最强的一阶对抗攻击方法。\n\n**FGSM vs PGD 对比**：\n\n| 特性 | FGSM | PGD |\n|------|------|-----|\n| 步数 | 单步 | 多步迭代 |\n| 强度 | 较弱 | 更强 |\n| 速度 | 快 | 慢 |\n| 精确度 | 粗糙 | 精细 |\n\n**PGD 算法流程**：\n\n```\n初始化：x_0 = x（或 x + 随机噪声）\n对于 t = 1 到 T：\n    1. 计算梯度：g_t = ∇_x Loss(θ, x_t, y)\n    2. 梯度步进：x_t+1 = x_t + α × sign(g_t)\n    3. 投影到约束域：x_t+1 = Proj_{x+S}(x_t+1)\n    4. 裁剪像素值：x_t+1 = clip(x_t+1, 0, 1)\n返回：x_T\n```\n\n**关键参数**：\n- `ε`：最大扰动范围（L∞ 范数约束）\n- `α`：每步步长（通常 α < ε）\n- `T`：迭代次数\n\n**投影操作**：确保扰动不超过 ε 限制\n```python\nProj_{x+S}(x') = clip(x' - x, -ε, ε) + x\n```"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第一部分：环境准备与依赖安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入必要的库\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "\n",
    "# 设置中文显示\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# 设置随机种子\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# 加载预训练模型\n",
    "print(\"=\" * 50)\n",
    "print(\"🔧 环境准备\")\n",
    "print(\"=\" * 50)\n",
    "print(\"正在加载 ResNet-18 模型...\")\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()\n",
    "print(\"✓ 模型加载成功！\")\n",
    "\n",
    "# ImageNet 标准化参数\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],\n",
    "    std=[0.229, 0.224, 0.225]\n",
    ")\n",
    "\n",
    "print(f\"  PyTorch 版本: {torch.__version__}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建测试图像（与实验 3.1 相同，保持一致性）\n",
    "def create_test_image():\n",
    "    \"\"\"创建用于测试的合成图像\"\"\"\n",
    "    np.random.seed(42)\n",
    "    img = np.random.rand(224, 224, 3) * 0.3 + 0.35\n",
    "    center_x, center_y = 112, 112\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            dist = np.sqrt((i - center_x)**2 + (j - center_y)**2)\n",
    "            if dist < 60:\n",
    "                img[i, j] = [0.1, 0.1, 0.1]  # 黑色中心\n",
    "            elif dist < 80:\n",
    "                img[i, j] = [0.9, 0.9, 0.9]  # 白色边缘\n",
    "    return torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)\n",
    "\n",
    "def predict(model, img_tensor):\n",
    "    \"\"\"预测图像类别和置信度\"\"\"\n",
    "    input_tensor = normalize(img_tensor).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    pred_class = output.argmax(dim=1).item()\n",
    "    confidence = probs[0, pred_class].item()\n",
    "    return pred_class, confidence\n",
    "\n",
    "# 创建原始图像\n",
    "original_image = create_test_image()\n",
    "original_class, original_confidence = predict(model, original_image)\n",
    "\n",
    "# 显示原始图像和预测\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(original_image.permute(1, 2, 0).numpy())\n",
    "plt.title(f\"原始测试图像\\n预测类别: {original_class}, 置信度: {original_confidence:.2%}\", fontsize=12)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"📊 原始预测结果\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  预测类别: {original_class}\")\n",
    "print(f\"  预测置信度: {original_confidence:.2%}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第二部分：实现 PGD 迭代攻击算法\n",
    "\n",
    "PGD 的核心是\"多次小步前进 + 投影约束\"。我们将逐步实现这个算法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "def pgd_attack(model, image, label, epsilon, alpha, num_steps):\n    \"\"\"\n    实现 PGD (Projected Gradient Descent) 迭代对抗攻击\n    \n    参数:\n        model: 目标神经网络模型\n        image: 原始图像张量 [C, H, W]，范围 [0, 1]\n        label: 原始标签（整数）\n        epsilon: 最大扰动范围 ε（L∞ 约束）\n        alpha: 每步的步长 α\n        num_steps: 迭代次数 T\n    \n    返回:\n        adversarial_image: 对抗样本张量 [C, H, W]\n    \"\"\"\n    # 步骤1：初始化对抗样本\n    # 策略A：从原图开始（常用）\n    adv_image = image.clone().detach()\n    # 策略B：从原图+随机噪声开始（更强）\n    # adv_image = image + torch.empty_like(image).uniform_(-epsilon, epsilon)\n    # adv_image = torch.clamp(adv_image, 0, 1)\n    \n    # 步骤2：开始迭代优化\n    for step in range(num_steps):\n        # 2.1 启用梯度计算\n        adv_image.requires_grad = True\n        \n        # 2.2 前向传播\n        normalized = normalize(adv_image).unsqueeze(0)\n        output = model(normalized)\n        \n        # 2.3 计算损失\n        loss = nn.CrossEntropyLoss()(output, torch.tensor([label]))\n        \n        # 2.4 反向传播计算梯度\n        model.zero_grad()\n        loss.backward()\n        \n        # 2.5 获取梯度\n        gradient = adv_image.grad.data\n        \n        # ========== 填空 1：沿梯度方向前进一小步 ==========\n        # \n        # 🎯 任务：实现 PGD 的单步更新（类似 FGSM）\n        # \n        # 💡 提示：\n        #   - PGD 每步的更新公式：x_t+1 = x_t + α × sign(梯度)\n        #   - 使用 alpha 作为步长（不是 epsilon）\n        #   - 记得先 detach() 断开计算图\n        # \n        # 📖 参考：\n        #   FGSM 是一步到位：x_adv = x + ε × sign(梯度)\n        #   PGD 是多步小跳：x_t+1 = x_t + α × sign(梯度)\n        # \n        # 难度：⭐⭐☆☆☆\n        # \n        # 请将 ___________ 替换为正确的代码\n        \n        adv_image = ___________  # 期望：adv_image.detach() + alpha * torch.sign(gradient)\n        \n        # ========== 填空 2：投影到 ε-ball 约束域 ==========\n        # \n        # 🎯 任务：确保扰动不超过 epsilon 限制\n        # \n        # 💡 提示：\n        #   - 计算扰动：perturbation = adv_image - image\n        #   - 使用 torch.clamp() 裁剪扰动到 [-epsilon, epsilon]\n        #   - 投影公式：perturbation = clamp(perturbation, -ε, ε)\n        # \n        # 难度：⭐⭐⭐☆☆\n        # \n        # 请将 ___________ 替换为正确的代码\n        \n        perturbation = adv_image - image\n        perturbation = ___________  # 期望：torch.clamp(perturbation, -epsilon, epsilon)\n        \n        # 2.7 应用投影后的扰动\n        adv_image = image + perturbation\n        \n        # 2.8 裁剪到有效像素范围 [0, 1]\n        adv_image = torch.clamp(adv_image, 0, 1)\n    \n    return adv_image.detach()\n\nprint(\"✓ PGD 攻击函数定义完成！\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 同时实现 FGSM 用于对比\n",
    "def fgsm_attack(model, image, label, epsilon):\n",
    "    \"\"\"FGSM 单步攻击（用于对比）\"\"\"\n",
    "    image_copy = image.clone().detach()\n",
    "    image_copy.requires_grad = True\n",
    "    \n",
    "    normalized = normalize(image_copy).unsqueeze(0)\n",
    "    output = model(normalized)\n",
    "    loss = nn.CrossEntropyLoss()(output, torch.tensor([label]))\n",
    "    \n",
    "    model.zero_grad()\n",
    "    loss.backward()\n",
    "    \n",
    "    gradient = image_copy.grad.data\n",
    "    perturbation = epsilon * torch.sign(gradient)\n",
    "    adversarial_image = torch.clamp(image_copy + perturbation, 0, 1)\n",
    "    \n",
    "    return adversarial_image.detach()\n",
    "\n",
    "print(\"✓ FGSM 对比函数定义完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第三部分：FGSM vs PGD 效果对比\n",
    "\n",
    "使用相同的 ε 值，对比单步 FGSM 和多步 PGD 的攻击效果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 设置攻击参数\nepsilon = 0.03      # 最大扰动范围\nalpha = 0.01        # PGD 每步步长（通常设置为 ε/步数 或更小）\nnum_steps = 10      # PGD 迭代次数\n\nprint(\"=\" * 50)\nprint(\"⚔️  FGSM vs PGD 攻击对比\")\nprint(\"=\" * 50)\nprint(f\"  攻击参数: ε={epsilon}, α={alpha}, 步数={num_steps}\")\nprint(\"=\" * 50)\n\n# 执行 FGSM 攻击（单步）\nfgsm_adv = fgsm_attack(model, original_image, original_class, epsilon)\nfgsm_pred, fgsm_conf = predict(model, fgsm_adv)\n\n# ========== 填空 3：执行 PGD 攻击 ==========\n# \n# 🎯 任务：调用 pgd_attack 函数执行多步迭代攻击\n# \n# 💡 提示：\n#   - 参数：model, original_image, original_class, epsilon, alpha, num_steps\n#   - 所有参数已在上面定义好\n# \n# 难度：⭐☆☆☆☆\n# \n# 请将 ___________ 替换为正确的代码\n\npgd_adv = ___________  # 期望：pgd_attack(model, original_image, original_class, epsilon, alpha, num_steps)\n\npgd_pred, pgd_conf = predict(model, pgd_adv)\n\n# 显示对比结果\nprint(f\"\\n原始图像:\")\nprint(f\"  预测: 类别 {original_class}, 置信度: {original_confidence:.2%}\")\nprint(f\"\\nFGSM 攻击 (1步):\")\nprint(f\"  预测: 类别 {fgsm_pred}, 置信度: {fgsm_conf:.2%}\")\nprint(f\"  攻击结果: {'✓ 成功' if fgsm_pred != original_class else '✗ 失败'}\")\nprint(f\"\\nPGD 攻击 ({num_steps}步):\")\nprint(f\"  预测: 类别 {pgd_pred}, 置信度: {pgd_conf:.2%}\")\nprint(f\"  攻击结果: {'✓ 成功' if pgd_pred != original_class else '✗ 失败'}\")\nprint(\"=\" * 50)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化对比\n",
    "fig, axes = plt.subplots(1, 4, figsize=(18, 5))\n",
    "\n",
    "# 子图1：原始图像\n",
    "axes[0].imshow(original_image.permute(1, 2, 0).numpy())\n",
    "axes[0].set_title(f\"原始图像\\n类别 {original_class}\\n置信度: {original_confidence:.1%}\", \n",
    "                  fontsize=11, color='green')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# 子图2：FGSM 对抗样本\n",
    "axes[1].imshow(fgsm_adv.permute(1, 2, 0).numpy())\n",
    "fgsm_color = 'red' if fgsm_pred != original_class else 'blue'\n",
    "axes[1].set_title(f\"FGSM (1步)\\n类别 {fgsm_pred}\\n置信度: {fgsm_conf:.1%}\", \n",
    "                  fontsize=11, color=fgsm_color)\n",
    "axes[1].axis('off')\n",
    "\n",
    "# 子图3：PGD 对抗样本\n",
    "axes[2].imshow(pgd_adv.permute(1, 2, 0).numpy())\n",
    "pgd_color = 'red' if pgd_pred != original_class else 'blue'\n",
    "axes[2].set_title(f\"PGD ({num_steps}步)\\n类别 {pgd_pred}\\n置信度: {pgd_conf:.1%}\", \n",
    "                  fontsize=11, color=pgd_color)\n",
    "axes[2].axis('off')\n",
    "\n",
    "# 子图4：扰动大小对比\n",
    "fgsm_perturbation = (fgsm_adv - original_image).abs().mean().item()\n",
    "pgd_perturbation = (pgd_adv - original_image).abs().mean().item()\n",
    "\n",
    "bars = axes[3].bar(['FGSM', 'PGD'], [fgsm_perturbation, pgd_perturbation], \n",
    "                   color=['orange', 'purple'])\n",
    "axes[3].set_title('平均扰动大小对比', fontsize=11)\n",
    "axes[3].set_ylabel('扰动值')\n",
    "axes[3].set_ylim(0, max(fgsm_perturbation, pgd_perturbation) * 1.2)\n",
    "\n",
    "# 添加数值标签\n",
    "for bar in bars:\n",
    "    height = bar.get_height()\n",
    "    axes[3].text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{height:.4f}',\n",
    "                ha='center', va='bottom', fontsize=10)\n",
    "\n",
    "plt.suptitle(\"FGSM vs PGD 攻击效果对比\", fontsize=14, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n扰动分析:\")\n",
    "print(f\"  FGSM 平均扰动: {fgsm_perturbation:.6f}\")\n",
    "print(f\"  PGD 平均扰动:  {pgd_perturbation:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 🤔 思考一下\n",
    "\n",
    "1. **攻击强度**：PGD 和 FGSM 哪个攻击成功率更高？为什么？\n",
    "2. **扰动大小**：两种方法的扰动大小有什么差异？\n",
    "3. **实际应用**：在什么场景下会选择 FGSM？什么场景下选择 PGD？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第四部分：探索迭代次数的影响\n",
    "\n",
    "迭代次数是 PGD 的重要参数。我们将测试不同迭代次数对攻击效果的影响。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 测试不同迭代次数的效果\nstep_values = [1, 3, 5, 10, 20, 40]\nepsilon = 0.03\nalpha = 0.01\n\nprint(\"=\" * 75)\nprint(\"🔬 不同迭代次数的攻击效果\")\nprint(\"=\" * 75)\nprint(f\"{'迭代次数':<10} {'预测类别':<12} {'预测置信度':<15} {'原类别置信度':<15} {'攻击结果'}\")\nprint(\"-\" * 75)\n\nresults = []\nfor steps in step_values:\n    # ========== 填空 4：对不同迭代次数执行 PGD 攻击 ==========\n    # \n    # 🎯 任务：对每个迭代次数执行 PGD 攻击\n    # \n    # 💡 提示：\n    #   - 参数：model, original_image, original_class, epsilon, alpha, steps\n    #   - steps 是当前循环变量\n    # \n    # 难度：⭐⭐☆☆☆\n    # \n    # 请将 ___________ 替换为正确的代码\n    \n    adv = ___________  # 期望：pgd_attack(model, original_image, original_class, epsilon, alpha, steps)\n    \n    pred, conf = predict(model, adv)\n    \n    # 计算原类别的置信度（用于观察攻击效果）\n    with torch.no_grad():\n        output = model(normalize(adv).unsqueeze(0))\n        probs = torch.softmax(output, dim=1)\n        orig_class_conf = probs[0, original_class].item()\n    \n    success = \"✓ 成功\" if pred != original_class else \"✗ 失败\"\n    results.append((steps, adv, pred, conf, orig_class_conf))\n    print(f\"{steps:<10} {pred:<12} {conf:<15.2%} {orig_class_conf:<15.2%} {success}\")\n\nprint(\"=\" * 75)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 可视化迭代次数的影响\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "\n",
    "# 子图1：原类别置信度随迭代次数的变化\n",
    "ax1 = plt.subplot(2, 2, 1)\n",
    "steps_list = [r[0] for r in results]\n",
    "orig_conf_list = [r[4] for r in results]\n",
    "\n",
    "ax1.plot(steps_list, orig_conf_list, 'bo-', linewidth=2, markersize=8, label='原类别置信度')\n",
    "ax1.axhline(y=original_confidence, color='g', linestyle='--', linewidth=2, \n",
    "            label=f'初始置信度 ({original_confidence:.1%})')\n",
    "ax1.axhline(y=0.5, color='r', linestyle='--', linewidth=1, alpha=0.5, label='50% 阈值')\n",
    "ax1.set_xlabel('迭代次数', fontsize=11)\n",
    "ax1.set_ylabel('原类别置信度', fontsize=11)\n",
    "ax1.set_title('迭代次数 vs 原类别置信度', fontsize=12, fontweight='bold')\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 子图2：新预测类别的置信度\n",
    "ax2 = plt.subplot(2, 2, 2)\n",
    "new_conf_list = [r[3] for r in results]\n",
    "ax2.plot(steps_list, new_conf_list, 'ro-', linewidth=2, markersize=8, label='新预测类别置信度')\n",
    "ax2.set_xlabel('迭代次数', fontsize=11)\n",
    "ax2.set_ylabel('新类别置信度', fontsize=11)\n",
    "ax2.set_title('迭代次数 vs 新预测置信度', fontsize=12, fontweight='bold')\n",
    "ax2.legend()\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "# 子图3-6：展示不同迭代次数的对抗样本\n",
    "selected_indices = [0, 2, 4, 5]  # 选择 1, 5, 20, 40 步\n",
    "for i, idx in enumerate(selected_indices):\n",
    "    ax = plt.subplot(2, 4, 5 + i)\n",
    "    steps, img, pred, conf, _ = results[idx]\n",
    "    ax.imshow(img.permute(1, 2, 0).numpy())\n",
    "    color = 'red' if pred != original_class else 'green'\n",
    "    ax.set_title(f\"{steps} 步\\n类别: {pred}\\n置信度: {conf:.1%}\", \n",
    "                 fontsize=10, color=color)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.suptitle(f\"PGD 迭代次数影响分析 (ε={epsilon}, α={alpha})\", \n",
    "             fontsize=14, fontweight='bold', y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 第五部分：PGD 攻击过程可视化\n",
    "\n",
    "深入观察 PGD 在每一步迭代中如何逐步降低原类别的置信度。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实现带历史记录的 PGD 攻击\n",
    "def pgd_attack_with_history(model, image, label, epsilon, alpha, num_steps):\n",
    "    \"\"\"\n",
    "    PGD 攻击并记录每一步的中间结果\n",
    "    \n",
    "    返回:\n",
    "        adversarial_image: 最终对抗样本\n",
    "        history: 每步的历史记录 [(step, pred_class, pred_conf, orig_class_conf), ...]\n",
    "    \"\"\"\n",
    "    history = []\n",
    "    adv_image = image.clone().detach()\n",
    "    \n",
    "    for step in range(num_steps):\n",
    "        adv_image.requires_grad = True\n",
    "        normalized = normalize(adv_image).unsqueeze(0)\n",
    "        output = model(normalized)\n",
    "        loss = nn.CrossEntropyLoss()(output, torch.tensor([label]))\n",
    "        \n",
    "        model.zero_grad()\n",
    "        loss.backward()\n",
    "        \n",
    "        gradient = adv_image.grad.data\n",
    "        adv_image = adv_image.detach() + alpha * torch.sign(gradient)\n",
    "        \n",
    "        # 投影操作\n",
    "        perturbation = adv_image - image\n",
    "        perturbation = torch.clamp(perturbation, -epsilon, epsilon)\n",
    "        adv_image = torch.clamp(image + perturbation, 0, 1)\n",
    "        \n",
    "        # 记录当前状态\n",
    "        pred, conf = predict(model, adv_image)\n",
    "        with torch.no_grad():\n",
    "            out = model(normalize(adv_image).unsqueeze(0))\n",
    "            probs = torch.softmax(out, dim=1)\n",
    "            orig_conf = probs[0, label].item()\n",
    "        history.append((step + 1, pred, conf, orig_conf))\n",
    "    \n",
    "    return adv_image.detach(), history\n",
    "\n",
    "# 执行 PGD 并记录过程\n",
    "print(\"执行 PGD 攻击并记录每步变化...\")\n",
    "_, history = pgd_attack_with_history(model, original_image, original_class, \n",
    "                                      epsilon=0.03, alpha=0.01, num_steps=30)\n",
    "\n",
    "# 提取数据\n",
    "steps = [h[0] for h in history]\n",
    "orig_confs = [h[3] for h in history]\n",
    "new_preds = [h[1] for h in history]\n",
    "new_confs = [h[2] for h in history]\n",
    "\n",
    "# 可视化攻击过程\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# 左图：原类别置信度下降曲线\n",
    "ax1.plot(steps, orig_confs, 'b-o', linewidth=2, markersize=4, label='原类别置信度')\n",
    "ax1.axhline(y=original_confidence, color='g', linestyle='--', linewidth=2, \n",
    "            label=f'初始置信度 ({original_confidence:.1%})')\n",
    "ax1.axhline(y=0.5, color='r', linestyle='--', linewidth=1, alpha=0.5)\n",
    "ax1.fill_between(steps, orig_confs, alpha=0.3)\n",
    "ax1.set_xlabel('迭代步数', fontsize=12)\n",
    "ax1.set_ylabel('原类别置信度', fontsize=12)\n",
    "ax1.set_title('PGD 攻击过程：原类别置信度变化', fontsize=13, fontweight='bold')\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# 右图：预测类别变化\n",
    "pred_changes = []\n",
    "current_pred = original_class\n",
    "for step, pred in enumerate(new_preds):\n",
    "    if pred != current_pred:\n",
    "        pred_changes.append((step + 1, current_pred, pred))\n",
    "        current_pred = pred\n",
    "\n",
    "ax2.plot(steps, new_confs, 'r-o', linewidth=2, markersize=4, label='新预测类别置信度')\n",
    "ax2.set_xlabel('迭代步数', fontsize=12)\n",
    "ax2.set_ylabel('新类别置信度', fontsize=12)\n",
    "ax2.set_title('PGD 攻击过程：新预测类别置信度变化', fontsize=13, fontweight='bold')\n",
    "ax2.legend(fontsize=10)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 输出统计信息\n",
    "print(\"=\" * 50)\n",
    "print(\"📊 PGD 攻击过程分析\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  初始置信度: {original_confidence:.2%}\")\n",
    "print(f\"  最终置信度: {orig_confs[-1]:.2%}\")\n",
    "print(f\"  置信度下降: {(original_confidence - orig_confs[-1]):.2%}\")\n",
    "print(f\"  预测类别变化次数: {len(pred_changes)}\")\n",
    "if pred_changes:\n",
    "    print(f\"  首次改变预测: 第 {pred_changes[0][0]} 步 (类别 {pred_changes[0][1]} → {pred_changes[0][2]})\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 📋 实验小结\n",
    "\n",
    "### 核心收获\n",
    "\n",
    "通过本实验，你已经：\n",
    "\n",
    "1. **理解原理**：掌握了 PGD 迭代攻击的算法原理和实现方法\n",
    "2. **对比分析**：深入理解了 PGD 相比 FGSM 的优势和代价\n",
    "3. **参数调优**：分析了迭代次数对攻击效果的影响\n",
    "4. **过程可视化**：观察了 PGD 如何逐步降低模型对原类别的置信度\n",
    "\n",
    "### 关键概念回顾\n",
    "\n",
    "**PGD vs FGSM 核心区别**：\n",
    "\n",
    "| 特性 | FGSM | PGD |\n",
    "|------|------|-----|\n",
    "| 更新公式 | `x_adv = x + ε·sign(∇L)` | `x_t+1 = Proj(x_t + α·sign(∇L))` |\n",
    "| 步数 | 1 | T (多步) |\n",
    "| 投影操作 | 无 | 有（确保 ‖x_adv - x‖∞ ≤ ε）|\n",
    "| 攻击强度 | 较弱 | 更强 |\n",
    "| 计算成本 | 低 | 高（T倍于FGSM）|\n",
    "\n",
    "**PGD 三个关键步骤**：\n",
    "1. **梯度步进**：x_t+1 = x_t + α × sign(∇L)\n",
    "2. **投影约束**：Proj(x_t+1) 到 ε-ball\n",
    "3. **像素裁剪**：clip(x_t+1, 0, 1)\n",
    "\n",
    "**参数选择建议**：\n",
    "- **ε**：总扰动预算（如 0.03, 0.1）\n",
    "- **α**：步长，通常设为 ε/10 或 2.5×ε/T\n",
    "- **T**：迭代次数，通常 10-40 步\n",
    "\n",
    "### 实验观察\n",
    "\n",
    "1. **攻击强度**：PGD 通常比 FGSM 有更高的攻击成功率\n",
    "2. **收敛性**：PGD 在前几步快速降低原类别置信度，后续收益递减\n",
    "3. **计算成本**：PGD 需要 T 次前向传播和反向传播，是 FGSM 的 T 倍\n",
    "4. **应用场景**：\n",
    "   - **FGSM**：快速攻击、对抗训练（降低计算成本）\n",
    "   - **PGD**：强力攻击、模型鲁棒性评估、生成高质量对抗样本\n",
    "\n",
    "### 填空参考答案\n",
    "\n",
    "<details>\n",
    "<summary>点击查看所有填空参考答案</summary>\n",
    "\n",
    "**填空 1：沿梯度方向前进一小步**\n",
    "```python\n",
    "adv_image = adv_image.detach() + alpha * torch.sign(gradient)\n",
    "```\n",
    "\n",
    "**填空 2：投影到 ε-ball 约束域**\n",
    "```python\n",
    "perturbation = torch.clamp(perturbation, -epsilon, epsilon)\n",
    "```\n",
    "\n",
    "**填空 3：执行 PGD 攻击**\n",
    "```python\n",
    "pgd_adv = pgd_attack(model, original_image, original_class, epsilon, alpha, num_steps)\n",
    "```\n",
    "\n",
    "**填空 4：对不同迭代次数执行 PGD 攻击**\n",
    "```python\n",
    "adv = pgd_attack(model, original_image, original_class, epsilon, alpha, steps)\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "### 延伸学习\n",
    "\n",
    "- **下一个实验**：实验 3.3 - 迁移攻击（黑盒攻击场景）\n",
    "- **论文阅读**：Madry et al., \"Towards Deep Learning Models Resistant to Adversarial Attacks\" (ICLR 2018)\n",
    "- **进阶挑战**：\n",
    "  - 实现 Targeted PGD（攻击到指定目标类别）\n",
    "  - 尝试随机初始化版本的 PGD\n",
    "  - 对比 L2 范数约束的 PGD\n",
    "\n",
    "### 🤔 深入思考\n",
    "\n",
    "1. **收敛分析**：从置信度变化曲线看，PGD 是否一定收敛？\n",
    "2. **参数权衡**：如何在攻击强度和计算成本之间找到平衡？\n",
    "3. **防御思路**：基于 PGD 的观察，你能想到哪些防御方法？\n",
    "4. **实际应用**：在黑盒场景（攻击者不知道模型参数）下，PGD 还能使用吗？\n",
    "\n",
    "### 安全提醒\n",
    "\n",
    "⚠️ **本实验仅用于教育目的**\n",
    "\n",
    "PGD 是评估模型鲁棒性的标准方法，也是对抗训练的重要工具。请将所学知识用于：\n",
    "- 评估和提升 AI 系统的安全性\n",
    "- 开发更鲁棒的模型\n",
    "- 推进对抗机器学习研究\n",
    "\n",
    "请勿用于攻击未经授权的系统。"
   ]
  },
  {
   "cell_type": "markdown",
   "source": "⚠️ 重要提醒\n\n实验完成后，请记得：\n\n1. **释放 GPU 资源**：如果你使用的是 Tencent CloudStudio，请点击右上角的\"停止\"按钮，停止运行。\n2. **保存实验结果**：如需保存，请下载 notebook 文件\n\n这样可以避免不必要的资源占用和费用产生。**否则会一直消耗你的免费资源额度。**",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": "# 实验结束，清理显存（可选）\n# 如果要继续进行下一个实验，可以运行这段代码释放显存\n\ndel model\nimport torch\ntorch.cuda.empty_cache()\nprint(\"✓ 显存已清理\")",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}