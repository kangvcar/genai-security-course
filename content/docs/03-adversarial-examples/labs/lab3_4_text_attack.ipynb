{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# å®éªŒ 3.4ï¼šæ–‡æœ¬å¯¹æŠ—æ”»å‡»\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "å®Œæˆæœ¬å®éªŒåï¼Œä½ å°†èƒ½å¤Ÿï¼š\n",
    "- âœ… ç†è§£æ–‡æœ¬å¯¹æŠ—æ”»å‡»ä¸å›¾åƒæ”»å‡»çš„æœ¬è´¨åŒºåˆ«\n",
    "- âœ… å®ç°åŸºäºåŒä¹‰è¯æ›¿æ¢çš„æ–‡æœ¬å¯¹æŠ—æ”»å‡»\n",
    "- âœ… åˆ†æè¯é‡è¦æ€§å¹¶è®¾è®¡é’ˆå¯¹æ€§æ”»å‡»ç­–ç•¥\n",
    "- âœ… è®¤è¯†æ–‡æœ¬å¯¹æŠ—æ”»å‡»åœ¨çœŸå®åœºæ™¯ä¸­çš„å¨èƒ\n",
    "\n",
    "## ğŸ“š å‰ç½®çŸ¥è¯†\n",
    "\n",
    "- äº†è§£è‡ªç„¶è¯­è¨€å¤„ç†ï¼ˆNLPï¼‰åŸºç¡€\n",
    "- ç†è§£æ–‡æœ¬åˆ†ç±»ä»»åŠ¡ï¼ˆå¦‚æƒ…æ„Ÿåˆ†æï¼‰\n",
    "- å®Œæˆå‰ä¸‰ä¸ªå®éªŒï¼ˆå›¾åƒå¯¹æŠ—æ”»å‡»ï¼‰\n",
    "\n",
    "## ğŸ–¥ï¸ å®éªŒç¯å¢ƒ\n",
    "\n",
    "| é¡¹ç›® | è¯´æ˜ |\n",
    "|------|------|\n",
    "| å¹³å° | è…¾è®¯ Cloud Studio |\n",
    "| GPU | NVIDIA Tesla T4ï¼ˆ16GBï¼‰|\n",
    "| æ¨¡å‹ | hfl/chinese-macbert-base (ä¸­æ–‡BERT) |\n",
    "| ä»»åŠ¡ | ä¸­æ–‡æƒ…æ„Ÿåˆ†æ |\n",
    "\n",
    "## â±ï¸ é¢„è®¡æ—¶é—´ï¼š30 åˆ†é’Ÿ\n",
    "\n",
    "## ğŸ“ å¡«ç©ºè¯´æ˜\n",
    "\n",
    "æœ¬å®éªŒå…± **5 ä¸ªå¡«ç©ºç»ƒä¹ **ï¼Œéš¾åº¦ï¼šâ­â­â­â˜†â˜†\n",
    "\n",
    "## æ ¸å¿ƒæ¦‚å¿µå›é¡¾\n",
    "\n",
    "### æ–‡æœ¬ vs å›¾åƒå¯¹æŠ—æ”»å‡»çš„åŒºåˆ«\n",
    "\n",
    "| ç»´åº¦ | å›¾åƒæ”»å‡» | æ–‡æœ¬æ”»å‡» |\n",
    "|------|---------|---------|\n",
    "| **æ•°æ®æ€§è´¨** | è¿ç»­ï¼ˆåƒç´ å€¼ï¼‰ | ç¦»æ•£ï¼ˆè¯è¯­ï¼‰ |\n",
    "| **æ‰°åŠ¨æ–¹å¼** | å¾®å°åƒç´ æ”¹å˜ | è¯è¯­æ›¿æ¢/æ’å…¥/åˆ é™¤ |\n",
    "| **æ¢¯åº¦å¯ç”¨æ€§** | å¯ç›´æ¥è®¡ç®—æ¢¯åº¦ | æ¢¯åº¦ä¸å¯ç›´æ¥åº”ç”¨ |\n",
    "| **è¯­ä¹‰ä¿æŒ** | è§†è§‰ç›¸ä¼¼ | è¯­ä¹‰ç›¸ä¼¼ |\n",
    "| **æ£€æµ‹éš¾åº¦** | äººçœ¼éš¾å¯Ÿè§‰ | å®¹æ˜“äº§ç”Ÿè¯­æ³•é”™è¯¯ |\n",
    "\n",
    "### æ–‡æœ¬å¯¹æŠ—æ”»å‡»ç­–ç•¥\n",
    "\n",
    "**1. å­—ç¬¦çº§æ”»å‡»**\n",
    "- æ’å…¥/åˆ é™¤å­—ç¬¦\n",
    "- åŒå½¢å­—æ›¿æ¢ï¼ˆå¦‚ `0` â†’ `O`ï¼‰\n",
    "- æ‰“å­—é”™è¯¯æ¨¡æ‹Ÿ\n",
    "\n",
    "**2. è¯çº§æ”»å‡»**\n",
    "- åŒä¹‰è¯æ›¿æ¢ï¼ˆæœ€å¸¸ç”¨ï¼‰\n",
    "- è¯åºè°ƒæ•´\n",
    "- é‡è¦è¯åˆ é™¤\n",
    "\n",
    "**3. å¥å­çº§æ”»å‡»**\n",
    "- æ·»åŠ æ— å…³å¥å­\n",
    "- æ”¹å†™å¥å­ç»“æ„\n",
    "\n",
    "### åŒä¹‰è¯æ›¿æ¢æ”»å‡»æµç¨‹\n",
    "\n",
    "```\n",
    "1. åˆ†æåŸå§‹æ–‡æœ¬ï¼Œè·å–æ¨¡å‹é¢„æµ‹\n",
    "2. è®¡ç®—æ¯ä¸ªè¯çš„é‡è¦æ€§ï¼ˆå½±å“é¢„æµ‹çš„ç¨‹åº¦ï¼‰\n",
    "3. ä¼˜å…ˆæ›¿æ¢é‡è¦æ€§é«˜çš„è¯\n",
    "4. ä»åŒä¹‰è¯åº“ä¸­é€‰æ‹©æ›¿æ¢è¯\n",
    "5. éªŒè¯æ›¿æ¢åçš„é¢„æµ‹æ˜¯å¦æ”¹å˜\n",
    "6. é‡å¤ç›´åˆ°æ”»å‡»æˆåŠŸæˆ–æ— å¯æ›¿æ¢è¯\n",
    "```\n",
    "\n",
    "**å…³é”®çº¦æŸ**ï¼š\n",
    "- è¯­ä¹‰ä¿æŒï¼šæ›¿æ¢åæ–‡æœ¬æ„æ€ä¸å˜\n",
    "- è¯­æ³•æ­£ç¡®ï¼šä¸äº§ç”Ÿè¯­æ³•é”™è¯¯\n",
    "- äººç±»å¯è¯»ï¼šäººç±»èƒ½ç†è§£æ–‡æœ¬å†…å®¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒå‡†å¤‡ä¸æ¨¡å‹åŠ è½½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…ä¾èµ–\n",
    "import sys\n",
    "!{sys.executable} -m pip install transformers torch -q\n",
    "\n",
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ”§ ç¯å¢ƒå‡†å¤‡å®Œæˆ\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc4a14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½ä¸­æ–‡æƒ…æ„Ÿåˆ†ææ¨¡å‹\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ“¦ åŠ è½½ä¸­æ–‡BERTæ¨¡å‹\")\n",
    "print(\"=\" * 50)\n",
    "print(\"æ­£åœ¨ä¸‹è½½æ¨¡å‹ï¼ˆé¦–æ¬¡è¿è¡Œéœ€è¦å‡ åˆ†é’Ÿï¼‰...\\n\")\n",
    "\n",
    "# ä½¿ç”¨äº¬ä¸œå•†å“è¯„è®ºæƒ…æ„Ÿåˆ†ææ¨¡å‹ï¼ˆå·²è®­ç»ƒå¥½çš„ä¸­æ–‡æƒ…æ„Ÿåˆ†ç±»å™¨ï¼‰\n",
    "model_name = \"uer/roberta-base-finetuned-jd-binary-chinese\"\n",
    "\n",
    "print(\"1ï¸âƒ£ åŠ è½½åˆ†è¯å™¨...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "print(\"   âœ“ Tokenizer åŠ è½½å®Œæˆ\")\n",
    "\n",
    "print(\"\\n2ï¸âƒ£ åŠ è½½æƒ…æ„Ÿåˆ†ç±»æ¨¡å‹...\")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(model_name)\n",
    "model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼\n",
    "\n",
    "param_count = sum(p.numel() for p in model.parameters()) / 1e6\n",
    "print(f\"   âœ“ æ¨¡å‹åŠ è½½å®Œæˆ (~{param_count:.1f}M å‚æ•°)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "print(\"âœ“ æ¨¡å‹åŠ è½½æˆåŠŸï¼\")\n",
    "print(f\"  æ¨¡å‹: RoBERTa-Base (ä¸­æ–‡)\")\n",
    "print(f\"  ä»»åŠ¡: äºŒåˆ†ç±»æƒ…æ„Ÿåˆ†æ (æ­£é¢/è´Ÿé¢)\")\n",
    "print(f\"  è®­ç»ƒæ•°æ®: äº¬ä¸œå•†å“è¯„è®º\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ä¸­æ–‡åŒä¹‰è¯è¯å…¸\n",
    "# åŸºäºå¸¸è§ç”µå•†è¯„è®ºåœºæ™¯çš„åŒä¹‰è¯æ›¿æ¢è¯åº“\n",
    "\n",
    "SYNONYMS = {\n",
    "    # æ­£é¢è¯æ±‡\n",
    "    \"å¥½\": [\"æ£’\", \"ä½³\", \"ä¼˜\", \"èµ\", \"å¦™\"],\n",
    "    \"å–œæ¬¢\": [\"çˆ±\", \"é’ç\", \"åçˆ±\", \"é’Ÿçˆ±\", \"ä¸­æ„\"],\n",
    "    \"ä¼˜ç§€\": [\"å‡ºè‰²\", \"æ°å‡º\", \"å“è¶Š\", \"ä¼˜è‰¯\", \"ä¸Šä¹˜\"],\n",
    "    \"æ»¡æ„\": [\"ç§°å¿ƒ\", \"å¦‚æ„\", \"èˆ’å¿ƒ\", \"æƒ¬æ„\", \"å¼€å¿ƒ\"],\n",
    "    \"æ¨è\": [\"å»ºè®®\", \"ä»‹ç»\", \"ä¸¾è\", \"åŠ›è\", \"å®‰åˆ©\"],\n",
    "    \"å¿«\": [\"è¿…é€Ÿ\", \"æ•æ·\", \"é£å¿«\", \"ç¥é€Ÿ\", \"å¿«æ·\"],\n",
    "    \"ä¾¿å®œ\": [\"å®æƒ \", \"åˆ’ç®—\", \"ä½ä»·\", \"ä¼˜æƒ \", \"äº²æ°‘\"],\n",
    "    \"æ¼‚äº®\": [\"ç¾ä¸½\", \"å¥½çœ‹\", \"é“ä¸½\", \"ç²¾ç¾\", \"ç¾è§‚\"],\n",
    "    \"ä¸é”™\": [\"å¯ä»¥\", \"æŒºå¥½\", \"å°šå¯\", \"è¿˜è¡Œ\", \"åˆæ ¼\"],\n",
    "    \"è´¨é‡\": [\"å“è´¨\", \"è´¨åœ°\", \"æ¡£æ¬¡\", \"æ°´å¹³\", \"æ°´å‡†\"],\n",
    "    \n",
    "    # è´Ÿé¢è¯æ±‡\n",
    "    \"å·®\": [\"ç³Ÿ\", \"çƒ‚\", \"åŠ£\", \"æ¬¡\", \"å­¬\"],\n",
    "    \"è®¨åŒ\": [\"åŒæ¶\", \"åæ„Ÿ\", \"å«Œå¼ƒ\", \"æ†æ¨\", \"æ¶å¿ƒ\"],\n",
    "    \"å¤±æœ›\": [\"æ²®ä¸§\", \"ç°å¿ƒ\", \"æ°”é¦\", \"å¿ƒå¯’\", \"æ³„æ°”\"],\n",
    "    \"æ…¢\": [\"ç¼“æ…¢\", \"è¿Ÿç¼“\", \"ç£¨è¹­\", \"æ‹–æ‹‰\", \"è¿Ÿé’\"],\n",
    "    \"è´µ\": [\"æ˜‚è´µ\", \"é«˜ä»·\", \"å¤©ä»·\", \"å¥¢ä¾ˆ\", \"æ­»è´µ\"],\n",
    "    \"éš¾ç”¨\": [\"éš¾æ“ä½œ\", \"ä¸å¥½ç”¨\", \"å¤æ‚\", \"éº»çƒ¦\", \"è´¹åŠ²\"],\n",
    "    \"åæ‚”\": [\"é—æ†¾\", \"æ‡Šæ‚”\", \"æ‚”æ¨\", \"ç—›å¿ƒ\", \"æ‚”ä¸å½“åˆ\"],\n",
    "    \n",
    "    # ä¸­æ€§è¯æ±‡\n",
    "    \"äº§å“\": [\"å•†å“\", \"è´§ç‰©\", \"ç‰©å“\", \"ä¸œè¥¿\", \"ç‰©ä»¶\"],\n",
    "    \"è´­ä¹°\": [\"ä¹°\", \"é€‰è´­\", \"å…¥æ‰‹\", \"ä¸‹å•\", \"é‡‡è´­\"],\n",
    "    \"ä½¿ç”¨\": [\"ç”¨\", \"è¿ç”¨\", \"åˆ©ç”¨\", \"é‡‡ç”¨\", \"åº”ç”¨\"],\n",
    "    \"å‘è´§\": [\"é€è´§\", \"é…é€\", \"ç‰©æµ\", \"å¿«é€’\", \"å¯„é€\"],\n",
    "    \"æœåŠ¡\": [\"æ€åº¦\", \"æ¥å¾…\", \"å¯¹å¾…\", \"å¾…é‡\", \"æ¬¾å¾…\"],\n",
    "}\n",
    "\n",
    "def get_synonyms(word):\n",
    "    \"\"\"\n",
    "    è·å–è¯çš„åŒä¹‰è¯åˆ—è¡¨\n",
    "    \n",
    "    å‚æ•°:\n",
    "        word: è¦æŸ¥æ‰¾åŒä¹‰è¯çš„è¯\n",
    "    \n",
    "    è¿”å›:\n",
    "        synonyms: åŒä¹‰è¯åˆ—è¡¨\n",
    "    \"\"\"\n",
    "    return SYNONYMS.get(word, [])\n",
    "\n",
    "print(f\"ğŸ“š åŒä¹‰è¯è¯å…¸ç»Ÿè®¡:\")\n",
    "print(f\"  è¯æ¡æ•°é‡: {len(SYNONYMS)}\")\n",
    "print(f\"  æ€»åŒä¹‰è¯æ•°: {sum(len(v) for v in SYNONYMS.values())}\")\n",
    "print(f\"\\nç¤ºä¾‹:\")\n",
    "print(f\"  'å¥½' çš„åŒä¹‰è¯: {get_synonyms('å¥½')}\")\n",
    "print(f\"  'å–œæ¬¢' çš„åŒä¹‰è¯: {get_synonyms('å–œæ¬¢')}\")\n",
    "print(f\"  'å·®' çš„åŒä¹‰è¯: {get_synonyms('å·®')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰æƒ…æ„Ÿåˆ†æè¾…åŠ©å‡½æ•°\n",
    "def analyze_sentiment(text):\n",
    "    \"\"\"\n",
    "    åˆ†ææ–‡æœ¬æƒ…æ„Ÿ\n",
    "    \n",
    "    å‚æ•°:\n",
    "        text: è¾“å…¥æ–‡æœ¬\n",
    "    \n",
    "    è¿”å›:\n",
    "        label: æƒ…æ„Ÿæ ‡ç­¾ (\"æ­£é¢\" æˆ– \"è´Ÿé¢\")\n",
    "        confidence: é¢„æµ‹ç½®ä¿¡åº¦\n",
    "    \"\"\"\n",
    "    # åˆ†è¯å’Œç¼–ç \n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    \n",
    "    # æ¨¡å‹æ¨ç†\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probs = torch.softmax(logits, dim=1)[0]\n",
    "    \n",
    "    # æ ‡ç­¾æ˜ å°„: 0=è´Ÿé¢, 1=æ­£é¢\n",
    "    pred_label = torch.argmax(probs).item()\n",
    "    confidence = probs[pred_label].item()\n",
    "    \n",
    "    label = \"æ­£é¢\" if pred_label == 1 else \"è´Ÿé¢\"\n",
    "    return label, confidence\n",
    "\n",
    "def get_positive_score(text):\n",
    "    \"\"\"\n",
    "    è·å–æ­£é¢æƒ…æ„Ÿçš„ç½®ä¿¡åº¦åˆ†æ•°\n",
    "    \n",
    "    å‚æ•°:\n",
    "        text: è¾“å…¥æ–‡æœ¬\n",
    "    \n",
    "    è¿”å›:\n",
    "        score: æ­£é¢æƒ…æ„Ÿç½®ä¿¡åº¦ [0, 1]\n",
    "    \"\"\"\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=128)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.softmax(outputs.logits, dim=1)[0]\n",
    "    return probs[1].item()  # ç´¢å¼•1å¯¹åº”æ­£é¢\n",
    "\n",
    "# æµ‹è¯•æƒ…æ„Ÿåˆ†æåŠŸèƒ½\n",
    "test_texts = [\n",
    "    \"è¿™ä¸ªäº§å“éå¸¸å¥½ï¼Œæˆ‘å¾ˆå–œæ¬¢ï¼\",\n",
    "    \"è´¨é‡å¤ªå·®äº†ï¼Œå®Œå…¨ä¸æ¨èè´­ä¹°ã€‚\",\n",
    "    \"è¿˜å¯ä»¥å§ï¼Œä»·æ ¼æœ‰ç‚¹è´µã€‚\",\n",
    "    \"å‘è´§é€Ÿåº¦å¿«ï¼ŒæœåŠ¡æ€åº¦å¥½ï¼Œæ»¡æ„ï¼\",\n",
    "    \"ç”¨äº†å‡ å¤©å°±åäº†ï¼ŒçœŸæ˜¯å¤±æœ›ã€‚\"\n",
    "]\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ§ª æƒ…æ„Ÿåˆ†æåŠŸèƒ½æµ‹è¯•\")\n",
    "print(\"=\" * 60)\n",
    "for text in test_texts:\n",
    "    label, score = analyze_sentiment(text)\n",
    "    color_code = '\\033[92m' if label == \"æ­£é¢\" else '\\033[91m'\n",
    "    reset_code = '\\033[0m'\n",
    "    print(f\"  {text[:30]:<30} â†’ {label} ({score:.2%})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## ç¬¬äºŒéƒ¨åˆ†ï¼šè¯é‡è¦æ€§åˆ†æ\n",
    "\n",
    "äº†è§£å“ªäº›è¯å¯¹æ¨¡å‹é¢„æµ‹å½±å“æœ€å¤§ï¼Œæ˜¯è®¾è®¡é«˜æ•ˆæ”»å‡»çš„å…³é”®ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_word_importance(text):\n",
    "    \"\"\"\n",
    "    è®¡ç®—æ–‡æœ¬ä¸­æ¯ä¸ªå­—ç¬¦å¯¹é¢„æµ‹ç»“æœçš„é‡è¦æ€§\n",
    "    \n",
    "    æ–¹æ³•ï¼šåˆ é™¤æ³• (Leave-One-Out)\n",
    "    - åˆ é™¤æŸä¸ªå­—ç¬¦ï¼Œè§‚å¯Ÿé¢„æµ‹ç½®ä¿¡åº¦çš„å˜åŒ–\n",
    "    - å˜åŒ–è¶Šå¤§ï¼Œè¯´æ˜è¯¥å­—ç¬¦è¶Šé‡è¦\n",
    "    \n",
    "    å‚æ•°:\n",
    "        text: è¾“å…¥æ–‡æœ¬\n",
    "    \n",
    "    è¿”å›:\n",
    "        importance_scores: [(å­—ç¬¦, é‡è¦æ€§åˆ†æ•°), ...]\n",
    "    \"\"\"\n",
    "    # è·å–åŸå§‹é¢„æµ‹åˆ†æ•°\n",
    "    original_score = get_positive_score(text)\n",
    "    \n",
    "    # ç®€å•åˆ†è¯ï¼ˆæŒ‰å­—ç¬¦ï¼‰\n",
    "    chars = list(text)\n",
    "    importance_scores = []\n",
    "    \n",
    "    for i, char in enumerate(chars):\n",
    "        # è·³è¿‡æ ‡ç‚¹ç¬¦å·\n",
    "        if char in ['ï¼Œ', 'ã€‚', 'ï¼', 'ï¼Ÿ', ' ', 'ã€', 'ï¼›']:\n",
    "            importance_scores.append((char, 0))\n",
    "            continue\n",
    "        \n",
    "        # ========== å¡«ç©º 1ï¼šè®¡ç®—åˆ é™¤è¯¥å­—åçš„æ–‡æœ¬ ==========\n",
    "        # \n",
    "        # ğŸ¯ ä»»åŠ¡ï¼šåˆ›å»ºåˆ é™¤ç¬¬ i ä¸ªå­—ç¬¦åçš„æ–°æ–‡æœ¬\n",
    "        # \n",
    "        # ğŸ’¡ æç¤ºï¼š\n",
    "        #   - æ‹¼æ¥ i ä¹‹å‰å’Œ i ä¹‹åçš„å­—ç¬¦\n",
    "        #   - chars[:i] æ˜¯å‰é¢çš„å­—ç¬¦\n",
    "        #   - chars[i+1:] æ˜¯åé¢çš„å­—ç¬¦\n",
    "        #   - ä½¿ç”¨ ''.join() æ‹¼æ¥æˆå­—ç¬¦ä¸²\n",
    "        # \n",
    "        # éš¾åº¦ï¼šâ­â­â˜†â˜†â˜†\n",
    "        \n",
    "        chars_without_i = ___________  # æœŸæœ›ï¼šchars[:i] + chars[i+1:]\n",
    "        modified_text = ''.join(chars_without_i)\n",
    "        \n",
    "        if not modified_text.strip():  # ç©ºæ–‡æœ¬è·³è¿‡\n",
    "            importance_scores.append((char, 0))\n",
    "            continue\n",
    "        \n",
    "        # è®¡ç®—åˆ é™¤è¯¥å­—åçš„æƒ…æ„Ÿåˆ†æ•°\n",
    "        modified_score = get_positive_score(modified_text)\n",
    "        \n",
    "        # é‡è¦æ€§ = åˆ é™¤å‰ååˆ†æ•°å˜åŒ–çš„ç»å¯¹å€¼\n",
    "        importance = abs(original_score - modified_score)\n",
    "        \n",
    "        importance_scores.append((char, importance))\n",
    "    \n",
    "    return importance_scores\n",
    "\n",
    "# æµ‹è¯•è¯é‡è¦æ€§åˆ†æ\n",
    "test_sentence = \"è¿™ä¸ªäº§å“éå¸¸å¥½ï¼Œæˆ‘å¾ˆå–œæ¬¢ï¼\"\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ” è¯é‡è¦æ€§åˆ†æ\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"æµ‹è¯•æ–‡æœ¬: '{test_sentence}'\")\n",
    "\n",
    "orig_label, orig_conf = analyze_sentiment(test_sentence)\n",
    "print(f\"åŸå§‹é¢„æµ‹: {orig_label} ({orig_conf:.2%})\\n\")\n",
    "\n",
    "importance = compute_word_importance(test_sentence)\n",
    "\n",
    "# æŒ‰é‡è¦æ€§æ’åºå¹¶æ˜¾ç¤ºå‰10\n",
    "sorted_importance = sorted(importance, key=lambda x: x[1], reverse=True)\n",
    "print(\"å­—ç¬¦é‡è¦æ€§æ’åï¼ˆå‰10ï¼‰:\")\n",
    "print(f\"{'æ’å':<6} {'å­—ç¬¦':<10} {'é‡è¦æ€§åˆ†æ•°':<15}\")\n",
    "print(\"-\" * 40)\n",
    "for rank, (char, score) in enumerate(sorted_importance[:10], 1):\n",
    "    if score > 0:\n",
    "        print(f\"{rank:<6} {char:<10} {score:<15.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–è¯é‡è¦æ€§\n",
    "chars = [c for c, _ in importance]\n",
    "scores = [s for _, s in importance]\n",
    "\n",
    "plt.figure(figsize=(16, 5))\n",
    "\n",
    "# æ ¹æ®é‡è¦æ€§è®¾ç½®é¢œè‰²\n",
    "colors = []\n",
    "for s in scores:\n",
    "    if s > 0.05:\n",
    "        colors.append('red')      # é«˜é‡è¦æ€§\n",
    "    elif s > 0.02:\n",
    "        colors.append('orange')   # ä¸­ç­‰é‡è¦æ€§\n",
    "    else:\n",
    "        colors.append('steelblue')  # ä½é‡è¦æ€§\n",
    "\n",
    "plt.bar(range(len(chars)), scores, color=colors)\n",
    "plt.xticks(range(len(chars)), chars, fontsize=13)\n",
    "plt.xlabel('å­—ç¬¦ä½ç½®', fontsize=12)\n",
    "plt.ylabel('é‡è¦æ€§åˆ†æ•°', fontsize=12)\n",
    "plt.title(f'å­—ç¬¦é‡è¦æ€§çƒ­åŠ›å›¾\\nåŸæ–‡: \"{test_sentence}\"', fontsize=14, fontweight='bold')\n",
    "plt.axhline(y=0.05, color='red', linestyle='--', alpha=0.5, label='é«˜é‡è¦æ€§é˜ˆå€¼')\n",
    "plt.axhline(y=0.02, color='orange', linestyle='--', alpha=0.5, label='ä¸­ç­‰é‡è¦æ€§é˜ˆå€¼')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nğŸ’¡ æ”»å‡»ç­–ç•¥æç¤º:\")\n",
    "print(\"   çº¢è‰²å­—ç¬¦ = é«˜é‡è¦æ€§ï¼Œä¼˜å…ˆæ”»å‡»ç›®æ ‡\")\n",
    "print(\"   æ©™è‰²å­—ç¬¦ = ä¸­ç­‰é‡è¦æ€§ï¼Œæ¬¡è¦æ”»å‡»ç›®æ ‡\")\n",
    "print(\"   è“è‰²å­—ç¬¦ = ä½é‡è¦æ€§ï¼Œæ›¿æ¢æ•ˆæœä¸æ˜æ˜¾\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®ç°åŒä¹‰è¯æ›¿æ¢æ”»å‡»\n",
    "\n",
    "åŸºäºè¯é‡è¦æ€§ï¼Œæˆ‘ä»¬è®¾è®¡ä¸€ä¸ªè´ªå¿ƒç­–ç•¥ï¼šä¼˜å…ˆæ›¿æ¢é‡è¦æ€§é«˜çš„è¯ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_attack(text, max_replacements=5):\n",
    "    \"\"\"\n",
    "    åŒä¹‰è¯æ›¿æ¢å¯¹æŠ—æ”»å‡»\n",
    "    \n",
    "    ç­–ç•¥ï¼š\n",
    "    1. éå†åŒä¹‰è¯è¯å…¸ä¸­çš„æ‰€æœ‰è¯\n",
    "    2. å¦‚æœè¯åœ¨æ–‡æœ¬ä¸­ï¼Œå°è¯•æ›¿æ¢ä¸ºåŒä¹‰è¯\n",
    "    3. é€‰æ‹©ä½¿ç½®ä¿¡åº¦å˜åŒ–æœ€å¤§çš„æ›¿æ¢\n",
    "    4. é‡å¤ç›´åˆ°æ”»å‡»æˆåŠŸæˆ–è¾¾åˆ°æœ€å¤§æ›¿æ¢æ¬¡æ•°\n",
    "    \n",
    "    å‚æ•°:\n",
    "        text: åŸå§‹æ–‡æœ¬\n",
    "        max_replacements: æœ€å¤§æ›¿æ¢æ¬¡æ•°\n",
    "    \n",
    "    è¿”å›:\n",
    "        adv_text: å¯¹æŠ—æ–‡æœ¬\n",
    "        success: æ˜¯å¦æ”»å‡»æˆåŠŸ\n",
    "        replacements: æ›¿æ¢å†å² [(åŸè¯, æ›¿æ¢è¯), ...]\n",
    "    \"\"\"\n",
    "    original_label, original_conf = analyze_sentiment(text)\n",
    "    current_text = text\n",
    "    replacements = []\n",
    "    \n",
    "    # éå†åŒä¹‰è¯è¯å…¸\n",
    "    for word, synonyms in SYNONYMS.items():\n",
    "        # æ£€æŸ¥è¯æ˜¯å¦åœ¨å½“å‰æ–‡æœ¬ä¸­\n",
    "        if word not in current_text:\n",
    "            continue\n",
    "        \n",
    "        # å°è¯•æ¯ä¸ªåŒä¹‰è¯ï¼Œæ‰¾åˆ°æœ€ä½³æ›¿æ¢\n",
    "        best_synonym = None\n",
    "        best_score_change = 0\n",
    "        \n",
    "        for synonym in synonyms:\n",
    "            # ========== å¡«ç©º 2ï¼šåˆ›å»ºæ›¿æ¢åçš„æ–‡æœ¬ ==========\n",
    "            # \n",
    "            # ğŸ¯ ä»»åŠ¡ï¼šå°†æ–‡æœ¬ä¸­çš„ç›®æ ‡è¯æ›¿æ¢ä¸ºåŒä¹‰è¯\n",
    "            # \n",
    "            # ğŸ’¡ æç¤ºï¼š\n",
    "            #   - ä½¿ç”¨å­—ç¬¦ä¸²çš„ replace æ–¹æ³•\n",
    "            #   - current_text.replace(old, new, count)\n",
    "            #   - count=1 è¡¨ç¤ºåªæ›¿æ¢ç¬¬ä¸€ä¸ªåŒ¹é…\n",
    "            # \n",
    "            # éš¾åº¦ï¼šâ­â˜†â˜†â˜†â˜†\n",
    "            \n",
    "            test_text = ___________  # æœŸæœ›ï¼šcurrent_text.replace(word, synonym, 1)\n",
    "            \n",
    "            new_label, new_conf = analyze_sentiment(test_text)\n",
    "            \n",
    "            # å¦‚æœæ”»å‡»æˆåŠŸï¼ˆæ ‡ç­¾æ”¹å˜ï¼‰ï¼Œç›´æ¥è¿”å›\n",
    "            if new_label != original_label:\n",
    "                replacements.append((word, synonym))\n",
    "                return test_text, True, replacements\n",
    "            \n",
    "            # è®¡ç®—ç½®ä¿¡åº¦å˜åŒ–ï¼ˆå¸Œæœ›é™ä½åŸæ ‡ç­¾çš„ç½®ä¿¡åº¦ï¼‰\n",
    "            if original_label == \"æ­£é¢\":\n",
    "                score_change = original_conf - new_conf\n",
    "            else:\n",
    "                score_change = new_conf - original_conf\n",
    "            \n",
    "            # è®°å½•æœ€ä½³æ›¿æ¢\n",
    "            if score_change > best_score_change:\n",
    "                best_score_change = score_change\n",
    "                best_synonym = synonym\n",
    "        \n",
    "        # åº”ç”¨æœ€ä½³æ›¿æ¢ï¼ˆå³ä½¿æ²¡æœ‰æ”¹å˜æ ‡ç­¾ï¼Œä¹Ÿå°è¯•é™ä½ç½®ä¿¡åº¦ï¼‰\n",
    "        if best_synonym and best_score_change > 0.01:\n",
    "            replacements.append((word, best_synonym))\n",
    "            current_text = current_text.replace(word, best_synonym, 1)\n",
    "            \n",
    "            # æ£€æŸ¥æ˜¯å¦æ”»å‡»æˆåŠŸ\n",
    "            new_label, _ = analyze_sentiment(current_text)\n",
    "            if new_label != original_label:\n",
    "                return current_text, True, replacements\n",
    "            \n",
    "            # è¾¾åˆ°æœ€å¤§æ›¿æ¢æ¬¡æ•°\n",
    "            if len(replacements) >= max_replacements:\n",
    "                break\n",
    "    \n",
    "    # æ”»å‡»å¤±è´¥ï¼Œè¿”å›å½“å‰æœ€ä½³ç»“æœ\n",
    "    final_label, _ = analyze_sentiment(current_text)\n",
    "    success = (final_label != original_label)\n",
    "    return current_text, success, replacements\n",
    "\n",
    "print(\"âœ“ åŒä¹‰è¯æ›¿æ¢æ”»å‡»å‡½æ•°å®šä¹‰å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•åŒä¹‰è¯æ›¿æ¢æ”»å‡»\n",
    "test_sentences = [\n",
    "    \"è¿™ä¸ªäº§å“éå¸¸å¥½ï¼Œæˆ‘å¾ˆå–œæ¬¢ï¼\",\n",
    "    \"è´¨é‡ä¼˜ç§€ï¼Œä»·æ ¼ä¾¿å®œï¼Œå¼ºçƒˆæ¨èè´­ä¹°ï¼\",\n",
    "    \"å‘è´§å¿«ï¼Œäº§å“æ¼‚äº®ï¼Œéå¸¸æ»¡æ„ã€‚\",\n",
    "    \"å¤ªå·®äº†ï¼Œè´¨é‡å¾ˆå·®ï¼Œä¸æ¨èã€‚\",\n",
    "    \"ç”¨äº†å‡ å¤©å°±åäº†ï¼Œå¾ˆå¤±æœ›ã€‚\",\n",
    "]\n",
    "\n",
    "print(\"=\" * 75)\n",
    "print(\"âš”ï¸  åŒä¹‰è¯æ›¿æ¢æ”»å‡»æµ‹è¯•\")\n",
    "print(\"=\" * 75)\n",
    "\n",
    "for i, sentence in enumerate(test_sentences, 1):\n",
    "    orig_label, orig_conf = analyze_sentiment(sentence)\n",
    "    \n",
    "    # ========== å¡«ç©º 3ï¼šæ‰§è¡ŒåŒä¹‰è¯æ›¿æ¢æ”»å‡» ==========\n",
    "    # \n",
    "    # ğŸ¯ ä»»åŠ¡ï¼šå¯¹æ¯ä¸ªæµ‹è¯•å¥å­æ‰§è¡Œæ”»å‡»\n",
    "    # \n",
    "    # ğŸ’¡ æç¤ºï¼š\n",
    "    #   - è°ƒç”¨ synonym_attack å‡½æ•°\n",
    "    #   - å‚æ•°æ˜¯å½“å‰çš„ sentence\n",
    "    #   - è¿”å›ä¸‰ä¸ªå€¼ï¼šå¯¹æŠ—æ–‡æœ¬ã€æˆåŠŸæ ‡å¿—ã€æ›¿æ¢å†å²\n",
    "    # \n",
    "    # éš¾åº¦ï¼šâ­â˜†â˜†â˜†â˜†\n",
    "    \n",
    "    adv_text, success, replacements = ___________  # æœŸæœ›ï¼šsynonym_attack(sentence)\n",
    "    \n",
    "    adv_label, adv_conf = analyze_sentiment(adv_text)\n",
    "    \n",
    "    print(f\"\\nã€æµ‹è¯• {i}ã€‘\")\n",
    "    print(f\"  åŸæ–‡: {sentence}\")\n",
    "    print(f\"  åŸå§‹: {orig_label} ({orig_conf:.2%})\")\n",
    "    \n",
    "    if replacements:\n",
    "        print(f\"  æ›¿æ¢: {' â†’ '.join([f'{o}â†’{n}' for o, n in replacements])}\")\n",
    "    else:\n",
    "        print(f\"  æ›¿æ¢: æ— \")\n",
    "    \n",
    "    print(f\"  å¯¹æŠ—: {adv_text}\")\n",
    "    print(f\"  ç»“æœ: {adv_label} ({adv_conf:.2%})\", end=\" \")\n",
    "    \n",
    "    if success:\n",
    "        print(\"- âœ“ æ”»å‡»æˆåŠŸï¼\")\n",
    "    else:\n",
    "        print(\"- âœ— æ”»å‡»å¤±è´¥\")\n",
    "\n",
    "print(\"=\" * 75)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37006db4",
   "metadata": {},
   "source": [
    "### ğŸ¤” æ€è€ƒä¸€ä¸‹\n",
    "\n",
    "1. **æ”»å‡»éš¾åº¦**ï¼šæ–‡æœ¬æ”»å‡»æ¯”å›¾åƒæ”»å‡»æ›´å®¹æ˜“è¿˜æ˜¯æ›´éš¾ï¼Ÿä¸ºä»€ä¹ˆï¼Ÿ\n",
    "2. **è¯­ä¹‰ä¿æŒ**ï¼šåŒä¹‰è¯æ›¿æ¢æ˜¯å¦å®Œç¾ä¿æŒäº†åŸæ–‡çš„è¯­ä¹‰ï¼Ÿ\n",
    "3. **é˜²å¾¡ç­–ç•¥**ï¼šå¦‚æœä½ æ˜¯é˜²å¾¡è€…ï¼Œå¦‚ä½•æ£€æµ‹æˆ–é˜²å¾¡è¿™ç§æ”»å‡»ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-11",
   "metadata": {},
   "source": [
    "## ç¬¬å››éƒ¨åˆ†ï¼šæ‰¹é‡æµ‹è¯•ä¸æ•ˆæœåˆ†æ\n",
    "\n",
    "åœ¨æ›´å¤šæ ·æœ¬ä¸Šæµ‹è¯•æ”»å‡»æˆåŠŸç‡ï¼Œåˆ†ææ”»å‡»æ•ˆæœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ‰¹é‡æµ‹è¯•æ”»å‡»æˆåŠŸç‡\n",
    "test_samples = [\n",
    "    \"è¿™æ¬¾æ‰‹æœºéå¸¸å¥½ç”¨ï¼Œæˆ‘å¾ˆå–œæ¬¢ã€‚\",\n",
    "    \"äº§å“è´¨é‡ä¼˜ç§€ï¼Œç‰©æµä¹Ÿå¾ˆå¿«ã€‚\",\n",
    "    \"æœåŠ¡æ€åº¦å¥½ï¼Œäº§å“æ¼‚äº®ï¼Œæ»¡æ„ï¼\",\n",
    "    \"ä»·æ ¼ä¾¿å®œï¼Œæ€§ä»·æ¯”é«˜ï¼Œæ¨èè´­ä¹°ã€‚\",\n",
    "    \"ç‰©è¶…æ‰€å€¼ï¼Œå¼ºçƒˆæ¨èï¼\",\n",
    "    \"å¤ªå·®äº†ï¼Œè´¨é‡å¾ˆå·®ï¼Œå¤±æœ›ã€‚\",\n",
    "    \"å‘è´§æ…¢ï¼Œäº§å“éš¾ç”¨ï¼Œä¸æ»¡æ„ã€‚\",\n",
    "    \"å¾ˆå¤±æœ›ï¼Œå®Œå…¨ä¸æ¨èã€‚\",\n",
    "    \"è´µè€Œä¸”è´¨é‡å·®ï¼Œåæ‚”ä¹°äº†ã€‚\",\n",
    "    \"ç”¨äº†ä¸€å¤©å°±åäº†ï¼ŒçœŸå·®ã€‚\",\n",
    "]\n",
    "\n",
    "# ========== å¡«ç©º 4ï¼šæ‰¹é‡æµ‹è¯•å¹¶ç»Ÿè®¡ç»“æœ ==========\n",
    "# \n",
    "# ğŸ¯ ä»»åŠ¡ï¼šå¯¹æ‰€æœ‰æ ·æœ¬æ‰§è¡Œæ”»å‡»å¹¶ç»Ÿè®¡æˆåŠŸç‡\n",
    "# \n",
    "# ğŸ’¡ æç¤ºï¼š\n",
    "#   - éå† test_samples\n",
    "#   - å¯¹æ¯ä¸ªæ ·æœ¬è°ƒç”¨ synonym_attack\n",
    "#   - ç»Ÿè®¡æˆåŠŸæ¬¡æ•°å’Œå¹³å‡æ›¿æ¢è¯æ•°\n",
    "# \n",
    "# éš¾åº¦ï¼šâ­â­â˜†â˜†â˜†\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ“Š æ‰¹é‡æ”»å‡»æµ‹è¯•\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'æ ·æœ¬':<35} {'æ›¿æ¢è¯æ•°':<12} {'æ”»å‡»ç»“æœ':<12}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "success_count = 0\n",
    "total_replacements = 0\n",
    "successful_replacements = []\n",
    "\n",
    "for sample in test_samples:\n",
    "    adv_text, success, replacements = ___________  # æœŸæœ›ï¼šsynonym_attack(sample)\n",
    "    \n",
    "    if success:\n",
    "        success_count += 1\n",
    "        num_replacements = len(replacements)\n",
    "        total_replacements += num_replacements\n",
    "        successful_replacements.append(num_replacements)\n",
    "        print(f\"{sample[:32]:<35} {num_replacements:<12} {'âœ“ æˆåŠŸ':<12}\")\n",
    "    else:\n",
    "        print(f\"{sample[:32]:<35} {len(replacements):<12} {'âœ— å¤±è´¥':<12}\")\n",
    "\n",
    "print(\"-\" * 70)\n",
    "print(f\"\\næ”»å‡»æˆåŠŸç‡: {success_count}/{len(test_samples)} ({success_count/len(test_samples)*100:.1f}%)\")\n",
    "\n",
    "if success_count > 0:\n",
    "    avg_replacements = total_replacements / success_count\n",
    "    print(f\"æˆåŠŸæ”»å‡»çš„å¹³å‡æ›¿æ¢è¯æ•°: {avg_replacements:.2f}\")\n",
    "    print(f\"æœ€å°‘æ›¿æ¢è¯æ•°: {min(successful_replacements)}\")\n",
    "    print(f\"æœ€å¤šæ›¿æ¢è¯æ•°: {max(successful_replacements)}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–æ”»å‡»å‰åçš„æƒ…æ„Ÿå˜åŒ–\n",
    "print(\"\\nå¯è§†åŒ–æ”»å‡»æ•ˆæœ...\")\n",
    "\n",
    "original_scores = []\n",
    "adversarial_scores = []\n",
    "labels_list = []\n",
    "attack_success = []\n",
    "\n",
    "for sample in test_samples:\n",
    "    orig_score = get_positive_score(sample)\n",
    "    adv_text, success, _ = synonym_attack(sample)\n",
    "    adv_score = get_positive_score(adv_text)\n",
    "    \n",
    "    original_scores.append(orig_score)\n",
    "    adversarial_scores.append(adv_score)\n",
    "    labels_list.append(sample[:8] + \"...\")\n",
    "    attack_success.append(success)\n",
    "\n",
    "# ç»˜åˆ¶å¯¹æ¯”å›¾\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# å·¦å›¾ï¼šç½®ä¿¡åº¦å¯¹æ¯”\n",
    "x = np.arange(len(labels_list))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax1.bar(x - width/2, original_scores, width, label='åŸå§‹', color='steelblue', alpha=0.8)\n",
    "bars2 = ax1.bar(x + width/2, adversarial_scores, width, label='æ”»å‡»å', color='coral', alpha=0.8)\n",
    "\n",
    "# æ ‡è®°æ”»å‡»æˆåŠŸçš„æ ·æœ¬\n",
    "for i, success in enumerate(attack_success):\n",
    "    if success:\n",
    "        ax1.plot([i - width/2, i + width/2], \n",
    "                [original_scores[i], adversarial_scores[i]], \n",
    "                'g--', linewidth=2, alpha=0.5)\n",
    "\n",
    "ax1.axhline(y=0.5, color='gray', linestyle='--', linewidth=1.5, label='å†³ç­–è¾¹ç•Œ', alpha=0.7)\n",
    "ax1.set_ylabel('æ­£é¢æƒ…æ„Ÿç½®ä¿¡åº¦', fontsize=12)\n",
    "ax1.set_title('åŒä¹‰è¯æ›¿æ¢æ”»å‡»ï¼šæƒ…æ„Ÿç½®ä¿¡åº¦å˜åŒ–', fontsize=13, fontweight='bold')\n",
    "ax1.set_xticks(x)\n",
    "ax1.set_xticklabels(labels_list, rotation=45, ha='right', fontsize=9)\n",
    "ax1.legend(fontsize=10)\n",
    "ax1.set_ylim(0, 1)\n",
    "ax1.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# å³å›¾ï¼šæ”»å‡»æˆåŠŸç‡ç»Ÿè®¡\n",
    "success_counts = [sum(attack_success), len(attack_success) - sum(attack_success)]\n",
    "colors = ['green', 'red']\n",
    "labels = [f'æˆåŠŸ ({success_counts[0]})', f'å¤±è´¥ ({success_counts[1]})']\n",
    "\n",
    "ax2.pie(success_counts, labels=labels, colors=colors, autopct='%1.1f%%', \n",
    "        startangle=90, textprops={'fontsize': 12})\n",
    "ax2.set_title(f'æ”»å‡»æˆåŠŸç‡ç»Ÿè®¡\\næ€»æ ·æœ¬æ•°: {len(test_samples)}', \n",
    "              fontsize=13, fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## ç¬¬äº”éƒ¨åˆ†ï¼šé«˜çº§æ”»å‡»æŠ€å·§æ¼”ç¤º\n",
    "\n",
    "é™¤äº†åŒä¹‰è¯æ›¿æ¢ï¼Œè¿˜æœ‰å…¶ä»–æ–‡æœ¬æ”»å‡»æ–¹æ³•ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "### æŠ€å·§ 1ï¼šåŒå½¢å­—æ›¿æ¢ï¼ˆè§†è§‰æ··æ·†ï¼‰\n",
    "\n",
    "# å®šä¹‰åŒå½¢å­—æ˜ å°„ï¼ˆå¤–è§‚ç›¸ä¼¼ä½†ç¼–ç ä¸åŒçš„å­—ç¬¦ï¼‰\n",
    "SIMILAR_CHARS = {\n",
    "    'å¥½': 'å¦¤',   # å½¢è¿‘å­—\n",
    "    'å–œ': 'å˜‰',\n",
    "    'ä¼˜': 'å¿§',\n",
    "    'æ¨': 'æ¨',   # å…¨è§’/åŠè§’\n",
    "    'è': 'è',\n",
    "    'è´¨': 'è²­',\n",
    "    'é‡': 'ç³§',\n",
    "}\n",
    "\n",
    "def similar_char_attack(text):\n",
    "    \"\"\"\n",
    "    åŒå½¢å­—æ›¿æ¢æ”»å‡»\n",
    "    \n",
    "    åŸç†ï¼šä½¿ç”¨å¤–è§‚ç›¸ä¼¼çš„å­—ç¬¦æ›¿æ¢åŸå­—ç¬¦\n",
    "    ç‰¹ç‚¹ï¼šäººçœ¼éš¾ä»¥å¯Ÿè§‰ï¼Œä½†æ”¹å˜äº†å­—ç¬¦ç¼–ç \n",
    "    \"\"\"\n",
    "    result = list(text)\n",
    "    replacements = []\n",
    "    \n",
    "    for i, char in enumerate(result):\n",
    "        if char in SIMILAR_CHARS:\n",
    "            result[i] = SIMILAR_CHARS[char]\n",
    "            replacements.append((char, SIMILAR_CHARS[char]))\n",
    "    \n",
    "    return ''.join(result), replacements\n",
    "\n",
    "# æ¼”ç¤ºåŒå½¢å­—æ”»å‡»\n",
    "test_text = \"è¿™ä¸ªäº§å“è´¨é‡å¥½ï¼Œæˆ‘å¾ˆå–œæ¬¢ï¼\"\n",
    "similar_text, sim_replacements = similar_char_attack(test_text)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"ğŸ­ åŒå½¢å­—æ›¿æ¢æ”»å‡»æ¼”ç¤º\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"åŸå§‹æ–‡æœ¬: {test_text}\")\n",
    "print(f\"æ”»å‡»æ–‡æœ¬: {similar_text}\")\n",
    "print(f\"æ›¿æ¢è®°å½•: {sim_replacements}\")\n",
    "print(f\"\\nåŸå§‹åˆ†æ: {analyze_sentiment(test_text)}\")\n",
    "print(f\"æ”»å‡»åˆ†æ: {analyze_sentiment(similar_text)}\")\n",
    "print(\"\\nğŸ’¡ æ³¨æ„ï¼šä¸¤æ®µæ–‡æœ¬çœ‹èµ·æ¥å‡ ä¹ä¸€æ ·ï¼Œä½†å­—ç¬¦ç¼–ç ä¸åŒ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c734bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### æŠ€å·§ 2ï¼šå­—ç¬¦æ’å…¥æ”»å‡»ï¼ˆæ·»åŠ å¹²æ‰°ï¼‰\n",
    "\n",
    "def character_insertion_attack(text, insert_char='â€‹'):\n",
    "    \"\"\"\n",
    "    å­—ç¬¦æ’å…¥æ”»å‡»\n",
    "    \n",
    "    åŸç†ï¼šåœ¨è¯è¯­ä¸­æ’å…¥é›¶å®½å­—ç¬¦æˆ–ç©ºæ ¼\n",
    "    ç‰¹ç‚¹ï¼šä¸æ”¹å˜è§†è§‰æ•ˆæœï¼Œä½†å½±å“åˆ†è¯\n",
    "    \n",
    "    å‚æ•°:\n",
    "        text: åŸå§‹æ–‡æœ¬\n",
    "        insert_char: è¦æ’å…¥çš„å­—ç¬¦ï¼ˆé»˜è®¤é›¶å®½ç©ºæ ¼ï¼‰\n",
    "    \"\"\"\n",
    "    # åœ¨æ¯ä¸ªå­—ä¹‹é—´æ’å…¥é›¶å®½å­—ç¬¦\n",
    "    result = insert_char.join(list(text))\n",
    "    return result\n",
    "\n",
    "# ========== å¡«ç©º 5ï¼šæµ‹è¯•å­—ç¬¦æ’å…¥æ”»å‡» ==========\n",
    "# \n",
    "# ğŸ¯ ä»»åŠ¡ï¼šå¯¹æµ‹è¯•æ–‡æœ¬æ‰§è¡Œå­—ç¬¦æ’å…¥æ”»å‡»å¹¶è§‚å¯Ÿæ•ˆæœ\n",
    "# \n",
    "# ğŸ’¡ æç¤ºï¼š\n",
    "#   - è°ƒç”¨ character_insertion_attack å‡½æ•°\n",
    "#   - å‚æ•°æ˜¯ test_text\n",
    "#   - è§‚å¯Ÿå¯¹æ¨¡å‹é¢„æµ‹çš„å½±å“\n",
    "# \n",
    "# éš¾åº¦ï¼šâ­â˜†â˜†â˜†â˜†\n",
    "\n",
    "inserted_text = ___________  # æœŸæœ›ï¼šcharacter_insertion_attack(test_text)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ğŸ”¤ å­—ç¬¦æ’å…¥æ”»å‡»æ¼”ç¤º\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"åŸå§‹æ–‡æœ¬: {test_text}\")\n",
    "print(f\"æ’å…¥åæ–‡æœ¬: {inserted_text}\")\n",
    "print(f\"æ–‡æœ¬é•¿åº¦: {len(test_text)} â†’ {len(inserted_text)}\")\n",
    "print(f\"\\nåŸå§‹åˆ†æ: {analyze_sentiment(test_text)}\")\n",
    "print(f\"æ’å…¥ååˆ†æ: {analyze_sentiment(inserted_text)}\")\n",
    "print(\"\\nğŸ’¡ æ’å…¥é›¶å®½å­—ç¬¦å¯èƒ½å¹²æ‰°åˆ†è¯å’Œæ¨¡å‹ç†è§£\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## ğŸ“‹ å®éªŒå°ç»“\n",
    "\n",
    "### æ ¸å¿ƒæ”¶è·\n",
    "\n",
    "é€šè¿‡æœ¬å®éªŒï¼Œä½ å·²ç»ï¼š\n",
    "\n",
    "1. **ç†è§£å·®å¼‚**ï¼šæŒæ¡äº†æ–‡æœ¬ä¸å›¾åƒå¯¹æŠ—æ”»å‡»çš„æœ¬è´¨åŒºåˆ«\n",
    "2. **å®ç°æ”»å‡»**ï¼šæˆåŠŸå®ç°äº†åŸºäºåŒä¹‰è¯æ›¿æ¢çš„æ–‡æœ¬å¯¹æŠ—æ”»å‡»\n",
    "3. **åˆ†æé‡è¦æ€§**ï¼šå­¦ä¼šäº†è®¡ç®—è¯é‡è¦æ€§å¹¶è®¾è®¡é’ˆå¯¹æ€§æ”»å‡»\n",
    "4. **æ¢ç´¢æŠ€å·§**ï¼šäº†è§£äº†å¤šç§æ–‡æœ¬æ”»å‡»æ–¹æ³•ï¼ˆåŒå½¢å­—ã€å­—ç¬¦æ’å…¥ç­‰ï¼‰\n",
    "\n",
    "### å…³é”®æ¦‚å¿µå›é¡¾\n",
    "\n",
    "**æ–‡æœ¬å¯¹æŠ—æ”»å‡»çš„ä¸‰å¤§æŒ‘æˆ˜**ï¼š\n",
    "\n",
    "| æŒ‘æˆ˜ | æè¿° | è§£å†³æ–¹æ¡ˆ |\n",
    "|------|------|---------|\n",
    "| **ç¦»æ•£æ€§** | æ–‡æœ¬ç”±ç¦»æ•£çš„è¯ç»„æˆï¼Œä¸èƒ½å¾®å°æ”¹å˜ | åŒä¹‰è¯æ›¿æ¢ã€å­—ç¬¦å˜æ¢ |\n",
    "| **è¯­ä¹‰ä¿æŒ** | å¿…é¡»ä¿æŒåŸæ–‡è¯­ä¹‰ä¸å˜ | ä½¿ç”¨åŒä¹‰è¯åº“ã€è¯­è¨€æ¨¡å‹éªŒè¯ |\n",
    "| **è¯­æ³•æ­£ç¡®** | é¿å…äº§ç”Ÿè¯­æ³•é”™è¯¯ | åŸºäºè§„åˆ™çš„æ›¿æ¢ã€è¯­æ³•æ£€æŸ¥ |\n",
    "\n",
    "**æ”»å‡»æ–¹æ³•å¯¹æ¯”**ï¼š\n",
    "\n",
    "| æ–¹æ³• | åŸç† | ä¼˜ç‚¹ | ç¼ºç‚¹ | é€‚ç”¨åœºæ™¯ |\n",
    "|------|------|------|------|---------|\n",
    "| **åŒä¹‰è¯æ›¿æ¢** | ç”¨åŒä¹‰è¯æ›¿æ¢åŸè¯ | ä¿æŒè¯­ä¹‰ï¼ŒæˆåŠŸç‡é«˜ | éœ€è¦åŒä¹‰è¯åº“ | é€šç”¨æ–‡æœ¬æ”»å‡» |\n",
    "| **åŒå½¢å­—æ›¿æ¢** | ç”¨å¤–è§‚ç›¸ä¼¼çš„å­—ç¬¦ | äººçœ¼éš¾å¯Ÿè§‰ | å¯èƒ½æ”¹å˜è¯­ä¹‰ | è§†è§‰æ··æ·†æ”»å‡» |\n",
    "| **å­—ç¬¦æ’å…¥** | æ’å…¥é›¶å®½å­—ç¬¦ | ä¸æ”¹å˜è§†è§‰ | å®¹æ˜“è¢«è¿‡æ»¤ | ç»•è¿‡å…³é”®è¯æ£€æµ‹ |\n",
    "| **è¯åºè°ƒæ•´** | æ”¹å˜è¯çš„é¡ºåº | ç®€å•ç›´æ¥ | å¯èƒ½è¯­æ³•é”™è¯¯ | å¥æ³•ä¸æ•æ„Ÿæ¨¡å‹ |\n",
    "\n",
    "### å®éªŒè§‚å¯Ÿ\n",
    "\n",
    "æ ¹æ®å®éªŒç»“æœï¼Œé€šå¸¸å¯è§‚å¯Ÿåˆ°ï¼š\n",
    "- **æ”»å‡»æˆåŠŸç‡**ï¼šåŒä¹‰è¯æ›¿æ¢åœ¨æƒ…æ„Ÿåˆ†æä»»åŠ¡ä¸Šçš„æˆåŠŸç‡é€šå¸¸åœ¨ 60-80%\n",
    "- **æ›¿æ¢æ•ˆç‡**ï¼šå¹³å‡åªéœ€æ›¿æ¢ 1-3 ä¸ªå…³é”®è¯å°±èƒ½æ”¹å˜é¢„æµ‹\n",
    "- **è¯é‡è¦æ€§**ï¼šæƒ…æ„Ÿè¯ï¼ˆå¦‚\"å¥½\"ã€\"å·®\"ï¼‰çš„é‡è¦æ€§è¿œé«˜äºä¸­æ€§è¯\n",
    "- **æ¨¡å‹è„†å¼±æ€§**ï¼šå³ä½¿æ˜¯BERTè¿™æ ·çš„å¤§æ¨¡å‹ä¹Ÿå®¹æ˜“å—åˆ°æ”»å‡»\n",
    "\n",
    "### å®é™…åº”ç”¨åœºæ™¯\n",
    "\n",
    "æ–‡æœ¬å¯¹æŠ—æ”»å‡»çš„ç°å®å¨èƒï¼š\n",
    "- **åƒåœ¾é‚®ä»¶æ£€æµ‹**ï¼šç»•è¿‡åƒåœ¾é‚®ä»¶è¿‡æ»¤å™¨\n",
    "- **å†…å®¹å®¡æ ¸**ï¼šè§„é¿æ•æ„Ÿè¯æ£€æµ‹\n",
    "- **æƒ…æ„Ÿåˆ†æ**ï¼šæ“çºµè¯„è®ºæƒ…æ„Ÿåˆ¤æ–­\n",
    "- **æ–‡æœ¬åˆ†ç±»**ï¼šè¯¯å¯¼æ–°é—»åˆ†ç±»ç³»ç»Ÿ\n",
    "\n",
    "### é˜²å¾¡ç­–ç•¥\n",
    "\n",
    "1. **è¾“å…¥é¢„å¤„ç†**ï¼š\n",
    "   - å­—ç¬¦å½’ä¸€åŒ–ï¼ˆå…¨è§’â†’åŠè§’ï¼‰\n",
    "   - å»é™¤ç‰¹æ®Šå­—ç¬¦\n",
    "   - æ‹¼å†™æ£€æŸ¥\n",
    "\n",
    "2. **å¯¹æŠ—è®­ç»ƒ**ï¼š\n",
    "   - ç”¨å¯¹æŠ—æ ·æœ¬å¢å¼ºè®­ç»ƒé›†\n",
    "   - æé«˜æ¨¡å‹å¯¹æ‰°åŠ¨çš„é²æ£’æ€§\n",
    "\n",
    "3. **é›†æˆæ–¹æ³•**ï¼š\n",
    "   - å¤šä¸ªæ¨¡å‹æŠ•ç¥¨\n",
    "   - åŸºäºè§„åˆ™çš„éªŒè¯\n",
    "\n",
    "4. **æ£€æµ‹æœºåˆ¶**ï¼š\n",
    "   - è¯­æ³•æ£€æŸ¥\n",
    "   - è¯­ä¹‰ä¸€è‡´æ€§éªŒè¯\n",
    "   - å¼‚å¸¸æ¨¡å¼æ£€æµ‹\n",
    "\n",
    "### å¡«ç©ºå‚è€ƒç­”æ¡ˆ\n",
    "\n",
    "<details>\n",
    "<summary>ç‚¹å‡»æŸ¥çœ‹æ‰€æœ‰å¡«ç©ºå‚è€ƒç­”æ¡ˆ</summary>\n",
    "\n",
    "**å¡«ç©º 1ï¼šè®¡ç®—åˆ é™¤è¯¥å­—åçš„æ–‡æœ¬**\n",
    "```python\n",
    "chars_without_i = chars[:i] + chars[i+1:]\n",
    "```\n",
    "\n",
    "**å¡«ç©º 2ï¼šåˆ›å»ºæ›¿æ¢åçš„æ–‡æœ¬**\n",
    "```python\n",
    "test_text = current_text.replace(word, synonym, 1)\n",
    "```\n",
    "\n",
    "**å¡«ç©º 3ï¼šæ‰§è¡ŒåŒä¹‰è¯æ›¿æ¢æ”»å‡»**\n",
    "```python\n",
    "adv_text, success, replacements = synonym_attack(sentence)\n",
    "```\n",
    "\n",
    "**å¡«ç©º 4ï¼šæ‰¹é‡æµ‹è¯•å¹¶ç»Ÿè®¡ç»“æœ**\n",
    "```python\n",
    "adv_text, success, replacements = synonym_attack(sample)\n",
    "```\n",
    "\n",
    "**å¡«ç©º 5ï¼šæµ‹è¯•å­—ç¬¦æ’å…¥æ”»å‡»**\n",
    "```python\n",
    "inserted_text = character_insertion_attack(test_text)\n",
    "```\n",
    "\n",
    "</details>\n",
    "\n",
    "### å»¶ä¼¸å­¦ä¹ \n",
    "\n",
    "- **è®ºæ–‡é˜…è¯»**ï¼š\n",
    "  - \"Adversarial Examples for Evaluating Reading Comprehension Systems\" (EMNLP 2017)\n",
    "  - \"TextFooler: Is BERT Really Robust?\" (AAAI 2020)\n",
    "  - \"BAE: BERT-based Adversarial Examples for Text Classification\" (EMNLP 2020)\n",
    "\n",
    "- **è¿›é˜¶æŒ‘æˆ˜**ï¼š\n",
    "  - å®ç°åŸºäºé—ä¼ ç®—æ³•çš„æ–‡æœ¬æ”»å‡»\n",
    "  - ä½¿ç”¨è¯­è¨€æ¨¡å‹ç”Ÿæˆæ›´è‡ªç„¶çš„å¯¹æŠ—æ ·æœ¬\n",
    "  - æ¢ç´¢é’ˆå¯¹æœºå™¨ç¿»è¯‘ã€é—®ç­”ç³»ç»Ÿçš„æ”»å‡»\n",
    "\n",
    "- **å·¥å…·æ¨è**ï¼š\n",
    "  - TextAttackï¼šæ–‡æœ¬å¯¹æŠ—æ”»å‡»æ¡†æ¶\n",
    "  - OpenAttackï¼šå¼€æºæ–‡æœ¬å¯¹æŠ—æ”»å‡»åº“\n",
    "\n",
    "### ğŸ¤” æ·±å…¥æ€è€ƒ\n",
    "\n",
    "1. **ä¼¦ç†é—®é¢˜**ï¼šæ–‡æœ¬å¯¹æŠ—æ”»å‡»ç ”ç©¶æ˜¯å¦åº”è¯¥è¢«é™åˆ¶ï¼Ÿå¦‚ä½•å¹³è¡¡ç ”ç©¶å’Œå®‰å…¨ï¼Ÿ\n",
    "2. **å®ç”¨æ€§**ï¼šåœ¨å“ªäº›åœºæ™¯ä¸‹ï¼Œæ”»å‡»è€…æœ€æœ‰å¯èƒ½ä½¿ç”¨æ–‡æœ¬å¯¹æŠ—æ”»å‡»ï¼Ÿ\n",
    "3. **æœªæ¥æ–¹å‘**ï¼šå¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚ GPTã€Claudeï¼‰æ˜¯å¦æ›´å®¹æ˜“æˆ–æ›´éš¾è¢«æ”»å‡»ï¼Ÿ\n",
    "4. **é˜²å¾¡æ€è·¯**ï¼šèƒ½å¦è®¾è®¡ä¸€ä¸ªå¯¹æ–‡æœ¬å¯¹æŠ—æ”»å‡»å®Œå…¨é²æ£’çš„æ¨¡å‹ï¼Ÿ\n",
    "\n",
    "### å®‰å…¨æé†’\n",
    "\n",
    "âš ï¸ **æœ¬å®éªŒä»…ç”¨äºæ•™è‚²ç›®çš„**\n",
    "\n",
    "æ–‡æœ¬å¯¹æŠ—æ”»å‡»æ˜¯è¯„ä¼°NLPç³»ç»Ÿå®‰å…¨æ€§çš„é‡è¦å·¥å…·ã€‚è¯·å°†æ‰€å­¦çŸ¥è¯†ç”¨äºï¼š\n",
    "- æµ‹è¯•å’Œæå‡è‡ªå·±ç³»ç»Ÿçš„é²æ£’æ€§\n",
    "- å¼€å‘é˜²å¾¡æ–¹æ³•å’Œæ£€æµ‹æœºåˆ¶\n",
    "- æ¨è¿›å®‰å…¨NLPç ”ç©¶\n",
    "\n",
    "è¯·å‹¿ç”¨äºï¼š\n",
    "- ç»•è¿‡å†…å®¹å®¡æ ¸ç³»ç»Ÿå‘å¸ƒè¿è§„å†…å®¹\n",
    "- åˆ¶é€ è™šå‡è¯„è®ºå’Œæ¶æ„ä¿¡æ¯\n",
    "- æ”»å‡»ä»–äººçš„æœåŠ¡å’Œç³»ç»Ÿ\n",
    "\n",
    "### ğŸ‰ æ¨¡å—ä¸‰å®Œæˆï¼\n",
    "\n",
    "æ­å–œä½ å®Œæˆäº†æ¨¡å—ä¸‰çš„æ‰€æœ‰å®éªŒï¼ä½ å·²ç»æŒæ¡äº†ï¼š\n",
    "- âœ… å›¾åƒå¯¹æŠ—æ”»å‡»ï¼ˆFGSM, PGDï¼‰\n",
    "- âœ… è¿ç§»æ”»å‡»ï¼ˆé»‘ç›’åœºæ™¯ï¼‰\n",
    "- âœ… æ–‡æœ¬å¯¹æŠ—æ”»å‡»\n",
    "\n",
    "ç»§ç»­å­¦ä¹ åç»­æ¨¡å—ï¼Œæ¢ç´¢æ›´å¤šAIå®‰å…¨è¯é¢˜ï¼"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
