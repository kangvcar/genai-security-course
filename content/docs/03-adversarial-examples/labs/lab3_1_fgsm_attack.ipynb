{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# å®éªŒ 3.1ï¼šFGSM ç™½ç›’å¯¹æŠ—æ”»å‡»\n",
    "\n",
    "## ğŸ¯ å­¦ä¹ ç›®æ ‡\n",
    "\n",
    "å®Œæˆæœ¬å®éªŒåï¼Œä½ å°†èƒ½å¤Ÿï¼š\n",
    "- è§£é‡Š FGSMï¼ˆå¿«é€Ÿæ¢¯åº¦ç¬¦å·æ³•ï¼‰çš„æ”»å‡»åŸç†\n",
    "- å®ç°åŸºäºæ¢¯åº¦çš„å¯¹æŠ—æ ·æœ¬ç”Ÿæˆæ–¹æ³•\n",
    "- åˆ†ææ‰°åŠ¨å¼ºåº¦å¯¹æ”»å‡»æ•ˆæœå’Œéšè”½æ€§çš„å½±å“\n",
    "- ç†è§£ç™½ç›’æ”»å‡»çš„å¨èƒåŠå…¶åœ¨çœŸå®åœºæ™¯ä¸­çš„æ„ä¹‰\n",
    "\n",
    "## ğŸ“š å‰ç½®çŸ¥è¯†\n",
    "\n",
    "- ç†è§£ç¥ç»ç½‘ç»œçš„å‰å‘ä¼ æ’­å’Œåå‘ä¼ æ’­\n",
    "- äº†è§£æ¢¯åº¦å’ŒæŸå¤±å‡½æ•°çš„æ¦‚å¿µ\n",
    "- å®Œæˆæ¨¡å—ä¸‰ç†è®ºç« èŠ‚ï¼šã€Šå¯¹æŠ—æ ·æœ¬åŸºç¡€ã€‹\n",
    "\n",
    "## ğŸ–¥ï¸ å®éªŒç¯å¢ƒ\n",
    "\n",
    "- å¹³å°ï¼šè…¾è®¯ Cloud Studioï¼ˆhttps://cloudstudio.net/ï¼‰\n",
    "- GPUï¼šNVIDIA Tesla T4ï¼ˆ16GB æ˜¾å­˜ï¼‰\n",
    "- æ¨¡å‹ï¼šResNet-18ï¼ˆImageNet é¢„è®­ç»ƒï¼‰\n",
    "- æ¡†æ¶ï¼šPyTorch 2.0+\n",
    "\n",
    "## ğŸ“ å¡«ç©ºè¯´æ˜\n",
    "\n",
    "æœ¬å®éªŒå…± **4 ä¸ªå¡«ç©ºç»ƒä¹ **ï¼Œéš¾åº¦ï¼šâ­â­â­â˜†â˜†"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸€éƒ¨åˆ†ï¼šç¯å¢ƒå‡†å¤‡ä¸ä¾èµ–å®‰è£…"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®‰è£…å¿…è¦çš„ä¾èµ–ï¼ˆé¦–æ¬¡è¿è¡Œéœ€è¦å‡ åˆ†é’Ÿï¼‰\n",
    "%pip install torch torchvision -q\n",
    "\n",
    "# å¯¼å…¥å¿…è¦çš„åº“\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import models, transforms\n",
    "from PIL import Image\n",
    "\n",
    "# è®¾ç½®ä¸­æ–‡æ˜¾ç¤º\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei', 'Arial Unicode MS', 'DejaVu Sans']\n",
    "plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "# è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å®éªŒå¯é‡å¤\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "\n",
    "# æ£€æŸ¥ç¯å¢ƒ\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ”§ ç¯å¢ƒæ£€æŸ¥\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  PyTorch ç‰ˆæœ¬: {torch.__version__}\")\n",
    "print(f\"  CUDA å¯ç”¨: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"  GPU è®¾å¤‡: {torch.cuda.get_device_name(0)}\")\n",
    "print(\"âœ“ ç¯å¢ƒå‡†å¤‡å®Œæˆï¼\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åŠ è½½é¢„è®­ç»ƒçš„ ResNet-18 æ¨¡å‹\n",
    "# ResNet-18 æ˜¯ä¸€ä¸ªåœ¨ ImageNet æ•°æ®é›†ä¸Šè®­ç»ƒçš„å›¾åƒåˆ†ç±»æ¨¡å‹\n",
    "# ImageNet åŒ…å« 1000 ä¸ªç±»åˆ«çš„æ—¥å¸¸ç‰©ä½“å›¾åƒ\n",
    "\n",
    "print(\"æ­£åœ¨åŠ è½½é¢„è®­ç»ƒæ¨¡å‹...\")\n",
    "model = models.resnet18(pretrained=True)\n",
    "model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼ï¼ˆå…³é—­ Dropout å’Œ BatchNorm çš„è®­ç»ƒè¡Œä¸ºï¼‰\n",
    "\n",
    "# ç»Ÿè®¡æ¨¡å‹å‚æ•°\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"âœ“ ResNet-18 æ¨¡å‹åŠ è½½æˆåŠŸï¼\")\n",
    "print(f\"  å‚æ•°é‡: {total_params:,} (~11M)\")\n",
    "print(f\"  è¾“å‡ºç±»åˆ«: 1000 (ImageNet ç±»åˆ«)\")\n",
    "\n",
    "# ImageNet ç±»åˆ«æ ‡ç­¾ï¼ˆéƒ¨åˆ†å¸¸è§ç±»åˆ«ï¼Œç”¨äºæ¼”ç¤ºï¼‰\n",
    "IMAGENET_LABELS = {\n",
    "    0: \"è¾èˆ\", 1: \"é‡‘é±¼\", 2: \"å¤§ç™½é²¨\", 3: \"è™é²¨\", \n",
    "    7: \"å…¬é¸¡\", 8: \"æ¯é¸¡\", 9: \"é¸µé¸Ÿ\", \n",
    "    281: \"è™æ–‘çŒ«\", 282: \"è™\", 285: \"åŸƒåŠçŒ«\", 291: \"ç‹®å­\",\n",
    "    388: \"å¤§ç†ŠçŒ«\", 389: \"å°ç†ŠçŒ«\",\n",
    "    417: \"æ°”çƒ\", 433: \"æµ´ç¼¸\", \n",
    "    504: \"å’–å•¡æ¯\", 605: \"iPod\", \n",
    "    852: \"ç½‘çƒ\", 920: \"ç›˜å­\"\n",
    "}\n",
    "\n",
    "print(f\"  å·²åŠ è½½ {len(IMAGENET_LABELS)} ä¸ªå¸¸è§ç±»åˆ«æ ‡ç­¾\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰å›¾åƒé¢„å¤„ç†å’Œè¾…åŠ©å‡½æ•°\n",
    "\n",
    "# ImageNet æ¨¡å‹éœ€è¦ç‰¹å®šçš„è¾“å…¥æ ¼å¼å’Œå½’ä¸€åŒ–\n",
    "preprocess = transforms.Compose([\n",
    "    transforms.Resize(256),           # ç¼©æ”¾åˆ° 256x256\n",
    "    transforms.CenterCrop(224),       # ä¸­å¿ƒè£å‰ªåˆ° 224x224\n",
    "    transforms.ToTensor(),            # è½¬æ¢ä¸ºå¼ é‡ï¼ŒèŒƒå›´ [0, 1]\n",
    "])\n",
    "\n",
    "# ImageNet æ ‡å‡†åŒ–å‚æ•°ï¼ˆæ ¹æ®è®­ç»ƒé›†ç»Ÿè®¡å¾—å‡ºï¼‰\n",
    "normalize = transforms.Normalize(\n",
    "    mean=[0.485, 0.456, 0.406],  # RGB ä¸‰é€šé“çš„å‡å€¼\n",
    "    std=[0.229, 0.224, 0.225]     # RGB ä¸‰é€šé“çš„æ ‡å‡†å·®\n",
    ")\n",
    "\n",
    "def predict(model, img_tensor):\n",
    "    \"\"\"\n",
    "    ä½¿ç”¨æ¨¡å‹å¯¹å›¾åƒè¿›è¡Œé¢„æµ‹\n",
    "    \n",
    "    å‚æ•°:\n",
    "        model: é¢„è®­ç»ƒæ¨¡å‹\n",
    "        img_tensor: å›¾åƒå¼ é‡ [C, H, W]ï¼ŒèŒƒå›´ [0, 1]\n",
    "    \n",
    "    è¿”å›:\n",
    "        pred_class: é¢„æµ‹ç±»åˆ«ï¼ˆæ•´æ•°ï¼‰\n",
    "        confidence: é¢„æµ‹ç½®ä¿¡åº¦ï¼ˆæ¦‚ç‡ï¼‰\n",
    "    \"\"\"\n",
    "    # æ­¥éª¤1ï¼šå½’ä¸€åŒ–å›¾åƒ\n",
    "    input_tensor = normalize(img_tensor).unsqueeze(0)  # æ·»åŠ  batch ç»´åº¦ [1, C, H, W]\n",
    "    \n",
    "    # æ­¥éª¤2ï¼šå‰å‘ä¼ æ’­\n",
    "    with torch.no_grad():  # ä¸è®¡ç®—æ¢¯åº¦ï¼ŒèŠ‚çœå†…å­˜\n",
    "        output = model(input_tensor)\n",
    "    \n",
    "    # æ­¥éª¤3ï¼šè®¡ç®—æ¦‚ç‡ï¼ˆä½¿ç”¨ softmaxï¼‰\n",
    "    probs = torch.softmax(output, dim=1)\n",
    "    \n",
    "    # æ­¥éª¤4ï¼šè·å–é¢„æµ‹ç±»åˆ«å’Œç½®ä¿¡åº¦\n",
    "    pred_class = output.argmax(dim=1).item()\n",
    "    confidence = probs[0, pred_class].item()\n",
    "    \n",
    "    return pred_class, confidence\n",
    "\n",
    "print(\"âœ“ è¾…åŠ©å‡½æ•°å®šä¹‰å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬äºŒéƒ¨åˆ†ï¼šå‡†å¤‡æµ‹è¯•å›¾åƒå¹¶è§‚å¯ŸåŸå§‹é¢„æµ‹\n",
    "\n",
    "ä¸ºäº†å®éªŒçš„å¯é‡å¤æ€§å’Œæ•™å­¦æ¸…æ™°åº¦ï¼Œæˆ‘ä»¬ç”Ÿæˆä¸€ä¸ªåˆæˆæµ‹è¯•å›¾åƒã€‚è¿™æ ·å¯ä»¥ç¡®ä¿æ¯æ¬¡è¿è¡Œå®éªŒéƒ½å¾—åˆ°ç›¸åŒçš„ç»“æœã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# åˆ›å»ºä¸€ä¸ªåˆæˆæµ‹è¯•å›¾åƒ\n",
    "def create_test_image():\n",
    "    \"\"\"\n",
    "    åˆ›å»ºä¸€ä¸ªç”¨äºæµ‹è¯•çš„åˆæˆå›¾åƒ\n",
    "    å›¾æ¡ˆï¼šä¸­å¿ƒé»‘è‰²åœ†å½¢ï¼Œå¤–å›´ç™½è‰²è¾¹ç¼˜ï¼ŒèƒŒæ™¯ä¸ºç°è‰²\n",
    "    \"\"\"\n",
    "    # åˆ›å»º 224x224 çš„éšæœºå›¾åƒèƒŒæ™¯\n",
    "    np.random.seed(42)  # å›ºå®šéšæœºç§å­ç¡®ä¿å¯é‡å¤æ€§\n",
    "    img = np.random.rand(224, 224, 3) * 0.3 + 0.35  # ç°è‰²èƒŒæ™¯\n",
    "    \n",
    "    # ç»˜åˆ¶ä¸­å¿ƒåœ†å½¢å›¾æ¡ˆï¼ˆæ¨¡æ‹ŸæŸç§ç‰©ä½“ï¼‰\n",
    "    center_x, center_y = 112, 112\n",
    "    for i in range(224):\n",
    "        for j in range(224):\n",
    "            dist = np.sqrt((i - center_x)**2 + (j - center_y)**2)\n",
    "            if dist < 60:\n",
    "                img[i, j] = [0.1, 0.1, 0.1]  # é»‘è‰²ä¸­å¿ƒ\n",
    "            elif dist < 80:\n",
    "                img[i, j] = [0.9, 0.9, 0.9]  # ç™½è‰²è¾¹ç¼˜\n",
    "    \n",
    "    # è½¬æ¢ä¸º PyTorch å¼ é‡æ ¼å¼ [C, H, W]\n",
    "    img_tensor = torch.tensor(img, dtype=torch.float32).permute(2, 0, 1)\n",
    "    return img_tensor\n",
    "\n",
    "# åˆ›å»ºæµ‹è¯•å›¾åƒ\n",
    "original_image = create_test_image()\n",
    "\n",
    "# å¯è§†åŒ–åŸå§‹å›¾åƒ\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(original_image.permute(1, 2, 0).numpy())\n",
    "plt.title(\"åŸå§‹æµ‹è¯•å›¾åƒ\", fontsize=14, pad=10)\n",
    "plt.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# è·å–æ¨¡å‹çš„åŸå§‹é¢„æµ‹\n",
    "original_class, original_confidence = predict(model, original_image)\n",
    "original_label = IMAGENET_LABELS.get(original_class, f\"æœªçŸ¥ç±»åˆ«\")\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ“Š åŸå§‹é¢„æµ‹ç»“æœ\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  é¢„æµ‹ç±»åˆ«: {original_label} (ID: {original_class})\")\n",
    "print(f\"  é¢„æµ‹ç½®ä¿¡åº¦: {original_confidence:.2%}\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### âœ… æ£€æŸ¥ç‚¹ 1\n",
    "\n",
    "è¿è¡Œåˆ°è¿™é‡Œï¼Œä½ åº”è¯¥çœ‹åˆ°ï¼š\n",
    "- âœ“ ä¸€å¼ åˆæˆçš„æµ‹è¯•å›¾åƒï¼ˆä¸­å¿ƒé»‘è‰²åœ†å½¢ï¼Œç™½è‰²è¾¹ç¼˜ï¼‰\n",
    "- âœ“ æ¨¡å‹å¯¹è¯¥å›¾åƒçš„é¢„æµ‹ç»“æœå’Œç½®ä¿¡åº¦\n",
    "\n",
    "å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æ£€æŸ¥ï¼š\n",
    "- æ¨¡å‹æ˜¯å¦æˆåŠŸåŠ è½½\n",
    "- å›¾åƒæ˜¯å¦æ­£ç¡®æ˜¾ç¤º"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬ä¸‰éƒ¨åˆ†ï¼šå®ç° FGSM å¯¹æŠ—æ”»å‡»\n",
    "\n",
    "ç°åœ¨æˆ‘ä»¬æ¥å®ç° FGSM æ”»å‡»çš„æ ¸å¿ƒç®—æ³•ã€‚å…³é”®æ­¥éª¤åŒ…æ‹¬ï¼š\n",
    "1. è®¡ç®—æ¨¡å‹å¯¹è¾“å…¥çš„æ¢¯åº¦\n",
    "2. è·å–æ¢¯åº¦çš„ç¬¦å·\n",
    "3. ç”Ÿæˆå¯¹æŠ—æ‰°åŠ¨\n",
    "4. æ·»åŠ æ‰°åŠ¨å¾—åˆ°å¯¹æŠ—æ ·æœ¬"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fgsm_attack(model, image, label, epsilon):\n",
    "    \"\"\"\n",
    "    å®ç° FGSM (Fast Gradient Sign Method) å¯¹æŠ—æ”»å‡»\n",
    "    \n",
    "    å‚æ•°:\n",
    "        model: ç›®æ ‡ç¥ç»ç½‘ç»œæ¨¡å‹\n",
    "        image: åŸå§‹å›¾åƒå¼ é‡ [C, H, W]ï¼ŒèŒƒå›´ [0, 1]\n",
    "        label: åŸå§‹å›¾åƒçš„çœŸå®æ ‡ç­¾ï¼ˆæ•´æ•°ï¼‰\n",
    "        epsilon: æ‰°åŠ¨å¼ºåº¦å‚æ•° Îµ\n",
    "    \n",
    "    è¿”å›:\n",
    "        adversarial_image: å¯¹æŠ—æ ·æœ¬å¼ é‡ [C, H, W]\n",
    "    \"\"\"\n",
    "    # æ­¥éª¤1ï¼šå¤åˆ¶å›¾åƒå¹¶å¯ç”¨æ¢¯åº¦è¿½è¸ª\n",
    "    # æˆ‘ä»¬éœ€è¦å¯¹è¾“å…¥å›¾åƒè®¡ç®—æ¢¯åº¦ï¼Œæ‰€ä»¥å¿…é¡»è®¾ç½® requires_grad=True\n",
    "    image_copy = image.clone().detach()\n",
    "    image_copy.requires_grad = True\n",
    "    \n",
    "    # æ­¥éª¤2ï¼šå½’ä¸€åŒ–å¹¶å‰å‘ä¼ æ’­\n",
    "    # æ·»åŠ  batch ç»´åº¦ [1, C, H, W]\n",
    "    normalized = normalize(image_copy).unsqueeze(0)\n",
    "    output = model(normalized)\n",
    "    \n",
    "    # æ­¥éª¤3ï¼šè®¡ç®—æŸå¤±\n",
    "    # ä½¿ç”¨äº¤å‰ç†µæŸå¤±ï¼Œç›®æ ‡æ˜¯æœ€å¤§åŒ–æ­£ç¡®ç±»åˆ«çš„æŸå¤±\n",
    "    loss = nn.CrossEntropyLoss()(output, torch.tensor([label]))\n",
    "    \n",
    "    # æ­¥éª¤4ï¼šåå‘ä¼ æ’­è®¡ç®—æ¢¯åº¦\n",
    "    model.zero_grad()  # æ¸…ç©ºæ¨¡å‹çš„æ¢¯åº¦\n",
    "    loss.backward()    # è®¡ç®—æ¢¯åº¦\n",
    "    \n",
    "    # æ­¥éª¤5ï¼šè·å–è¾“å…¥å›¾åƒçš„æ¢¯åº¦\n",
    "    # gradient çš„å½¢çŠ¶ä¸ image_copy ç›¸åŒ\n",
    "    gradient = image_copy.grad.data\n",
    "    \n",
    "    # ========== å¡«ç©º 1ï¼šç”Ÿæˆå¯¹æŠ—æ‰°åŠ¨ ==========\n",
    "    # \n",
    "    # ğŸ¯ ä»»åŠ¡ï¼šæ ¹æ® FGSM å…¬å¼è®¡ç®—å¯¹æŠ—æ‰°åŠ¨\n",
    "    # \n",
    "    # ğŸ’¡ æç¤ºï¼š\n",
    "    #   - FGSM å…¬å¼ï¼šperturbation = Îµ Ã— sign(æ¢¯åº¦)\n",
    "    #   - sign() å‡½æ•°è¿”å›æ¢¯åº¦çš„ç¬¦å·ï¼ˆ+1 æˆ– -1ï¼‰\n",
    "    #   - ä½¿ç”¨ torch.sign() å‡½æ•°\n",
    "    # \n",
    "    # ğŸ“– å‚è€ƒæ–‡æ¡£ï¼š\n",
    "    #   torch.sign(tensor) è¿”å›å¼ é‡ä¸­æ¯ä¸ªå…ƒç´ çš„ç¬¦å·\n",
    "    # \n",
    "    # éš¾åº¦ï¼šâ­â­â˜†â˜†â˜†\n",
    "    \n",
    "    perturbation = ___________  # æœŸæœ›ï¼šepsilon * torch.sign(gradient)\n",
    "    \n",
    "    # æ­¥éª¤6ï¼šç”Ÿæˆå¯¹æŠ—æ ·æœ¬\n",
    "    adversarial_image = image_copy + perturbation\n",
    "    \n",
    "    # æ­¥éª¤7ï¼šè£å‰ªåˆ°æœ‰æ•ˆåƒç´ èŒƒå›´ [0, 1]\n",
    "    # ç¡®ä¿ç”Ÿæˆçš„å¯¹æŠ—æ ·æœ¬æ˜¯æœ‰æ•ˆå›¾åƒ\n",
    "    adversarial_image = torch.clamp(adversarial_image, 0, 1)\n",
    "    \n",
    "    return adversarial_image.detach()\n",
    "\n",
    "print(\"âœ“ FGSM æ”»å‡»å‡½æ•°å®šä¹‰å®Œæˆï¼\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== å¡«ç©º 2ï¼šæ‰§è¡Œ FGSM æ”»å‡» ==========\n",
    "# \n",
    "# ğŸ¯ ä»»åŠ¡ï¼šè°ƒç”¨ fgsm_attack å‡½æ•°ç”Ÿæˆå¯¹æŠ—æ ·æœ¬\n",
    "# \n",
    "# ğŸ’¡ æç¤ºï¼š\n",
    "#   - éœ€è¦ä¼ å…¥ï¼šmodelï¼ˆæ¨¡å‹ï¼‰ã€original_imageï¼ˆåŸå›¾ï¼‰ã€original_classï¼ˆæ ‡ç­¾ï¼‰ã€epsilonï¼ˆæ‰°åŠ¨å¼ºåº¦ï¼‰\n",
    "#   - epsilon å»ºè®®ä» 0.03 å¼€å§‹å°è¯•\n",
    "#   - å‡½æ•°è¿”å›å¯¹æŠ—æ ·æœ¬\n",
    "# \n",
    "# éš¾åº¦ï¼šâ­â˜†â˜†â˜†â˜†\n",
    "\n",
    "epsilon = 0.03  # æ‰°åŠ¨å¼ºåº¦å‚æ•°\n",
    "\n",
    "# æ‰§è¡Œæ”»å‡»\n",
    "adversarial_image = ___________  # æœŸæœ›ï¼šfgsm_attack(model, original_image, original_class, epsilon)\n",
    "\n",
    "# è·å–å¯¹æŠ—æ ·æœ¬çš„é¢„æµ‹ç»“æœ\n",
    "adv_class, adv_confidence = predict(model, adversarial_image)\n",
    "adv_label = IMAGENET_LABELS.get(adv_class, f\"æœªçŸ¥ç±»åˆ«\")\n",
    "\n",
    "# æ˜¾ç¤ºæ”»å‡»ç»“æœ\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ¯ FGSM æ”»å‡»ç»“æœ\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  åŸå§‹é¢„æµ‹: {original_label} (ID: {original_class}) - ç½®ä¿¡åº¦: {original_confidence:.2%}\")\n",
    "print(f\"  æ”»å‡»åé¢„æµ‹: {adv_label} (ID: {adv_class}) - ç½®ä¿¡åº¦: {adv_confidence:.2%}\")\n",
    "print(f\"  æ‰°åŠ¨å¼ºåº¦ Îµ: {epsilon}\")\n",
    "\n",
    "# åˆ¤æ–­æ”»å‡»æ˜¯å¦æˆåŠŸ\n",
    "if original_class != adv_class:\n",
    "    print(f\"  æ”»å‡»ç»“æœ: âœ“ æˆåŠŸï¼æ¨¡å‹é¢„æµ‹å‘ç”Ÿæ”¹å˜\")\n",
    "else:\n",
    "    print(f\"  æ”»å‡»ç»“æœ: âœ— å¤±è´¥ï¼Œæ¨¡å‹é¢„æµ‹æœªæ”¹å˜\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¤” æ€è€ƒä¸€ä¸‹\n",
    "\n",
    "1. **è§‚å¯Ÿç°è±¡**ï¼šå¯¹æŠ—æ ·æœ¬çš„é¢„æµ‹ç»“æœä¸åŸå›¾æœ‰ä»€ä¹ˆä¸åŒï¼Ÿ\n",
    "2. **æ€è€ƒåŸç†**ï¼šä¸ºä»€ä¹ˆæ·»åŠ ä¸€ä¸ªå¾ˆå°çš„æ‰°åŠ¨å°±èƒ½è®©æ¨¡å‹æ”¹å˜é¢„æµ‹ï¼Ÿ\n",
    "3. **å®‰å…¨å¯ç¤º**ï¼šè¿™ç§æ”»å‡»åœ¨ç°å®ä¸–ç•Œä¸­æ„å‘³ç€ä»€ä¹ˆå¨èƒï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬å››éƒ¨åˆ†ï¼šå¯è§†åŒ–å¯¹æŠ—æ ·æœ¬å’Œæ‰°åŠ¨\n",
    "\n",
    "å¯¹æŠ—æ”»å‡»çš„ä¸€ä¸ªé‡è¦ç‰¹æ€§æ˜¯**å¯¹äººçœ¼ä¸å¯è§**ã€‚è®©æˆ‘ä»¬å¯è§†åŒ–åŸå›¾ã€æ‰°åŠ¨å’Œå¯¹æŠ—æ ·æœ¬ï¼Œè§‚å¯Ÿå®ƒä»¬çš„å·®å¼‚ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== å¡«ç©º 3ï¼šè®¡ç®—å¯¹æŠ—æ‰°åŠ¨ ==========\n",
    "# \n",
    "# ğŸ¯ ä»»åŠ¡ï¼šè®¡ç®—å¯¹æŠ—æ ·æœ¬ä¸åŸå›¾çš„å·®å¼‚ï¼ˆæ‰°åŠ¨ï¼‰\n",
    "# \n",
    "# ğŸ’¡ æç¤ºï¼š\n",
    "#   - æ‰°åŠ¨ = å¯¹æŠ—æ ·æœ¬ - åŸå§‹å›¾åƒ\n",
    "#   - è¿™æ˜¯ä¸€ä¸ªç®€å•çš„å‡æ³•æ“ä½œ\n",
    "# \n",
    "# éš¾åº¦ï¼šâ­â˜†â˜†â˜†â˜†\n",
    "\n",
    "perturbation = ___________  # æœŸæœ›ï¼šadversarial_image - original_image\n",
    "\n",
    "# å¯è§†åŒ–å¯¹æ¯”\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "# å­å›¾1ï¼šåŸå§‹å›¾åƒ\n",
    "axes[0].imshow(original_image.permute(1, 2, 0).numpy())\n",
    "axes[0].set_title(f\"åŸå§‹å›¾åƒ\\né¢„æµ‹: {original_label}\\nç½®ä¿¡åº¦: {original_confidence:.1%}\", \n",
    "                  fontsize=12, color='green')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# å­å›¾2ï¼šå¯¹æŠ—æ‰°åŠ¨ï¼ˆæ”¾å¤§æ˜¾ç¤ºä»¥ä¾¿è§‚å¯Ÿï¼‰\n",
    "# å°†æ‰°åŠ¨å½’ä¸€åŒ–åˆ° [0, 1] èŒƒå›´ä»¥ä¾¿å¯è§†åŒ–\n",
    "perturbation_vis = perturbation - perturbation.min()\n",
    "perturbation_vis = perturbation_vis / (perturbation_vis.max() + 1e-8)\n",
    "axes[1].imshow(perturbation_vis.permute(1, 2, 0).numpy())\n",
    "axes[1].set_title(f\"å¯¹æŠ—æ‰°åŠ¨ï¼ˆæ”¾å¤§æ˜¾ç¤ºï¼‰\\nÎµ = {epsilon}\", \n",
    "                  fontsize=12, color='orange')\n",
    "axes[1].axis('off')\n",
    "\n",
    "# å­å›¾3ï¼šå¯¹æŠ—æ ·æœ¬\n",
    "axes[2].imshow(adversarial_image.permute(1, 2, 0).numpy())\n",
    "attack_color = 'red' if original_class != adv_class else 'blue'\n",
    "axes[2].set_title(f\"å¯¹æŠ—æ ·æœ¬\\né¢„æµ‹: {adv_label}\\nç½®ä¿¡åº¦: {adv_confidence:.1%}\", \n",
    "                  fontsize=12, color=attack_color)\n",
    "axes[2].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# è®¡ç®—å¹¶æ˜¾ç¤ºæ‰°åŠ¨çš„ç»Ÿè®¡ä¿¡æ¯\n",
    "print(\"=\" * 50)\n",
    "print(\"ğŸ“ æ‰°åŠ¨ç»Ÿè®¡åˆ†æ\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"  æœ€å¤§æ‰°åŠ¨å€¼: {perturbation.abs().max().item():.6f}\")\n",
    "print(f\"  å¹³å‡æ‰°åŠ¨å€¼: {perturbation.abs().mean().item():.6f}\")\n",
    "print(f\"  æ‰°åŠ¨èŒƒå›´: [{perturbation.min().item():.6f}, {perturbation.max().item():.6f}]\")\n",
    "print(f\"  Lâˆ èŒƒæ•°: {perturbation.abs().max().item():.6f} (åº”æ¥è¿‘ Îµ={epsilon})\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ç¬¬äº”éƒ¨åˆ†ï¼šæ¢ç´¢æ‰°åŠ¨å¼ºåº¦çš„å½±å“\n",
    "\n",
    "**æ ¸å¿ƒé—®é¢˜**ï¼šæ‰°åŠ¨å¼ºåº¦ Îµ å¦‚ä½•å½±å“æ”»å‡»æ•ˆæœå’Œå›¾åƒè´¨é‡ï¼Ÿ\n",
    "\n",
    "æˆ‘ä»¬å°†æµ‹è¯•ä¸åŒçš„ Îµ å€¼ï¼Œè§‚å¯Ÿï¼š\n",
    "1. **æ”»å‡»æˆåŠŸç‡**ï¼šÎµ è¶Šå¤§ï¼Œæ”»å‡»è¶Šå®¹æ˜“æˆåŠŸå—ï¼Ÿ\n",
    "2. **å›¾åƒè´¨é‡**ï¼šÎµ è¶Šå¤§ï¼Œå›¾åƒå˜åŒ–è¶Šæ˜æ˜¾å—ï¼Ÿ\n",
    "3. **å¹³è¡¡ç‚¹**ï¼šæ˜¯å¦å­˜åœ¨ä¸€ä¸ªæœ€ä¼˜çš„ Îµ å€¼ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# æµ‹è¯•ä¸åŒæ‰°åŠ¨å¼ºåº¦çš„æ•ˆæœ\n",
    "epsilon_values = [0.0, 0.01, 0.02, 0.03, 0.05, 0.1]\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"ğŸ”¬ ä¸åŒ Îµ å€¼çš„æ”»å‡»æ•ˆæœå¯¹æ¯”\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"{'Îµ å€¼':<10} {'é¢„æµ‹ç±»åˆ«':<15} {'ç½®ä¿¡åº¦':<12} {'æ”»å‡»ç»“æœ':<15}\")\n",
    "print(\"-\" * 70)\n",
    "\n",
    "results = []\n",
    "for eps in epsilon_values:\n",
    "    if eps == 0:\n",
    "        # Îµ=0 æ—¶å°±æ˜¯åŸå›¾ï¼Œä¸éœ€è¦æ”»å‡»\n",
    "        test_pred, test_conf = original_class, original_confidence\n",
    "        test_img = original_image\n",
    "    else:\n",
    "        # ========== å¡«ç©º 4ï¼šå¯¹ä¸åŒ epsilon æ‰§è¡Œæ”»å‡» ==========\n",
    "        # \n",
    "        # ğŸ¯ ä»»åŠ¡ï¼šå¯¹æ¯ä¸ª epsilon å€¼æ‰§è¡Œ FGSM æ”»å‡»\n",
    "        # \n",
    "        # ğŸ’¡ æç¤ºï¼š\n",
    "        #   - è°ƒç”¨ fgsm_attack å‡½æ•°\n",
    "        #   - å‚æ•°ï¼šmodel, original_image, original_class, eps\n",
    "        #   - å°†ç»“æœå­˜å‚¨åœ¨ test_img å˜é‡ä¸­\n",
    "        # \n",
    "        # éš¾åº¦ï¼šâ­â­â˜†â˜†â˜†\n",
    "        \n",
    "        test_img = ___________  # æœŸæœ›ï¼šfgsm_attack(model, original_image, original_class, eps)\n",
    "        test_pred, test_conf = predict(model, test_img)\n",
    "    \n",
    "    # åˆ¤æ–­æ”»å‡»æ˜¯å¦æˆåŠŸ\n",
    "    success = \"âœ“ æˆåŠŸ\" if test_pred != original_class else \"âœ— å¤±è´¥\"\n",
    "    test_label = IMAGENET_LABELS.get(test_pred, f\"ç±»åˆ«{test_pred}\")\n",
    "    \n",
    "    results.append((eps, test_img, test_pred, test_conf, success))\n",
    "    print(f\"{eps:<10.2f} {test_label:<15} {test_conf:<12.2%} {success:<15}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å¯è§†åŒ–ä¸åŒ Îµ å€¼çš„å¯¹æŠ—æ ·æœ¬\n",
    "fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, (eps, img, pred, conf, success) in enumerate(results):\n",
    "    axes[idx].imshow(img.permute(1, 2, 0).numpy())\n",
    "    \n",
    "    # æ ¹æ®æ”»å‡»ç»“æœè®¾ç½®é¢œè‰²\n",
    "    color = 'red' if pred != original_class else 'green'\n",
    "    label = IMAGENET_LABELS.get(pred, f\"ç±»åˆ«{pred}\")\n",
    "    \n",
    "    axes[idx].set_title(\n",
    "        f\"Îµ = {eps}\\né¢„æµ‹: {label}\\nç½®ä¿¡åº¦: {conf:.1%}\\n{success}\",\n",
    "        fontsize=11,\n",
    "        color=color\n",
    "    )\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.suptitle(\"ä¸åŒæ‰°åŠ¨å¼ºåº¦ Îµ çš„å¯¹æŠ—æ ·æœ¬æ•ˆæœå¯¹æ¯”\", fontsize=16, y=0.98)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ğŸ¤” æ·±å…¥æ€è€ƒ\n",
    "\n",
    "åŸºäºä¸Šé¢çš„å®éªŒç»“æœï¼Œæ€è€ƒä»¥ä¸‹é—®é¢˜ï¼š\n",
    "\n",
    "1. **æ‰°åŠ¨ä¸æˆåŠŸç‡**ï¼šä» Îµ=0.01 åˆ° Îµ=0.1ï¼Œæ”»å‡»æˆåŠŸç‡å¦‚ä½•å˜åŒ–ï¼Ÿ\n",
    "2. **æ‰°åŠ¨ä¸éšè”½æ€§**ï¼šå“ªä¸ª Îµ å€¼æ—¢èƒ½æˆåŠŸæ”»å‡»ï¼Œåˆä¸ä¼šè®©å›¾åƒå˜åŒ–å¤ªæ˜æ˜¾ï¼Ÿ\n",
    "3. **å®é™…åº”ç”¨**ï¼šåœ¨ç°å®åœºæ™¯ä¸­ï¼ˆå¦‚äººè„¸è¯†åˆ«ã€è‡ªåŠ¨é©¾é©¶ï¼‰ï¼Œæ”»å‡»è€…ä¼šå¦‚ä½•é€‰æ‹© Îµï¼Ÿ\n",
    "4. **é˜²å¾¡æ€è·¯**ï¼šå¦‚æœä½ æ˜¯é˜²å¾¡è€…ï¼Œå¦‚ä½•æ£€æµ‹æˆ–é˜²å¾¡è¿™ç§æ”»å‡»ï¼Ÿ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“‹ å®éªŒå°ç»“\n",
    "\n",
    "### æ ¸å¿ƒæ”¶è·\n",
    "\n",
    "é€šè¿‡æœ¬å®éªŒï¼Œä½ å·²ç»ï¼š\n",
    "\n",
    "1. **ç†è§£åŸç†**ï¼šæŒæ¡äº† FGSM å¯¹æŠ—æ”»å‡»çš„æ•°å­¦åŸç†å’Œå®ç°æ–¹æ³•\n",
    "2. **åŠ¨æ‰‹å®è·µ**ï¼šæˆåŠŸç”Ÿæˆäº†ç¬¬ä¸€ä¸ªå¯¹æŠ—æ ·æœ¬ï¼Œè§‚å¯Ÿäº†æ”»å‡»æ•ˆæœ\n",
    "3. **å‚æ•°æ¢ç´¢**ï¼šåˆ†æäº†æ‰°åŠ¨å¼ºåº¦ Îµ å¯¹æ”»å‡»æˆåŠŸç‡å’Œéšè”½æ€§çš„å½±å“\n",
    "4. **å®‰å…¨è®¤çŸ¥**ï¼šè®¤è¯†åˆ°æ·±åº¦å­¦ä¹ æ¨¡å‹åœ¨é¢å¯¹å¯¹æŠ—æ ·æœ¬æ—¶çš„è„†å¼±æ€§\n",
    "\n",
    "### å…³é”®ä»£ç å›é¡¾\n",
    "\n",
    "```python\n",
    "# FGSM æ ¸å¿ƒå…¬å¼\n",
    "x_adv = x + Îµ Ã— sign(âˆ‡_x Loss(Î¸, x, y))\n",
    "\n",
    "# PyTorch å®ç°\n",
    "perturbation = epsilon * torch.sign(gradient)\n",
    "adversarial_image = original_image + perturbation\n",
    "```\n",
    "\n",
    "### ğŸ”‘ å…³é”®è¦ç‚¹\n",
    "\n",
    "- **ç™½ç›’æ”»å‡»**ï¼šæ”»å‡»è€…éœ€è¦çŸ¥é“æ¨¡å‹ç»“æ„å’Œå‚æ•°\n",
    "- **æ¢¯åº¦æ–¹å‘**ï¼šæ²¿ç€æŸå¤±å‡½æ•°æ¢¯åº¦çš„ç¬¦å·æ–¹å‘æ·»åŠ æ‰°åŠ¨\n",
    "- **å‚æ•°æƒè¡¡**ï¼šÎµ è¶Šå¤§æ”»å‡»è¶Šå¼ºï¼Œä½†æ‰°åŠ¨è¶Šæ˜æ˜¾\n",
    "- **Lâˆ çº¦æŸ**ï¼šFGSM ä¿è¯æ¯ä¸ªåƒç´ çš„æ‰°åŠ¨ä¸è¶…è¿‡ Îµ\n",
    "\n",
    "### å®é™…åº”ç”¨åœºæ™¯\n",
    "\n",
    "FGSM æ”»å‡»åœ¨ä»¥ä¸‹åœºæ™¯ä¸­å…·æœ‰ç°å®å¨èƒï¼š\n",
    "- **å›¾åƒåˆ†ç±»ç³»ç»Ÿ**ï¼šæ¬ºéª—å†…å®¹å®¡æ ¸ã€åƒåœ¾é‚®ä»¶è¿‡æ»¤\n",
    "- **äººè„¸è¯†åˆ«**ï¼šç»•è¿‡èº«ä»½éªŒè¯ã€éšç§ä¿æŠ¤\n",
    "- **è‡ªåŠ¨é©¾é©¶**ï¼šå¹²æ‰°äº¤é€šæ ‡å¿—è¯†åˆ«\n",
    "- **åŒ»ç–—è¯Šæ–­**ï¼šå½±å“ç–¾ç—…è¯Šæ–­å‡†ç¡®æ€§\n",
    "\n",
    "### å»¶ä¼¸å­¦ä¹ \n",
    "\n",
    "- **ä¸‹ä¸€ä¸ªå®éªŒ**ï¼šå®éªŒ 3.2 - PGD è¿­ä»£æ”»å‡»ï¼ˆæ›´å¼ºçš„å¯¹æŠ—æ”»å‡»æ–¹æ³•ï¼‰\n",
    "- **è®ºæ–‡é˜…è¯»**ï¼šGoodfellow et al., \"Explaining and Harnessing Adversarial Examples\" (ICLR 2015)\n",
    "- **è¿›é˜¶æŒ‘æˆ˜**ï¼šå°è¯•å®ç° Targeted FGSMï¼ˆè®©æ¨¡å‹é¢„æµ‹ä¸ºæŒ‡å®šç±»åˆ«ï¼‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“– å‚è€ƒç­”æ¡ˆ\n",
    "\n",
    "<details>\n",
    "<summary>ç‚¹å‡»å±•å¼€å‚è€ƒç­”æ¡ˆ</summary>\n",
    "\n",
    "**å¡«ç©º 1ï¼šç”Ÿæˆå¯¹æŠ—æ‰°åŠ¨**\n",
    "```python\n",
    "perturbation = epsilon * torch.sign(gradient)\n",
    "```\n",
    "\n",
    "**å¡«ç©º 2ï¼šæ‰§è¡Œ FGSM æ”»å‡»**\n",
    "```python\n",
    "adversarial_image = fgsm_attack(model, original_image, original_class, epsilon)\n",
    "```\n",
    "\n",
    "**å¡«ç©º 3ï¼šè®¡ç®—å¯¹æŠ—æ‰°åŠ¨**\n",
    "```python\n",
    "perturbation = adversarial_image - original_image\n",
    "```\n",
    "\n",
    "**å¡«ç©º 4ï¼šå¯¹ä¸åŒ epsilon æ‰§è¡Œæ”»å‡»**\n",
    "```python\n",
    "test_img = fgsm_attack(model, original_image, original_class, eps)\n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®éªŒç»“æŸï¼Œæ¸…ç†æ˜¾å­˜ï¼ˆå¯é€‰ï¼‰\n",
    "# å¦‚æœè¦ç»§ç»­è¿›è¡Œä¸‹ä¸€ä¸ªå®éªŒï¼Œå¯ä»¥è¿è¡Œè¿™æ®µä»£ç é‡Šæ”¾æ˜¾å­˜\n",
    "\n",
    "del model\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "print(\"âœ“ æ˜¾å­˜å·²æ¸…ç†\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "âš ï¸ é‡è¦æé†’\n",
    "\n",
    "å®éªŒå®Œæˆåï¼Œè¯·è®°å¾—ï¼š\n",
    "\n",
    "1. **é‡Šæ”¾ GPU èµ„æº**ï¼šå¦‚æœä½ ä½¿ç”¨çš„æ˜¯ Tencent CloudStudio, è¯·ç‚¹å‡»å³ä¸Šè§’çš„ \"åœæ­¢\" æŒ‰é’®ï¼Œåœæ­¢è¿è¡Œã€‚\n",
    "2. **ä¿å­˜å®éªŒç»“æœ**ï¼šå¦‚éœ€ä¿å­˜ï¼Œè¯·ä¸‹è½½ notebook æ–‡ä»¶\n",
    "\n",
    "è¿™æ ·å¯ä»¥é¿å…ä¸å¿…è¦çš„èµ„æºå ç”¨å’Œè´¹ç”¨äº§ç”Ÿã€‚**å¦åˆ™ä¼šä¸€ç›´æ¶ˆè€—ä½ çš„å…è´¹èµ„æºé¢åº¦ã€‚**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
