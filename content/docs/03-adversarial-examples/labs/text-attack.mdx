---
title: "实验 3.4：文本对抗攻击"
description: 实践词级文本对抗攻击技术
---


import { Callout } from 'fumadocs-ui/components/callout';


<Callout title="" type="info">
预计实验约50分钟
</Callout>

## 实验目标

本实验将帮助你理解文本对抗攻击的独特挑战，并通过实际操作体验词级攻击技术。

<Callout title="学习目标" type="info">
完成本实验后，你将能够：
- 理解文本对抗攻击与图像攻击的本质区别
- 使用删除法识别句子中的重要词
- 实现基于同义词替换的词级攻击
- 观察攻击前后模型输出的变化
- 分析不同替换策略的攻击效果
</Callout>

## 实验前提

<Callout title="环境要求" type="warn">
- Python 3.8+
- PyTorch 1.10+ 或 TensorFlow 2.x
- transformers（Hugging Face）
- nltk 或 jieba（用于中文分词）
- 同义词词典或词向量模型

本实验需要一个预训练的文本分类模型（如 BERT 情感分类模型）。
</Callout>

## 实验内容

:::notebook{file="./lab3_4_text_attack.ipynb" showCellNumbers}
:::

## 实验总结

<Callout title="完成检查" type="success">
完成本实验后，你应该已经：
- 理解了文本离散性带来的攻击挑战
- 成功使用删除法识别了句子中的重要词
- 实现了基于同义词替换的词级攻击
- 观察了替换前后模型预测结果的变化
- 分析了语义保持与攻击效果之间的权衡
</Callout>

## 延伸思考

1. 为什么文本对抗攻击比图像对抗攻击更具挑战性？

2. 在词级攻击中，如何在保持语义的同时最大化攻击效果？

3. 如果攻击目标是一个基于规则的简单分类器（如关键词匹配），你会使用什么攻击策略？

4. 从防御者的角度，如何设计一个对词级攻击更鲁棒的文本分类系统？

5. 字符级攻击、词级攻击和句级攻击各有什么适用场景？