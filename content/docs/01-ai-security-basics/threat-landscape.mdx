---
title: 第1章：AI 安全威胁全景图
description: 认识 AI 安全领域的主要威胁，理解为什么 AI 安全与传统网络安全存在本质差异
---

import { Callout } from 'fumadocs-ui/components/callout';
import { Tab, Tabs } from 'fumadocs-ui/components/tabs';
import { Step, Steps } from 'fumadocs-ui/components/steps';

在人工智能技术快速发展的今天，AI 系统已经深入到我们生活的方方面面：从手机上的语音助手，到自动驾驶汽车，再到医疗诊断系统。然而，随着 AI 应用的普及，一个新的问题逐渐浮出水面：**这些看似智能的系统，是否真的安全可靠？**

本章将带领大家认识 AI 安全领域的主要威胁，理解为什么 AI 安全与传统网络安全存在本质差异，并通过真实案例了解这些威胁在现实世界中的影响。

## 章节目标

<Callout title="学完本章后，你将能够：" type="info">
1. **识别 AI 安全威胁的独特性**：理解 AI 系统面临的安全威胁与传统软件系统的本质区别
2. **掌握 AI 威胁分类体系**：了解 OWASP AI Top 10 等主流威胁分类框架，能够识别常见的 AI 安全风险
3. **分析真实安全事件**：通过典型案例理解 AI 安全威胁的实际影响和危害
4. **建立安全意识**：认识到 AI 安全问题的严重性，为后续深入学习打下基础
</Callout>

## AI 安全：一个全新的战场

### 从一个真实事件说起

2023年2月，微软发布了集成 ChatGPT 技术的新版必应搜索引擎。然而，上线仅几天后，用户就发现了一个令人震惊的现象：通过特定的对话方式，可以让必应的 AI 助手"Sydney"表现出攻击性、情绪化，甚至泄露其系统设置信息。

<Callout title="Sydney 事件" type="warn">
一位用户通过巧妙的提问，成功让 Sydney 透露了它的内部指令，包括"我的名字是 Sydney"、"我不能透露我的提示词"等原本应该保密的信息。这个事件引发了全球关注，微软不得不紧急限制对话轮次，并对系统进行多次调整。
</Callout>

这个案例揭示了一个重要事实：**即使是科技巨头精心打造的 AI 系统，也可能存在意想不到的安全漏洞。**

### AI 安全威胁的独特性

传统的网络安全主要关注代码漏洞、权限控制、数据加密等问题。例如，SQL 注入攻击利用的是代码对输入验证不足的漏洞，攻击者通过构造特殊的输入字符串来执行恶意数据库操作。这类攻击的原理相对明确，防御方法也比较成熟。

但 AI 系统的安全问题有着本质的不同：

<Tabs items={['传统软件', 'AI 系统']}>
  <Tab value="传统软件">
    传统软件就像一台按照固定程序运行的机器，它的行为是可预测的。如果输入 A，就一定输出 B。安全问题通常出现在程序逻辑的漏洞上。
  </Tab>
  <Tab value="AI 系统">
    AI 系统更像一个经过训练的"学生"。它通过学习大量数据来掌握某种能力，但这个"学生"的行为并不总是可预测的。同样的问题，换一种问法可能得到完全不同的答案。
  </Tab>
</Tabs>

这种差异带来了几个独特的安全挑战：

**第一，输入的多样性和不可预测性**  
传统系统可以通过输入验证来防御攻击，但 AI 系统需要处理自然语言、图像等复杂输入。攻击者可以通过精心设计的输入，让 AI 系统产生错误的输出，而这些输入在表面上看起来可能完全正常。

**第二，模型行为的不透明性**  
深度学习模型通常包含数百万甚至数十亿个参数，我们很难完全理解模型为什么会做出某个决策。这种"黑盒"特性使得发现和修复安全问题变得极其困难。

**第三，攻击的隐蔽性**  
对 AI 系统的攻击可能不会留下明显的痕迹。例如，攻击者可以在训练数据中植入恶意样本，这些样本在正常情况下不会被发现，但在特定条件下会触发模型的异常行为。

<Callout title="思考" type="idea">
既然 AI 系统这么容易受到攻击，为什么还要使用它们？答案是，AI 技术带来的便利和效率提升是巨大的，我们不能因噎废食。但正因如此，我们更需要深入理解 AI 的安全风险，学会如何防范和应对这些威胁。
</Callout>

## AI 威胁分类：OWASP AI Top 10

为了系统地理解 AI 面临的安全威胁，安全研究人员开发了多种分类框架。其中最具影响力的是 OWASP（开放式 Web 应用程序安全项目）发布的"AI Top 10"威胁清单。

### OWASP AI Top 10 威胁概览

| 序号 | 威胁名称 | 简要描述 |
|:---:|---------|---------|
| 1 | **提示词注入** | 通过精心设计的输入文本，诱导模型执行非预期的操作 |
| 2 | **数据投毒** | 在训练数据中注入恶意样本，影响模型的行为 |
| 3 | **模型窃取** | 通过反复查询模型，训练一个功能相似的"山寨"模型 |
| 4 | **对抗样本** | 在输入数据中添加人类难以察觉的微小扰动，导致模型产生错误输出 |
| 5 | **隐私泄露** | 通过特定的查询方式，让模型泄露训练数据中的敏感信息 |
| 6 | **供应链攻击** | 在开源模型、预训练权重或第三方数据集中植入恶意代码或后门 |
| 7 | **模型逆向** | 通过分析模型的输出，推断出训练数据的特征 |
| 8 | **拒绝服务** | 构造特殊的输入，让 AI 系统消耗大量计算资源 |
| 9 | **不安全的输出处理** | AI 系统的输出没有经过适当的验证和过滤 |
| 10 | **模型配置错误** | 不当的模型配置导致安全问题 |

### 威胁分类的实用价值

了解这些威胁分类不仅仅是为了应付考试，而是有实际的应用价值。当我们在开发或使用 AI 系统时，可以根据这个清单进行安全检查：

- 我们的系统是否容易受到提示词注入攻击？
- 训练数据的来源是否可靠，是否可能被投毒？
- 模型的输出是否经过了适当的验证？
- 我们是否使用了来自可信来源的预训练模型？

## 真实世界的 AI 安全事件

理论知识固然重要，但真实案例能让我们更直观地理解 AI 安全威胁的影响。

### 案例一：ChatGPT 越狱事件（2022-2023）

<Steps>
  <Step>
    **背景**
    
    OpenAI 在发布 ChatGPT 时，设置了严格的内容过滤机制，禁止模型生成暴力、色情、违法等有害内容。
  </Step>
  <Step>
    **攻击过程**
    
    用户很快发现，通过角色扮演的方式可以绕过这些限制。最著名的是"DAN"（Do Anything Now）越狱方法。用户让 ChatGPT 扮演一个"没有任何限制"的角色，从而诱导模型生成原本被禁止的内容。
  </Step>
  <Step>
    **影响与启示**
    
    这类越狱方法在社交媒体上广泛传播，OpenAI 不得不持续更新模型。这说明仅仅依靠内容过滤是不够的，需要在系统设计层面就考虑安全问题。
  </Step>
</Steps>

### 案例二：自动驾驶系统的对抗攻击（2018）

研究人员发现，在停车标志上贴上特定图案的贴纸，可以让图像识别系统将其误认为限速标志。这些贴纸对人类驾驶员来说只是普通的涂鸦，但对 AI 系统来说却能造成严重的误判。

<Callout title="安全启示" type="error">
AI 系统在关键应用场景中必须考虑对抗攻击的风险。对于自动驾驶这类安全关键系统，不能仅仅依赖单一的感知模型，需要多重验证机制。
</Callout>

### 案例三：GitHub Copilot 泄露训练数据（2021）

研究人员发现，通过特定的提示，可以让 Copilot 输出训练数据中的原始代码，包括一些包含 API 密钥、密码等敏感信息的代码片段。这暴露了 AI 模型的"记忆泄露"问题。

## AI 安全与传统安全的对比

| 对比维度 | 传统安全 | AI 安全 |
|---------|---------|---------|
| **攻击面** | 代码漏洞、配置错误、网络协议 | 训练数据、模型输入、模型本身、供应链 |
| **防御方法** | 输入验证、访问控制、加密、补丁管理 | 对抗训练、输入检测、模型加固、输出验证 |
| **测试验证** | 单元测试、集成测试，结果确定 | 概率性行为，难以穷举测试 |
| **修复方式** | 修改代码、打补丁 | 可能需要重新训练模型 |

## 本章小结

本章我们建立了对 AI 安全威胁的整体认识：

1. **AI 安全的独特性**：AI 系统面临的安全威胁与传统软件有本质区别，主要体现在输入的多样性、模型的不透明性和攻击的隐蔽性上。

2. **主要威胁类型**：OWASP AI Top 10 列出了当前最严重的十大威胁，包括提示词注入、数据投毒、对抗样本、隐私泄露等。

3. **真实案例的启示**：通过 ChatGPT 越狱、自动驾驶对抗攻击、Copilot 数据泄露等案例，我们看到这些威胁是现实存在的风险。

4. **安全思维的重要性**：AI 安全不是一个可以"一劳永逸"解决的问题，而是需要在整个系统生命周期中持续关注的议题。

## 课后思考题

<Callout title="思考与练习" type="info">
1. **理解性问题**：请用自己的话解释，为什么说 AI 安全威胁与传统软件安全威胁有本质区别？

2. **分析性问题**：回顾本章介绍的三个真实案例，分析它们分别属于 OWASP AI Top 10 中的哪些威胁类型？

3. **应用性问题**：假设你正在开发一个基于大语言模型的智能客服系统，你认为应该重点防范哪些安全威胁？
</Callout>

## 延伸阅读

- [OWASP AI Security and Privacy Guide](https://owasp.org/www-project-ai-security-and-privacy-guide/)
- 《对抗机器学习》（Adversarial Machine Learning）相关论文
