---
title: 第3章：红队视角：像攻击者一样思考
description: 建立红队思维，学习威胁建模方法，理解攻击者的动机和手法
---

import { Callout } from 'fumadocs-ui/components/callout';
import { Tab, Tabs } from 'fumadocs-ui/components/tabs';
import { Step, Steps } from 'fumadocs-ui/components/steps';
import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';

在网络安全领域，有一个特殊的角色叫做"红队"（Red Team）。他们的任务不是防御攻击，而是模拟攻击者的思维和手法，主动寻找系统的漏洞。本章将带领大家建立红队思维，学习如何从攻击者的角度审视 AI 系统。

## 章节目标

<Callout title="学完本章后，你将能够：" type="info">
1. **理解红队思维的本质**：掌握攻击者视角与防御者视角的差异
2. **掌握威胁建模方法**：了解 CIA 三元组和 STRIDE 威胁建模框架
3. **建立攻防对抗意识**：理解攻击者的动机、能力和常用手法
4. **明确法律伦理边界**：了解网络安全相关法律法规
</Callout>

## 什么是红队思维

### 从一个真实故事说起

2016年，特斯拉举办了一场"黑客马拉松"活动，邀请安全研究人员尝试攻破其自动驾驶系统。一支安全团队成功发现了一个漏洞：通过向车载系统发送特制的无线信号，可以远程控制车辆的刹车系统。

<Callout title="红队价值" type="success">
特斯拉不仅没有追究这个团队的责任，反而给予了丰厚的奖励，并迅速修复了这个漏洞。这体现了红队思维的核心价值：**通过模拟攻击来发现和修复安全问题，而不是等到真正的攻击发生。**
</Callout>

### 红队与蓝队：攻防的两面

<Tabs items={['红队 (Red Team)', '蓝队 (Blue Team)']}>
  <Tab value="红队 (Red Team)">
    扮演攻击者的角色，主动寻找系统漏洞，测试防御措施的有效性。目标是"攻破"系统，暴露安全弱点。
  </Tab>
  <Tab value="蓝队 (Blue Team)">
    负责防御和响应，设计安全机制，监控异常行为，修复发现的漏洞。目标是"守住"系统，保护资产安全。
  </Tab>
</Tabs>

这两个团队看似对立，实际上是相辅相成的。红队发现的问题，为蓝队提供了改进的方向；蓝队的防御措施，又为红队提供了新的挑战。

### 红队思维的核心特征

| 特征 | 说明 |
|-----|------|
| **质疑一切假设** | 如果用户不按常理出牌呢？如果输入超出预期范围呢？ |
| **寻找意外的交互** | 各组件单独安全，组合起来可能产生漏洞 |
| **从攻击者角度评估价值** | 思考：对攻击者来说，哪些部分最有价值？ |
| **持续学习和适应** | 攻击技术在不断演进，需要持续学习新手法 |

<Callout title="道德边界" type="warn">
学习攻击技术不是为了变成"黑客"，而是为了帮助组织发现和修复漏洞。关键在于动机和行为——红队的目标是帮助，而不是破坏。
</Callout>

## 威胁建模：系统化分析安全风险

### CIA 三元组：信息安全的基石

| 安全目标 | 说明 | AI 系统中的体现 |
|---------|------|----------------|
| **机密性 (Confidentiality)** | 确保信息只能被授权的人访问 | 训练数据隐私、模型参数保护、查询历史保密 |
| **完整性 (Integrity)** | 确保信息和系统不被未授权修改 | 训练数据不被篡改、预测结果可靠 |
| **可用性 (Availability)** | 确保授权用户在需要时能够访问 | 模型服务持续可用、推理速度满足需求 |

### STRIDE 威胁建模框架

STRIDE 是微软提出的威胁分类框架，将威胁分为六大类：

<Steps>
  <Step>
    **S - Spoofing（欺骗）**
    
    攻击者伪装成合法用户或系统组件。
    
    *AI 例子*：攻击者伪造 API 请求，冒充授权用户访问模型
  </Step>
  <Step>
    **T - Tampering（篡改）**
    
    攻击者修改数据或代码。
    
    *AI 例子*：在训练数据中注入恶意样本，修改模型参数
  </Step>
  <Step>
    **R - Repudiation（抵赖）**
    
    攻击者否认自己的行为，或系统无法证明操作执行者。
    
    *AI 例子*：攻击者对模型进行恶意查询后否认，系统缺乏审计日志
  </Step>
  <Step>
    **I - Information Disclosure（信息泄露）**
    
    未授权访问敏感信息。
    
    *AI 例子*：通过模型查询提取训练数据，窃取模型参数
  </Step>
  <Step>
    **D - Denial of Service（拒绝服务）**
    
    使系统无法为合法用户提供服务。
    
    *AI 例子*：发送大量请求耗尽计算资源，构造特殊输入让模型陷入长时间计算
  </Step>
  <Step>
    **E - Elevation of Privilege（权限提升）**
    
    攻击者获得超出授权范围的权限。
    
    *AI 例子*：通过提示词注入让模型执行管理员操作
  </Step>
</Steps>

### STRIDE for AI：实例分析

**场景**：一个基于大语言模型的智能客服系统

| 威胁类型 | 具体威胁 | 潜在影响 |
|---------|---------|---------|
| Spoofing | 攻击者伪造用户身份访问客服系统 | 获取其他用户的订单信息 |
| Tampering | 通过提示词注入修改系统行为 | 让客服给出错误的退款承诺 |
| Repudiation | 用户否认自己发送过恶意查询 | 难以追责和防范重复攻击 |
| Information Disclosure | 通过巧妙提问提取训练数据 | 泄露其他用户的对话记录 |
| Denial of Service | 发送大量复杂查询 | 系统响应缓慢，影响正常用户 |
| Elevation of Privilege | 诱导模型执行管理员命令 | 修改订单状态、查看后台数据 |

## 攻击者画像：了解你的对手

### 攻击者的动机

| 动机类型 | 说明 |
|---------|------|
| **经济利益** | 窃取模型或数据并出售、勒索、欺诈 |
| **竞争优势** | 窃取商业机密、破坏竞争对手服务 |
| **意识形态/政治** | 抗议 AI 技术使用方式、暴露系统偏见 |
| **好奇心和挑战** | 测试技术能力、学术研究 |
| **恶意破坏** | 让系统产生有害输出、造成混乱 |

### 攻击者的能力等级

<Tabs items={['初级攻击者', '中级攻击者', '高级攻击者', '内部威胁']}>
  <Tab value="初级攻击者">
    **Script Kiddies**
    - 技术能力有限，主要使用现成的工具和脚本
    - 攻击方法简单，容易被基础防御措施阻止
    - 但数量众多，可能造成大规模的低级别威胁
    
    *对 AI 系统的威胁*：使用公开的提示词注入模板，尝试简单的越狱攻击
  </Tab>
  <Tab value="中级攻击者">
    **Skilled Individuals**
    - 具备一定的技术知识，能够修改和组合现有工具
    - 可以发现一些明显的漏洞
    - 通常是独立行动或小团队
    
    *对 AI 系统的威胁*：设计定制化的对抗样本，进行有针对性的数据投毒
  </Tab>
  <Tab value="高级攻击者">
    **APT (Advanced Persistent Threat)**
    - 技术能力强，资源充足，通常有组织支持
    - 能够发现复杂的漏洞，进行长期的渗透
    - 攻击手法隐蔽，难以检测和防御
    
    *对 AI 系统的威胁*：供应链攻击，在预训练模型中植入后门
  </Tab>
  <Tab value="内部威胁">
    **Insider Threats**
    - 拥有合法访问权限的内部人员
    - 了解系统的内部结构和弱点
    - 可能是最危险的威胁类型
    
    *对 AI 系统的威胁*：直接访问训练数据进行投毒，窃取模型参数
  </Tab>
</Tabs>

### 攻击者的常用手法

<Steps>
  <Step>
    **侦察 (Reconnaissance)**
    
    收集信息：探测系统功能和限制、识别模型类型和版本、测试输入输出边界
  </Step>
  <Step>
    **武器化 (Weaponization)**
    
    准备攻击工具：构造对抗样本、设计提示词注入载荷、准备投毒数据
  </Step>
  <Step>
    **投递 (Delivery)**
    
    发送攻击载荷：通过正常 API 接口发送恶意输入、在公开数据集中植入恶意样本
  </Step>
  <Step>
    **利用 (Exploitation)**
    
    触发漏洞：让模型产生错误输出、提取敏感信息、获取未授权访问
  </Step>
  <Step>
    **持久化 (Persistence)**
    
    确保效果持续：在模型中植入后门、建立持久访问通道
  </Step>
</Steps>

## 法律与伦理边界

<Callout title="重要提醒" type="error">
进行安全测试必须遵守法律法规和道德准则：
- 只在获得授权的系统上进行测试
- 不要对生产环境造成破坏
- 发现漏洞后负责任地披露
- 不要利用漏洞牟利或伤害他人
</Callout>

## 本章小结

1. **红队思维**：主动寻找漏洞，质疑假设，从攻击者角度思考
2. **CIA 三元组**：机密性、完整性、可用性是信息安全的基石
3. **STRIDE 框架**：系统化分析威胁的六大类别
4. **攻击者画像**：了解不同攻击者的动机、能力和手法
5. **法律伦理**：安全测试必须在授权和道德范围内进行

## 课后思考题

<Accordions>
  <Accordion title="思考题1：红队与蓝队的关系">
    请解释红队思维与蓝队思维的区别，以及它们如何相互促进？
  </Accordion>
  <Accordion title="思考题2：STRIDE 框架应用">
    使用 STRIDE 框架分析一个你熟悉的 AI 应用（如智能客服、图像识别系统等），识别可能的威胁。
  </Accordion>
  <Accordion title="思考题3：内部威胁防范">
    如果你是一个 AI 系统的安全负责人，你会如何识别和防范内部威胁？
  </Accordion>
</Accordions>
