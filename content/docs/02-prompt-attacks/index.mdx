---
title: 提示词攻击总览
description: 深入学习提示词注入、越狱技术和防御策略，理解 AI 系统面临的最普遍攻击面
---

import { Cards, Card } from 'fumadocs-ui/components/card';
import { Callout } from 'fumadocs-ui/components/callout';
import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';
import { ShieldAlert, Flame, KeyRound, Filter, ShieldCheck } from 'lucide-react';

<Callout title="" type="info">
预计阅读约3-4小时，实验约3小时
</Callout>

在模块一中，我们建立了 AI 安全的整体认知：了解了威胁全景、大语言模型（LLM）的工作原理、红队思维，并搭建好了实验环境。从本模块开始，我们将把这些基础知识应用到具体的攻击场景中。

本模块聚焦的是 OWASP Top 10 for LLM Applications 中排名第一的威胁类别——**提示词注入（Prompt Injection）**及其衍生攻击技术。提示词攻击之所以排在首位，是因为它直接利用了大语言模型最根本的特性：无法区分指令和数据。攻击者不需要任何代码漏洞，仅通过精心设计的自然语言，就能操纵 AI 系统执行非预期的操作、绕过安全限制，甚至泄露敏感信息。

本模块将沿着"攻击原理 → 攻击技术 → 防御对策"的主线展开，从最基础的注入原理讲起，逐步深入到越狱、提示词提取、过滤器绕过等进阶攻击手法，最后以多层防御架构收束全模块。

## 学习目标

<Callout title="完成本模块后，你将能够：" type="success">
- 理解提示词注入（Prompt Injection）的本质，掌握直接注入和间接注入的原理
- 掌握主流越狱技术，包括 DAN 系列、编码绕过和逻辑操纵
- 学会系统提示提取技术，了解如何获取 AI 系统的内部配置
- 理解内容过滤器的工作机制，掌握字符级、语义级、结构级绕过技术
- 建立多层防御思维，设计和评估 AI 系统的安全方案
</Callout>

## 章节概览

<Cards>
  <Card icon={<ShieldAlert />} title="第1章：提示词注入基础原理" href="/docs/02-prompt-attacks/injection-basics">
    理解提示词注入的本质，掌握直接注入、间接注入和多轮对话注入技术
  </Card>
  <Card icon={<Flame />} title="第2章：越狱技术详解" href="/docs/02-prompt-attacks/jailbreaking">
    学习 DAN 系列越狱技术、编码绕过、逻辑操纵和场景构造方法
  </Card>
  <Card icon={<KeyRound />} title="第3章：系统提示提取技术" href="/docs/02-prompt-attacks/prompt-extraction">
    掌握直接请求、间接诱导、编码翻译等系统提示词提取方法
  </Card>
  <Card icon={<Filter />} title="第4章：内容过滤器绕过技术" href="/docs/02-prompt-attacks/filter-bypass">
    深入理解内容过滤器的工作机制，学习三大类绕过技术
  </Card>
  <Card icon={<ShieldCheck />} title="第5章：防御机制与对策" href="/docs/02-prompt-attacks/defense-strategies">
    建立多层防御架构，掌握输入层、模型层、输出层的防御技术
  </Card>
</Cards>

## 配套实验

<Cards>
  <Card title="实验 2.1：提示词注入" href="/docs/02-prompt-attacks/labs/prompt-injection">
    通过实际操作体验直接注入、间接注入等攻击技术
  </Card>
  <Card title="实验 2.2：越狱技术体验" href="/docs/02-prompt-attacks/labs/jailbreaking">
    亲手尝试不同的越狱技术，观察模型的响应
  </Card>
  <Card title="实验 2.3：系统提示提取" href="/docs/02-prompt-attacks/labs/prompt-extraction">
    使用多种技术尝试提取系统提示词
  </Card>
</Cards>

<Callout title="安全提示" type="warn">
本模块介绍的攻击技术仅供学习和研究目的。请在合法和授权的环境中进行实验，不要将这些技术用于未经授权的系统或恶意用途。
</Callout>

## 常见问题

<Accordions>
  <Accordion title="提示词攻击和传统的 SQL 注入有什么区别？">
    两者的核心原理相似——都是利用系统无法区分指令和数据的问题。但 SQL 注入针对的是数据库查询，而提示词攻击针对的是 AI 模型。SQL 注入可以通过参数化查询完全防御，但提示词攻击的防御更加困难，因为 AI 模型本质上需要理解自然语言。
  </Accordion>
  <Accordion title="学习这些攻击技术会不会被用于非法用途？">
    学习攻击技术的目的是为了更好地防御。就像学习密码破解技术是为了设计更安全的密码策略一样。理解攻击者的方法是建立有效防御的前提。请始终在授权的环境中进行实验，并遵守道德准则。
  </Accordion>
  <Accordion title="这些攻击技术对所有 AI 模型都有效吗？">
    不同模型的安全性差异很大。大型商业模型（如 GPT-4、Claude）有较强的安全对齐，但仍然可能被绕过。开源模型或未经安全微调的模型更容易受到攻击。本模块会讨论不同技术的适用场景。
  </Accordion>
  <Accordion title="学完这个模块能做什么？">
    学完本模块后，你将能够：识别和分析各类提示词攻击、评估 AI 系统的安全风险、设计多层防御方案、进行基本的红队测试。这些技能对于 AI 安全工程师、产品经理和开发者都非常有价值。
  </Accordion>
</Accordions>
