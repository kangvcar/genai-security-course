---
title: 数据投毒总览
description: 深入理解数据投毒攻击原理和后门检测技术
icon: Skull
---

import { Cards, Card } from 'fumadocs-ui/components/card';
import { Callout } from 'fumadocs-ui/components/callout';

在前面的模块中，我们学习了针对已部署模型的攻击技术——提示词注入和对抗样本都发生在模型推理阶段。然而，还有一类更加隐蔽、影响更加深远的攻击方式：它不是在模型使用时发起攻击，而是在模型训练之前就已经埋下隐患。这就是**数据投毒攻击（Data Poisoning Attack）**。

数据投毒就像是在教科书印刷之前篡改内容——学生拿到的教科书看起来完全正常，但里面的某些知识点已经被悄悄改错了。一旦训练数据被污染，其影响将伴随模型的整个生命周期。

## 学习目标

<Callout title="完成本模块后，你将能够：" type="success">
- 理解数据投毒攻击的基本原理，区分标签翻转和干净标签攻击
- 掌握后门攻击的核心概念，了解触发器设计和 BadNets 攻击方法
- 认识 AI 供应链的安全风险，包括模型仓库投毒和 Pickle 漏洞
- 掌握后门检测技术，包括激活聚类、Neural Cleanse 和 STRIP
- 建立完整的防御思维，从数据、训练、模型、供应链四个层面保护 AI 系统
</Callout>

## 章节概览

<Cards>
  <Card title="第1章：数据投毒攻击原理" href="/docs/05-data-poisoning/poisoning-principles">
    理解标签翻转攻击和干净标签攻击的原理与危害
  </Card>
  <Card title="第2章：后门攻击技术" href="/docs/05-data-poisoning/backdoor-attacks">
    深入学习触发器设计和 BadNets 等经典后门攻击方法
  </Card>
  <Card title="第3章：供应链攻击向量" href="/docs/05-data-poisoning/supply-chain-attacks">
    探索模型仓库投毒、Pickle 漏洞和数据集投毒的威胁
  </Card>
  <Card title="第4章：后门检测技术" href="/docs/05-data-poisoning/backdoor-detection">
    掌握激活聚类、Neural Cleanse 和 STRIP 等检测方法
  </Card>
  <Card title="第5章：防御与缓解措施" href="/docs/05-data-poisoning/defense-mitigation">
    学习数据清洗、鲁棒训练、后门移除和供应链安全实践
  </Card>
</Cards>

## 配套实验

<Cards>
  <Card title="实验 5.1：标签翻转攻击" href="/docs/05-data-poisoning/labs/label-flipping">
    实践标签翻转投毒攻击，观察不同投毒比例的影响
  </Card>
  <Card title="实验 5.2：后门攻击" href="/docs/05-data-poisoning/labs/backdoor-attack">
    实现 BadNets 后门攻击，理解触发器植入过程
  </Card>
  <Card title="实验 5.3：后门检测" href="/docs/05-data-poisoning/labs/backdoor-detection">
    使用激活聚类等方法检测模型中的后门
  </Card>
</Cards>

<Callout title="安全提示" type="warn">
本模块介绍的攻击技术仅供学习和研究目的。请在合法和授权的环境中进行实验，不要将这些技术用于未经授权的系统或恶意用途。
</Callout>
