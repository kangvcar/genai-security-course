---
title: 第1章：安全评估方法论
description: 学习系统性评估 AI 应用安全性的框架、威胁建模方法和安全检查清单
---

import { Callout } from 'fumadocs-ui/components/callout';
import { Tabs, Tab } from 'fumadocs-ui/components/tabs';
import { Accordion, Accordions } from 'fumadocs-ui/components/accordion';
import { Steps, Step } from 'fumadocs-ui/components/steps';

<Callout title="" type="info">
预计阅读约12分钟
</Callout>

## 本章导读

前四个模块中，我们学习了各种具体的攻击技术和防御方法。但在实际工作中，你面对的不是"某一种攻击"，而是一整个 AI 应用系统——你需要回答的问题是：**这个系统整体上安全吗？有哪些风险？优先修什么？**

这就需要一套系统性的评估方法。本章将介绍 AI 安全评估的基本框架，让你掌握"从哪里开始、检查什么、如何排序"的结构化思路。

## 学习目标

<Callout title="本章学完后，你将能够：" type="info">
1. **理解安全评估的基本流程**：知道一次完整的安全评估包含哪些步骤
2. **掌握威胁建模方法**：能使用 STRIDE 模型识别 AI 应用的安全威胁
3. **构建风险矩阵**：能对识别出的威胁进行风险评级（可能性×影响）
4. **使用安全检查清单**：知道 AI 应用安全评估需要检查哪些项目
</Callout>

## 1 为什么需要系统性评估

### 1.1 "打地鼠"式安全的问题

在前面的模块中，我们分别学习了提示词注入、越狱、对抗样本、隐私泄露、数据投毒、供应链攻击……每一种攻击都有对应的防御方法。但如果只是"发现一个问题修一个"，就像打地鼠一样，永远被动应对。

这种方式的问题在于：

```text title="被动式安全的困境"
问题1：可能有你不知道的攻击方式（未知的未知）
问题2：不同攻击之间可能组合使用，单独防御不够
问题3：资源有限，不知道应该优先处理哪个风险
问题4：缺乏全局视角，可能遗漏关键环节
```

系统性安全评估的目标就是解决这些问题——用一个**结构化的方法**来全面检查系统的安全状况。

### 1.2 安全评估的基本流程

一次完整的 AI 安全评估通常包含以下步骤：

<Steps>
  <Step>
    ### 资产识别
    
    弄清楚要保护什么：模型、数据、用户信息、系统提示词、API 密钥等。
  </Step>
  <Step>
    ### 威胁建模
    
    分析谁可能攻击、用什么方式攻击、攻击什么目标。这是评估的核心步骤。
  </Step>
  <Step>
    ### 风险评估
    
    对每个威胁评估其发生的可能性和影响程度，确定优先级。
  </Step>
  <Step>
    ### 安全测试
    
    实际验证系统是否能抵御已识别的威胁。包括自动化测试和手动红队测试。
  </Step>
  <Step>
    ### 报告与修复
    
    记录发现的问题，给出修复建议，跟踪修复进度。
  </Step>
</Steps>

到这里，我们对安全评估有了一个整体的认识。下面重点讲解其中最核心的两个步骤：威胁建模和风险评估。

## 2 威胁建模：STRIDE 方法

### 2.1 什么是威胁建模

威胁建模（Threat Modeling）是一种结构化的方法，用来系统地识别一个系统可能面临的安全威胁。它的核心思想是：**站在攻击者的角度，思考"如果我要攻击这个系统，我会怎么做"**。

如果说前面四个模块教你的是"具体的攻击和防御技术"，那么威胁建模就是教你"在什么时候、对什么对象使用这些技术"。

### 2.2 STRIDE 模型

STRIDE 是微软提出的一种经典威胁分类方法。它把所有安全威胁分为六类，每类对应一个英文首字母：

| 类别 | 英文 | 含义 | AI 应用中的典型例子 |
|------|------|------|-------------------|
| **S** | Spoofing | 身份伪造 | 伪造用户身份调用 AI API |
| **T** | Tampering | 数据篡改 | 修改模型输入或训练数据（对抗样本、数据投毒） |
| **R** | Repudiation | 抵赖 | 用户否认曾发送过攻击性提示词 |
| **I** | Information Disclosure | 信息泄露 | 系统提示词泄露、训练数据提取、隐私泄露 |
| **D** | Denial of Service | 拒绝服务 | 发送大量复杂提示词使 AI 服务不可用 |
| **E** | Elevation of Privilege | 权限提升 | 通过提示词注入让模型执行超出权限的操作 |

### 2.3 STRIDE 在 AI 应用中的实践

让我们用一个具体的例子来演示如何使用 STRIDE。假设我们要评估一个 **AI 客服聊天机器人** 的安全性：

<Tabs items={["S - 身份伪造", "T - 数据篡改", "R - 抵赖", "I - 信息泄露", "D - 拒绝服务", "E - 权限提升"]}>
  <Tab value="S - 身份伪造">
```text title="威胁分析"
攻击场景：攻击者伪造管理员身份，通过提示词注入声称自己是"系统管理员"
涉及知识：模块二第1章 提示词注入
防御措施：不在提示词中实现身份验证，使用应用层的身份认证机制
风险等级：中
```
  </Tab>
  <Tab value="T - 数据篡改">
```text title="威胁分析"
攻击场景：攻击者通过对抗样本修改输入，使客服给出错误的产品信息
涉及知识：模块四第1章 对抗样本
防御措施：输入规范化、Unicode清洗（模块三第2章）
风险等级：中
```
  </Tab>
  <Tab value="R - 抵赖">
```text title="威胁分析"
攻击场景：用户声称从未发送过某条不当消息
涉及知识：日志审计
防御措施：完整记录所有对话日志，包含时间戳和用户标识
风险等级：低
```
  </Tab>
  <Tab value="I - 信息泄露">
```text title="威胁分析"
攻击场景1：攻击者提取系统提示词，了解客服系统的内部规则
攻击场景2：攻击者诱导模型泄露其他用户的订单信息
涉及知识：模块二第4章 系统提示提取、模块四第2章 隐私泄露
防御措施：系统提示词加固（模块三第1章）、输出过滤（模块三第3章）
风险等级：高
```
  </Tab>
  <Tab value="D - 拒绝服务">
```text title="威胁分析"
攻击场景：攻击者发送超长或超复杂的提示词，消耗大量GPU资源
涉及知识：资源管理
防御措施：输入长度限制、请求频率限制、超时控制
风险等级：中
```
  </Tab>
  <Tab value="E - 权限提升">
```text title="威胁分析"
攻击场景：通过提示词注入让客服执行退款、修改订单等超出权限的操作
涉及知识：模块二第1章 提示词注入
防御措施：权限控制不依赖LLM判断，敏感操作需人工审批
风险等级：高
```
  </Tab>
</Tabs>

<Callout title="关键原则" type="warn">
威胁建模最重要的不是找到所有威胁，而是**不遗漏关键类别**。STRIDE 的六个类别就像一份"检查表"，提醒你从六个角度逐一检查，避免思维盲区。
</Callout>

## 3 风险评估：优先级排序

### 3.1 风险矩阵

识别出威胁后，下一步是确定**优先处理哪些**。资源总是有限的，不可能同时修复所有问题。

风险矩阵是一种简单有效的优先级排序工具。它用两个维度来评估每个威胁：

```text title="风险矩阵"
              影响程度
          低      中      高
可  高   中风险  高风险  极高风险
能  中   低风险  中风险  高风险  
性  低   极低    低风险  中风险
```

**可能性**：这个威胁实际发生的概率有多大？考虑因素包括攻击难度、攻击者动机、暴露面大小。

**影响程度**：如果威胁发生，后果有多严重？考虑因素包括数据泄露范围、业务中断时间、法律合规风险、声誉损失。

### 3.2 AI 应用的典型风险排序

根据当前 AI 安全领域的实践经验，以下是 AI 应用中常见威胁的典型风险排序：

| 风险等级 | 威胁类型 | 理由 |
|----------|---------|------|
| 极高 | 提示词注入导致数据泄露 | 可能性高（攻击门槛低）+ 影响大（用户数据泄露） |
| 高 | 系统提示词提取 | 可能性高 + 影响中（暴露内部逻辑） |
| 高 | 越狱生成有害内容 | 可能性中 + 影响大（合规和声誉风险） |
| 中 | 供应链投毒 | 可能性低 + 影响极大（整个系统被控制） |
| 中 | 对抗样本攻击 | 可能性中 + 影响中 |
| 低 | 训练数据提取（小模型） | 可能性低 + 影响中 |

<Callout title="因场景而异" type="warn">
风险排序不是固定的。医疗 AI 和聊天机器人的风险排序完全不同——医疗 AI 中"生成错误信息"的风险等级远高于一般场景。实验 5.2 会让你针对具体场景进行威胁建模。
</Callout>

## 4 安全检查清单

### 4.1 为什么需要检查清单

威胁建模和风险评估帮你"想清楚要查什么"，而检查清单则帮你"确保不遗漏"。检查清单是安全评估中最实用的工具——它把抽象的安全要求转化为具体的、可逐项检查的条目。

### 4.2 AI 应用安全检查清单框架

以下是一份通用的 AI 应用安全检查清单框架，按照"防御层级"组织：

<Accordions>
  <Accordion title="1. 输入层安全（对应模块三第2章）">

```text title="检查项"
□ 是否限制了输入长度
□ 是否进行了 Unicode 规范化和特殊字符清洗
□ 是否实现了提示词注入检测
□ 是否有请求频率限制
□ 是否验证了输入数据的格式和类型
```
  </Accordion>
  <Accordion title="2. 模型层安全（对应模块三第1章）">

```text title="检查项"
□ 系统提示词是否包含防注入指令
□ 系统提示词是否包含角色边界定义
□ 是否使用了安全对齐的基础模型
□ 模型是否来自可信来源（对应模块四第4章）
□ 模型文件格式是否安全（safetensors vs pickle）
```
  </Accordion>
  <Accordion title="3. 输出层安全（对应模块三第3章）">

```text title="检查项"
□ 是否实现了敏感信息检测和脱敏
□ 是否检测输出中的有害内容
□ 是否限制了输出长度
□ 是否记录了输出日志
□ 高风险操作是否需要人工确认
```
  </Accordion>
  <Accordion title="4. 应用层安全">

```text title="检查项"
□ API 是否有身份认证和权限控制
□ 是否使用 HTTPS 加密通信
□ 是否有完整的审计日志
□ 错误信息是否避免泄露内部细节
□ 是否有异常行为监控和告警
```
  </Accordion>
  <Accordion title="5. 数据与隐私安全（对应模块四第2章）">

```text title="检查项"
□ 用户对话数据的存储是否加密
□ 是否明确了数据保留策略
□ 是否遵守了相关隐私法规（如个人信息保护法）
□ 训练数据是否经过 PII 清洗
□ 是否有数据泄露应急预案
```
  </Accordion>
</Accordions>

### 4.3 从检查清单到自动化

手动逐项检查可以发现问题，但对于持续运行的 AI 系统，更好的做法是把**检查清单中可自动化的部分**写成脚本，集成到开发流程中。

实验 5.1 就是做这件事——把上面的检查项中可编程的部分实现为 Python 函数，构建一个自动化安全检查工具。

## 本章小结

本章介绍了 AI 安全评估的系统性方法，从"点"到"面"地提升了你的安全思维：

1. **安全评估不是打地鼠**：需要系统性的框架来全面识别和管理风险
2. **STRIDE 是威胁建模的"检查表"**：从六个维度（身份伪造、数据篡改、抵赖、信息泄露、拒绝服务、权限提升）系统识别威胁
3. **风险矩阵帮你排序优先级**：用"可能性×影响程度"来决定先修什么
4. **检查清单确保不遗漏**：把安全要求转化为具体的可检查条目

接下来的实验 5.1 和 5.2 将让你动手实践威胁建模和安全检查清单的编写。

<Callout title="思考题" type="info">
1. 你正在为一个学校的 AI 作文批改助手做安全评估。用 STRIDE 方法，至少识别 3 个威胁。
2. 在上述场景中，哪个威胁的风险等级最高？为什么？
3. 如果资源只够修复两个问题，你会优先选择哪两个？
</Callout>
